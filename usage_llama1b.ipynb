{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/jovyan/sivtsov/associative-recurrent-memory-transformer\")\n",
    "sys.path.append(\"/home/jovyan/sivtsov/armt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/svtdanny/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from grouped_batching.llama1b_grouping import (\n",
    "    wrap_model_with_armt, get_grouped_states, \n",
    "    make_grouped_layer_from_single_layer, make_grouped_model_from_naive,\n",
    "    make_grouped_sliced_layer_from_single_layer\n",
    ")\n",
    "from grouped_batching.batching import GroupedBatcher\n",
    "from grouped_batching.executor import ArmtGroupedExecutor\n",
    "from grouped_batching.fast_executor import FastGroupedArmtExecutor, GroupedLayerContext, associate_with_context, update_mem_with_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_default_device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = torch.bfloat16\n",
    "torch.set_default_dtype(dtype)\n",
    "torch.set_grad_enabled(False)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    }
   ],
   "source": [
    "source_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B\"\n",
    "                                            #  , attn_implementation=\"sdpa\"\n",
    "                                            , attn_implementation=\"flash_attention_2\"\n",
    "                                             ,torch_dtype=dtype)\n",
    "source_model.eval()\n",
    "source_model.lm_head = torch.nn.Identity()\n",
    "reference_model = copy.deepcopy(source_model)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = source_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "armt_config = dict(\n",
    "    # segment_size=32,\n",
    "    # num_mem_tokens=16,\n",
    "    # segment_size=512,\n",
    "    # num_mem_tokens=128,\n",
    "    segment_size=1024,\n",
    "    num_mem_tokens=128,\n",
    "    d_mem=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "armt_model = wrap_model_with_armt(source_model, **armt_config)\n",
    "armt_model.to(\"cuda\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "armt_reference_model = wrap_model_with_armt(reference_model, **armt_config)\n",
    "armt_reference_model.to(\"cuda\")\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2813396/3159263316.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cpt = torch.load(model_cpt, map_location='cuda')\n"
     ]
    }
   ],
   "source": [
    "model_cpt = \"/home/jovyan/.cache/huggingface/hub/models--irodkin--ARMT-llama3.2-1B/snapshots/746e74bba3edc4cb3eaa11e13df5d900495e2300/armt_llama3.2-1B_step19500.bin\"\n",
    "cpt = torch.load(model_cpt, map_location='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armt_model.load_state_dict(cpt, strict=False)\n",
    "# armt_reference_model.load_state_dict(cpt, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_states = get_grouped_states(armt_model)\n",
    "# grouped_layer = make_grouped_layer_from_single_layer(\n",
    "#     copy.deepcopy(armt_model.memory_cell.model.model.layers[0]), *grouped_states)\n",
    "# # grouped_layer._grouped_execution = True\n",
    "# # grouped_layer._skip_associating = True\n",
    "# armt_grouped_model, source_model_layers = make_grouped_model_from_naive(armt_model, grouped_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grouped_batching.llama1b_grouping_autograd import make_grouped_training_layer_from_single_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINABLE VERSION\n",
    "\n",
    "# grouped_layer = make_grouped_training_layer_from_single_layer(\n",
    "#     copy.deepcopy(armt_model.memory_cell.model.model.layers[0]),\n",
    "#     armt_model.memory_cell.model.model.layers\n",
    "# )\n",
    "# armt_grouped_model, source_model_layers = make_grouped_model_from_naive(armt_model, grouped_layer)\n",
    "\n",
    "### AMORTIZIBLE VERSION\n",
    "\n",
    "# grouped_states = get_grouped_states(armt_model)\n",
    "# grouped_layer = make_grouped_layer_from_single_layer(\n",
    "#         copy.deepcopy(armt_model.memory_cell.model.model.layers[0]), *grouped_states)\n",
    "    \n",
    "# armt_grouped_model, source_model_layers = make_grouped_model_from_naive(armt_model, grouped_layer)\n",
    "\n",
    "# batcher = GroupedBatcher(\n",
    "#     armt_grouped_model, \n",
    "#     n_layers=model_config.num_hidden_layers, \n",
    "#     seg_size=armt_config[\"segment_size\"]+armt_config[\"num_mem_tokens\"], \n",
    "#     hid_dim=model_config.hidden_size, \n",
    "#     pos_embed_dim=model_config.hidden_size\n",
    "# )\n",
    "# executor = ArmtGroupedExecutor(armt_grouped_model, grouped_layer, batcher)\n",
    "\n",
    "### FAST LATENCY VERSION\n",
    "\n",
    "grouped_context = GroupedLayerContext()\n",
    "\n",
    "grouped_states = get_grouped_states(armt_model)\n",
    "grouped_layer = make_grouped_sliced_layer_from_single_layer(\n",
    "    grouped_context, copy.deepcopy(armt_model.memory_cell.model.model.layers[0]), *grouped_states\n",
    ")\n",
    "armt_grouped_model, source_model_layers = make_grouped_model_from_naive(armt_model, grouped_layer)\n",
    "\n",
    "\n",
    "executor = FastGroupedArmtExecutor(\n",
    "    armt_grouped_model, \n",
    "    grouped_layer, \n",
    "    grouped_context, \n",
    "    model_config.num_hidden_layers, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jit compile As: [torch.Size([512, 2048]), torch.Size([512, 2048]), torch.Size([512, 2048]), torch.Size([512, 2048]), torch.Size([512, 2048]), torch.Size([512, 2048]), torch.Size([512, 2048]), torch.Size([512, 2048]), torch.Size([512, 2048]), torch.Size([512, 2048]), torch.Size([512, 2048]), torch.Size([512, 2048]), torch.Size([512, 2048]), torch.Size([512, 2048]), torch.Size([512, 2048]), torch.Size([512, 2048])] Bs: [torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64])]\n",
      "\n",
      "// Gemm operator cutlass_tensorop_bf16_s16816gemm_grouped_bf16_256x128_64x3_tt_align8\n",
      "using cutlass_tensorop_bf16_s16816gemm_grouped_bf16_256x128_64x3_tt_align8_base =\n",
      "  typename cutlass::gemm::kernel::DefaultGemmGrouped<\n",
      "    cutlass::bfloat16_t, cutlass::layout::RowMajor, cutlass::ComplexTransform::kNone, 8,\n",
      "    cutlass::bfloat16_t, cutlass::layout::RowMajor, cutlass::ComplexTransform::kNone, 8,\n",
      "    cutlass::bfloat16_t, cutlass::layout::RowMajor,\n",
      "    float,\n",
      "    cutlass::arch::OpClassTensorOp,\n",
      "    cutlass::arch::Sm80,\n",
      "    cutlass::gemm::GemmShape<256, 128, 64>,\n",
      "    cutlass::gemm::GemmShape<64, 64, 64>,\n",
      "    cutlass::gemm::GemmShape<16, 8, 16>,\n",
      "    cutlass::epilogue::thread::LinearCombination<cutlass::bfloat16_t, 8, float, float>,\n",
      "    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<1>,\n",
      "    3,\n",
      "    cutlass::gemm::kernel::GroupScheduleMode::kDeviceOnly,\n",
      "    cutlass::arch::OpMultiplyAdd\n",
      ">::GemmKernel;\n",
      "\n",
      "// Define named type\n",
      "struct cutlass_tensorop_bf16_s16816gemm_grouped_bf16_256x128_64x3_tt_align8_type :\n",
      "  public cutlass_tensorop_bf16_s16816gemm_grouped_bf16_256x128_64x3_tt_align8_base { };\n",
      "\n",
      "USE_EFFICIENT_ALLOCATION\n"
     ]
    }
   ],
   "source": [
    "### ONLY FOR FAST LATENCY VERSION\n",
    "\n",
    "# compile full layers\n",
    "segments_input = torch.rand((model_config.num_hidden_layers, 512, 2048), device=\"cuda\", dtype=dtype)\n",
    "\n",
    "i, j = 0, 16\n",
    "grouped_context.start_idx = i\n",
    "grouped_context.end_idx = j\n",
    "grouped_context.is_full = True\n",
    "\n",
    "ao = associate_with_context(grouped_layer, grouped_context, segments_input[i:j])\n",
    "grouped_layer.generate_mode = True\n",
    "armt_grouped_model.memory_cell.model.model(inputs_embeds=segments_input[i:j], use_cache=False)\n",
    "update_mem_with_context(grouped_layer, grouped_context, segments_input[i:j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_segments = 150\n",
    "input_ids = torch.randint(\n",
    "    0, 10000, \n",
    "    (1, num_segments*armt_config[\"segment_size\"]), \n",
    "    dtype=torch.long, \n",
    "    device=\"cuda\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 153600])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.46 s, sys: 303 ms, total: 6.76 s\n",
      "Wall time: 6.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    # armt_reference_model.memory_cell.zero_mem()\n",
    "    armt_reference_model.memory_cell.generate_mode(False)\n",
    "    reference_output = armt_reference_model.forward(input_ids)\n",
    "\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.92 s, sys: 1.9 ms, total: 2.92 s\n",
      "Wall time: 2.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = executor.forward(input_ids)\n",
    "\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0104, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(output.logits-reference_output.logits)/torch.norm(reference_output.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0., device='cuda:0'), tensor(0., device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for some it is zero during all computations\n",
    "executor.armt_model.memory_cell.model.model.layers[0].W_mem.abs().sum(), armt_reference_model.memory_cell.model.model.layers[0].W_mem.abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8516e+00, 3.1641e-01, 3.5400e-03,  ..., 8.1177e-03, 1.5545e-04,\n",
       "         2.9602e-03],\n",
       "        [1.0986e-02, 2.6001e-02, 3.6523e-01,  ..., 1.3428e-03, 6.4941e-02,\n",
       "         1.6797e-01],\n",
       "        [9.3079e-04, 7.9956e-03, 5.3101e-03,  ..., 4.4688e+00, 2.3535e-01,\n",
       "         5.3101e-03],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 1.0645e-01,  ..., 9.7656e-02, 0.0000e+00,\n",
       "         1.5312e+00],\n",
       "        [6.6406e-02, 0.0000e+00, 8.3618e-03,  ..., 9.4238e-02, 5.4688e+00,\n",
       "         1.1812e+01],\n",
       "        [5.7188e+00, 2.6367e-01, 6.9336e-02,  ..., 0.0000e+00, 1.8164e-01,\n",
       "         1.2695e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor.armt_model.memory_cell.model.model.layers[0].z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1047e-02, 2.6123e-02, 3.6523e-01, 1.9684e-03, 4.1875e+00, 5.4688e+00,\n",
       "         2.0599e-04, 1.0312e+00, 4.1246e-05, 3.9577e-05, 3.0518e-02, 1.8311e-03,\n",
       "         2.7466e-04, 0.0000e+00, 4.4861e-03, 2.4531e+00, 1.0889e-01, 6.4844e-01,\n",
       "         1.3428e-02, 1.2031e+00, 3.0938e+00, 3.4809e-05, 3.8086e-01, 1.7422e+00,\n",
       "         1.8516e+00, 1.1562e+00, 1.1230e-02, 6.5002e-03, 1.0791e-01, 9.7656e-04,\n",
       "         1.1292e-02, 2.0117e-01, 1.1641e+00, 4.9375e+00, 1.0234e+00, 6.0156e-01,\n",
       "         9.8145e-02, 2.1094e-01, 3.7689e-03, 3.4943e-03, 9.1934e-04, 1.1094e+00,\n",
       "         1.2500e+00, 2.7812e+00, 5.3750e+00, 2.9449e-03, 7.9727e-04, 1.6406e-01,\n",
       "         1.0681e-02, 5.4626e-03, 2.7812e+00, 3.1471e-05, 5.9009e-06, 4.5625e+00,\n",
       "         7.3047e-01, 9.6680e-02, 2.0508e-01, 8.9453e-01, 1.4420e-03, 4.1260e-02,\n",
       "         1.1292e-02, 1.7090e-02, 4.8828e-02, 1.4258e-01, 4.6094e-01, 1.1658e-02,\n",
       "         0.0000e+00, 7.7515e-03, 2.0156e+00, 4.1875e+00, 1.9836e-03, 3.5938e+00,\n",
       "         2.1973e-03, 1.5137e-01, 1.8066e-02, 3.5156e-02, 1.9688e+00, 1.8438e+00,\n",
       "         4.2725e-04, 1.0395e-04, 1.5020e-05, 2.5391e-02, 4.0283e-02, 9.6512e-04,\n",
       "         6.2256e-03, 4.8096e-02, 3.9062e-03, 2.8381e-03, 1.1328e-01, 6.4850e-05,\n",
       "         3.0708e-04, 8.9453e-01, 1.6719e+00, 4.5312e-01, 9.4604e-04, 4.0627e-04,\n",
       "         6.4468e-04, 1.8158e-03, 9.2578e-01, 4.3359e-01, 1.4746e-01, 4.6387e-03,\n",
       "         6.9809e-04, 3.0938e+00, 1.1484e+00, 6.4062e+00, 0.0000e+00, 0.0000e+00,\n",
       "         6.9375e+00, 1.0875e+01, 2.4512e-01, 2.1362e-03, 5.0049e-03, 7.1777e-02,\n",
       "         1.1914e-01, 1.3203e+00, 2.8906e-01, 3.6621e-03, 4.8218e-03, 3.0078e-01,\n",
       "         9.3262e-02, 2.0801e-01, 4.8218e-03, 7.2861e-04, 9.5215e-03, 3.6926e-03,\n",
       "         7.2937e-03, 3.7500e-01, 4.5654e-02, 1.3086e-01, 3.8300e-03, 2.2812e+00,\n",
       "         0.0000e+00, 4.8125e+00, 7.7724e-05, 6.0272e-04, 3.7956e-04, 4.6143e-02,\n",
       "         3.7109e-01, 2.6855e-03, 8.4839e-03, 2.8729e-05, 4.8828e-02, 7.4387e-04,\n",
       "         1.9219e+00, 1.2024e-02, 1.3379e-01, 1.2656e+00, 5.4836e-05, 2.1973e-01,\n",
       "         1.5000e+00, 1.4343e-02, 8.0859e-01, 2.4375e+00, 9.4604e-03, 1.6602e-01,\n",
       "         2.8381e-03, 8.5449e-03, 1.4375e+00, 2.3438e-01, 5.3750e+00, 1.6479e-03,\n",
       "         1.5312e+00, 1.9688e+00, 5.2246e-02, 1.4922e+00, 2.0905e-03, 5.3406e-04,\n",
       "         2.8229e-03, 8.4229e-03, 1.4922e+00, 1.9922e+00, 3.2969e+00, 2.6245e-03,\n",
       "         1.8359e-01, 1.2054e-03, 6.4087e-04, 2.7188e+00, 1.8082e-03, 1.6937e-03,\n",
       "         1.5625e-02, 1.1921e-05, 5.3906e-01, 9.1406e-01, 1.8164e-01, 4.7266e-01,\n",
       "         2.2095e-02, 3.0078e-01, 1.4954e-02, 4.7070e-01, 1.1536e-02, 1.9336e-01,\n",
       "         1.6406e-01, 3.8147e-03, 1.0375e+01, 8.7280e-03, 1.1536e-02, 1.0391e+00,\n",
       "         3.5553e-03, 2.9907e-03, 7.1716e-03, 1.0547e+00, 1.0559e-02, 1.6016e+00,\n",
       "         9.2163e-03, 4.3438e+00, 4.8828e-04, 5.6250e+00, 3.1281e-04, 1.3428e-02,\n",
       "         8.6975e-04, 2.9144e-03, 2.8687e-02, 0.0000e+00, 1.2024e-02, 5.2002e-02,\n",
       "         4.4250e-04, 5.3406e-04, 4.4336e-01, 5.6458e-04, 2.6094e+00, 1.3477e-01,\n",
       "         1.4160e-01, 6.7188e-01, 1.1902e-02, 2.1851e-02, 8.2397e-03, 1.7422e+00,\n",
       "         8.9844e-02, 5.3406e-03, 1.5527e-01, 2.8076e-03, 6.8438e+00, 1.1875e+00,\n",
       "         0.0000e+00, 4.4688e+00, 0.0000e+00, 4.7812e+00, 7.0095e-05, 2.2125e-03,\n",
       "         4.8047e-01, 0.0000e+00, 2.6562e-01, 3.5547e-01, 2.5940e-03, 3.7231e-03,\n",
       "         1.0625e+00, 8.4400e-05, 1.6641e+00, 3.6133e-02, 1.4404e-02, 4.7363e-02,\n",
       "         3.9375e+00, 4.4861e-03, 5.2188e+00, 5.6763e-03, 9.4604e-03, 3.8750e+00,\n",
       "         1.4343e-02, 2.2430e-03, 2.6094e+00, 4.6730e-04, 6.0654e-04, 0.0000e+00,\n",
       "         2.9219e+00, 1.3379e-01, 3.4180e-01, 0.0000e+00, 3.3417e-03, 2.1820e-03,\n",
       "         1.0620e-02, 4.0283e-02, 5.3711e-03, 1.3125e+00, 2.0000e+00, 1.7344e+00,\n",
       "         1.2344e+00, 6.4062e-01, 2.1094e+00, 3.4688e+00, 1.3306e-02, 2.3281e+00,\n",
       "         5.3711e-03, 1.2891e-01, 9.8828e-01, 1.9653e-02, 2.3242e-01, 2.6703e-04,\n",
       "         2.4707e-01, 3.1875e+00, 4.1008e-04, 2.9219e+00, 1.6406e-01, 7.7734e-01,\n",
       "         1.3199e-03, 6.6376e-04, 1.1875e+00, 1.9409e-02, 5.9204e-03, 2.4844e+00,\n",
       "         2.3906e+00, 1.9150e-03, 1.2207e-01, 3.4375e+00, 0.0000e+00, 1.0400e-01,\n",
       "         1.9141e+00, 1.5259e-03, 2.7344e-02, 1.9141e+00, 0.0000e+00, 6.0938e-01,\n",
       "         1.5469e+00, 4.2969e-01, 3.5645e-02, 1.2891e-01, 5.4169e-04, 1.6406e-01,\n",
       "         4.9561e-02, 2.6367e-02, 4.9375e+00, 1.7929e-03, 6.9809e-04, 5.8984e-01,\n",
       "         3.8574e-02, 3.5706e-03, 3.6163e-03, 3.2196e-03, 1.1094e+00, 3.1562e+00,\n",
       "         2.1667e-03, 1.2344e+00, 6.6797e-01, 1.3672e-02, 1.0452e-03, 1.3281e+00,\n",
       "         1.0596e-01, 9.9945e-04, 3.6406e+00, 2.6512e-04, 7.0703e-01, 1.0938e+00,\n",
       "         5.1498e-04, 6.0938e-01, 4.2419e-03, 1.6785e-03, 5.7031e-01, 2.0117e-01,\n",
       "         2.1973e-03, 1.1797e+00, 5.2002e-02, 1.5564e-02, 1.8616e-03, 9.5215e-02,\n",
       "         5.0049e-03, 7.9956e-03, 3.0664e-01, 8.3618e-03, 1.0234e+00, 2.3340e-01,\n",
       "         1.6846e-02, 7.0312e+00, 1.5163e-04, 4.3438e+00, 1.0188e+01, 2.4223e-04,\n",
       "         2.6512e-04, 3.8528e-04, 2.0938e+00, 7.4387e-05, 9.9182e-04, 2.1406e+00,\n",
       "         2.9373e-04, 3.2997e-04, 2.3438e+00, 4.7852e-02, 2.6550e-03, 1.0312e+00,\n",
       "         4.5471e-03, 1.2146e-02, 6.2012e-02, 1.3580e-03, 6.4941e-02, 1.6602e-01]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "armt_reference_model.memory_cell.model.model.layers[1].z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this way you can \"batch\" several inputs to amortize the cost of the batcher\n",
    "\n",
    "__BUT:__ this will work only for discriminative tasks for now, because for autoregressive generation memory of all entries in batch should be preserved (currently only last segment memory will be preserved) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n",
      "torch.Size([16, 128, 1]) torch.Size([16, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "### ONLY FOR AMORTIZABLE VERSION\n",
    "\n",
    "output_list = executor.forward([input_ids, input_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(output_list[0].logits, output_list[1].logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda_rmt_it_venv]",
   "language": "python",
   "name": "conda-env-conda_rmt_it_venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
