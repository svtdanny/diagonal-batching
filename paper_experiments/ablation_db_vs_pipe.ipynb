{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d608bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/svtdanny/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import LlamaConfig\n",
    "from transformers.models.llama.modeling_llama import LlamaDecoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a916156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.rand((batch_size, M, K), device=device, dtype=dtype)\n",
    "# b_single = torch.rand((K, N), device=device, dtype=dtype)\n",
    "# b_batch = torch.rand((batch_size, K, N), device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a5478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4118db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pick_num_heads(hidden_size: int, preferred_head_dim: int = 64) -> int:\n",
    "    # choose a divisor of hidden_size close to hidden_size / preferred_head_dim\n",
    "    candidates = [d for d in range(1, hidden_size + 1) if hidden_size % d == 0]\n",
    "    target = max(1, hidden_size // preferred_head_dim)\n",
    "    return min(candidates, key=lambda d: abs(d - target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e5da95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaDecoderLayer(\n",
       "  (self_attn): LlamaAttention(\n",
       "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "  )\n",
       "  (mlp): LlamaMLP(\n",
       "    (gate_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "    (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "    (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "    (act_fn): SiLU()\n",
       "  )\n",
       "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_heads = _pick_num_heads(hidden_size)\n",
    "cfg = LlamaConfig(\n",
    "    hidden_size=hidden_size,\n",
    "    intermediate_size=4 * hidden_size,\n",
    "    num_hidden_layers=1,\n",
    "    num_attention_heads=n_heads,\n",
    "    max_position_embeddings=4096,\n",
    "    attention_bias=False,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    #  attn_implementation=\"eager\",\n",
    "    attn_implementation=\"sdpa\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "layer = LlamaDecoderLayer(cfg, layer_idx=0)\n",
    "layer.to(\"cuda\", dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee80f0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1cb4680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaDecoderLayer(\n",
       "  (self_attn): LlamaAttention(\n",
       "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "  )\n",
       "  (mlp): LlamaMLP(\n",
       "    (gate_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "    (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "    (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "    (act_fn): SiLU()\n",
       "  )\n",
       "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd6e9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 2048\n",
    "test_inp = torch.rand((16, seq_len, hidden_size), device=\"cuda\", dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b183f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 126 ms, sys: 81.4 ms, total: 208 ms\n",
      "Wall time: 207 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = layer.mlp(test_inp)\n",
    "\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76e2b5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 79.4 ms, sys: 35.7 ms, total: 115 ms\n",
      "Wall time: 114 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create dummy attention mask and position embeddings (cos, sin tuple for RoPE)\n",
    "attention_mask = torch.ones((1, 1, seq_len, seq_len), device=\"cuda\", dtype=torch.bool)\n",
    "head_dim = hidden_size // n_heads\n",
    "cos = torch.rand((1, seq_len, head_dim), device=\"cuda\", dtype=torch.bfloat16)\n",
    "sin = torch.rand((1, seq_len, head_dim), device=\"cuda\", dtype=torch.bfloat16)\n",
    "position_embeddings = (cos, sin)\n",
    "\n",
    "_ = layer.self_attn(test_inp, attention_mask=attention_mask, position_embeddings=position_embeddings)\n",
    "\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7272a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "del _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae391a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 12\n",
    "# n_groups = 32\n",
    "n_groups = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89fdec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inp = torch.rand((n_groups, seq_len, hidden_size), device=\"cuda\", dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0256557",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_concrete = test_inp.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c10c7c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = torch.ones((1, 1, seq_len, seq_len), device=\"cuda\", dtype=torch.bool)\n",
    "head_dim = hidden_size // n_heads\n",
    "cos = torch.rand((1, seq_len, head_dim), device=\"cuda\", dtype=torch.bfloat16)\n",
    "sin = torch.rand((1, seq_len, head_dim), device=\"cuda\", dtype=torch.bfloat16)\n",
    "position_embeddings = (cos, sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb70750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 ms, sys: 373 Î¼s, total: 10.6 ms\n",
      "Wall time: 9.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for i in range(n_iters):\n",
    "    inp_concrete = layer.mlp(inp_concrete)\n",
    "    inp_concrete, _ = layer.self_attn(\n",
    "        inp_concrete, \n",
    "        attention_mask=attention_mask, \n",
    "        position_embeddings=position_embeddings,\n",
    "        use_cache=False\n",
    "    )\n",
    "    # del _\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a34c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "del inp_concrete\n",
    "del _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b28fa8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e6170e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [LlamaDecoderLayer(cfg, layer_idx=0) for _ in range(n_groups)]\n",
    "layers = [layer.to(\"cuda\", dtype=torch.bfloat16) for layer in layers]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c24d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_inp = torch.rand((n_iters, seq_len, hidden_size), device=\"cuda\", dtype=torch.bfloat16)\n",
    "additional_inp = list(additional_inp.split(1, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cb1189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_sol_concrete = list(test_inp.clone().split(1, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "201bb53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "streams = [torch.cuda.Stream() for _ in range(n_groups)]\n",
    "ready_from_prev = [torch.cuda.Event() for _ in range(n_groups-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5253ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = torch.ones((1, 1, seq_len, seq_len), device=\"cuda\", dtype=torch.bool)\n",
    "head_dim = hidden_size // n_heads\n",
    "cos = torch.rand((1, seq_len, head_dim), device=\"cuda\", dtype=torch.bfloat16)\n",
    "sin = torch.rand((1, seq_len, head_dim), device=\"cuda\", dtype=torch.bfloat16)\n",
    "position_embeddings = (cos, sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5fa49c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.23 s, sys: 2.48 ms, total: 1.23 s\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(n_iters):\n",
    "    for j in range(n_groups):\n",
    "        with torch.cuda.stream(streams[j]):\n",
    "            if j > 0:\n",
    "                streams[j].wait_event(ready_from_prev[j-1])\n",
    "                # pass\n",
    "            else:\n",
    "                inp_sol_concrete[0] = additional_inp[i]\n",
    "            cur_inp = inp_sol_concrete[j]\n",
    "             \n",
    "            cur_inp = layers[j].mlp(cur_inp)\n",
    "\n",
    "            cur_inp, _ = layer.self_attn(\n",
    "                cur_inp, \n",
    "                attention_mask=attention_mask, \n",
    "                position_embeddings=position_embeddings,\n",
    "                use_cache=False\n",
    "                )\n",
    "            \n",
    "            if j < n_groups - 1:\n",
    "                inp_sol_concrete[j+1] = cur_inp\n",
    "                ready_from_prev[j].record()\n",
    "                \n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6198ee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del inp_sol_concrete\n",
    "del ready_from_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4bfa5d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 512])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe08272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svtdanny",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
