{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/jovyan/gkuzmin/rmt_it/optimized_armt/grouped_batching/associative-recurrent-memory-transformer\")\n",
    "sys.path.append(\"/home/jovyan/gkuzmin/rmt_it/optimized_armt/grouped_batching\")\n",
    "sys.path.append(\"/home/jovyan/gkuzmin/rmt_it/optimized_armt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cutlass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from grouped_batching.llama1b_grouping import wrap_model_with_armt, get_grouped_states, make_grouped_layer_from_single_layer, make_grouped_model_from_naive\n",
    "from grouped_batching.batching import GroupedBatcher\n",
    "from grouped_batching.executor import ArmtGroupedExecutor\n",
    "# switch to fast version for generation\n",
    "#from grouped_batching.fast_executor import FastGroupedArmtExecutor, GroupedLayerContext, associate_with_context, update_mem_with_context\n",
    "#from grouped_batching.llama1b_grouping_autograd import make_grouped_training_layer_from_single_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_amt.language_modeling_old import AssociativeRecurrentWrapper, AssociativeMemoryCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget \"https://huggingface.co/AIRI-NLP/ARMT-Llama3-1b-Instruct-2x1024-v2/resolve/main/pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "armt_cpt_path = \"../grouped_batching_old//pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f8588e00700>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = torch.bfloat16\n",
    "torch.set_default_dtype(dtype)\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base model\n",
    "source_model = AutoModelForCausalLM.from_pretrained(\"unsloth/Llama-3.2-1B-Instruct\",\n",
    "                                                    attn_implementation=\"flash_attention_2\",\n",
    "                                                    torch_dtype=dtype,\n",
    "                                                    device_map=\"cpu\")\n",
    "source_model.eval()\n",
    "#source_model.lm_head = torch.nn.Identity()\n",
    "#reference_model = copy.deepcopy(source_model)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Llama-3.2-1B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssociativeRecurrentWrapper(\n",
       "  (memory_cell): AssociativeMemoryCell(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 2048, padding_idx=128004)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x AssociativeLayerWrapper(\n",
       "            (W_mq): Linear(in_features=2048, out_features=64, bias=False)\n",
       "            (W_mk): Linear(in_features=2048, out_features=64, bias=False)\n",
       "            (W_mv): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (W_mb): Linear(in_features=2048, out_features=1, bias=True)\n",
       "            (layer): LlamaDecoderLayer(\n",
       "              (self_attn): LlamaAttention(\n",
       "                (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "                (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "                (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "              )\n",
       "              (mlp): LlamaMLP(\n",
       "                (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "                (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "                (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "                (act_fn): SiLU()\n",
       "              )\n",
       "              (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "              (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "    )\n",
       "    (W_mq): ModuleList()\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x AssociativeLayerWrapper(\n",
       "        (W_mq): Linear(in_features=2048, out_features=64, bias=False)\n",
       "        (W_mk): Linear(in_features=2048, out_features=64, bias=False)\n",
       "        (W_mv): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (W_mb): Linear(in_features=2048, out_features=1, bias=True)\n",
       "        (layer): LlamaDecoderLayer(\n",
       "          (self_attn): LlamaAttention(\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "            (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "            (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after wrap base model in original ARMT and ARMT with grouped batching, and load pretrained weigths\n",
    "# the actual segment_size for this model is segment_size - mem_size, so we will use it later\n",
    "segment_size = 1024\n",
    "mem_size = 16\n",
    "segment_alignment = \"left\"\n",
    "attend_to_previous_input = False\n",
    "device = \"cpu\"\n",
    "max_n_segments = 32\n",
    "mem_cell_args = dict(\n",
    "    base_model=source_model,\n",
    "    num_mem_tokens=mem_size,\n",
    "    d_mem=64,\n",
    "    layers_attr=\"model.layers\",\n",
    "    wrap_pos=False,\n",
    "    correction=True,\n",
    ")\n",
    "\n",
    "cell = AssociativeMemoryCell(**mem_cell_args)\n",
    "original_model = AssociativeRecurrentWrapper(cell,\n",
    "                                            segment_size=segment_size-mem_size,\n",
    "                                            max_n_segments=max_n_segments,\n",
    "                                            segment_alignment=segment_alignment,\n",
    "                                            attend_to_previous_input=attend_to_previous_input,\n",
    ").to(device)\n",
    "\n",
    "cpt = torch.load(armt_cpt_path, map_location=device)\n",
    "original_model.load_state_dict(cpt, strict=True)\n",
    "original_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "armt_model = copy.deepcopy(original_model)\n",
    "grouped_states = get_grouped_states(armt_model)\n",
    "grouped_layer = make_grouped_layer_from_single_layer(\n",
    "    copy.deepcopy(armt_model.memory_cell.model.model.layers[0]), *grouped_states)\n",
    "# grouped_layer._grouped_execution = True\n",
    "# grouped_layer._skip_associating = True\n",
    "armt_grouped_model, source_model_layers = make_grouped_model_from_naive(armt_model, grouped_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = source_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = GroupedBatcher(\n",
    "    armt_grouped_model, \n",
    "    n_layers=model_config.num_hidden_layers, \n",
    "    seg_size=segment_size, \n",
    "    hid_dim=model_config.hidden_size, \n",
    "    pos_embed_dim=model_config.hidden_size\n",
    ")\n",
    "executor = ArmtGroupedExecutor(armt_grouped_model, grouped_layer, batcher)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 - check on random ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_segments = 10\n",
    "input_ids = torch.randint(\n",
    "    0, 5000, \n",
    "    (1, num_segments*(segment_size-mem_size)), \n",
    "    dtype=torch.long, \n",
    "    device=\"cuda\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model.memory_cell.zero_mem()\n",
    "reference_output = original_model.forward(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jit compile As: [torch.Size([1024, 2048]), torch.Size([1024, 2048]), torch.Size([1024, 2048]), torch.Size([1024, 2048]), torch.Size([1024, 2048]), torch.Size([1024, 2048]), torch.Size([1024, 2048]), torch.Size([1024, 2048]), torch.Size([1024, 2048]), torch.Size([1024, 2048]), torch.Size([1024, 2048]), torch.Size([1024, 2048]), torch.Size([1024, 2048]), torch.Size([1024, 2048]), torch.Size([1024, 2048]), torch.Size([1024, 2048])] Bs: [torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64]), torch.Size([2048, 64])]\n",
      "\n",
      "// Gemm operator cutlass_tensorop_bf16_s16816gemm_grouped_bf16_256x128_64x3_tt_align8\n",
      "using cutlass_tensorop_bf16_s16816gemm_grouped_bf16_256x128_64x3_tt_align8_base =\n",
      "  typename cutlass::gemm::kernel::DefaultGemmGrouped<\n",
      "    cutlass::bfloat16_t, cutlass::layout::RowMajor, cutlass::ComplexTransform::kNone, 8,\n",
      "    cutlass::bfloat16_t, cutlass::layout::RowMajor, cutlass::ComplexTransform::kNone, 8,\n",
      "    cutlass::bfloat16_t, cutlass::layout::RowMajor,\n",
      "    float,\n",
      "    cutlass::arch::OpClassTensorOp,\n",
      "    cutlass::arch::Sm80,\n",
      "    cutlass::gemm::GemmShape<256, 128, 64>,\n",
      "    cutlass::gemm::GemmShape<64, 64, 64>,\n",
      "    cutlass::gemm::GemmShape<16, 8, 16>,\n",
      "    cutlass::epilogue::thread::LinearCombination<cutlass::bfloat16_t, 8, float, float>,\n",
      "    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<1>,\n",
      "    3,\n",
      "    cutlass::gemm::kernel::GroupScheduleMode::kDeviceOnly,\n",
      "    cutlass::arch::OpMultiplyAdd\n",
      ">::GemmKernel;\n",
      "\n",
      "// Define named type\n",
      "struct cutlass_tensorop_bf16_s16816gemm_grouped_bf16_256x128_64x3_tt_align8_type :\n",
      "  public cutlass_tensorop_bf16_s16816gemm_grouped_bf16_256x128_64x3_tt_align8_base { };\n",
      "\n",
      "USE_EFFICIENT_ALLOCATION\n"
     ]
    }
   ],
   "source": [
    "output = executor.forward(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.4062,  6.3438,  5.1562,  ..., -3.2969, -3.2969, -3.2969],\n",
       "         [ 3.3594, 10.1250,  4.6875,  ..., -1.8281, -1.8281, -1.8359],\n",
       "         [ 3.1250,  6.8750,  3.8281,  ..., -3.0000, -3.0000, -3.0000],\n",
       "         ...,\n",
       "         [ 6.3125,  5.5000,  6.4062,  ..., -0.7734, -0.7734, -0.7734],\n",
       "         [ 6.9688,  6.0625,  6.0312,  ..., -1.7578, -1.7578, -1.7578],\n",
       "         [ 6.8125,  5.5938,  5.6250,  ..., -1.7109, -1.7031, -1.7031]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.4062,  6.3438,  5.1562,  ..., -3.2969, -3.2969, -3.2969],\n",
       "         [ 3.3594, 10.1250,  4.6875,  ..., -1.8281, -1.8281, -1.8359],\n",
       "         [ 3.1250,  6.8750,  3.8281,  ..., -3.0000, -3.0000, -3.0000],\n",
       "         ...,\n",
       "         [ 6.2812,  5.4688,  6.4688,  ..., -0.7969, -0.7930, -0.7930],\n",
       "         [ 6.9688,  6.0000,  6.0312,  ..., -1.8047, -1.8047, -1.8047],\n",
       "         [ 6.8125,  5.5312,  5.5938,  ..., -1.7422, -1.7422, -1.7422]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0201, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(output.logits-reference_output.logits)/torch.norm(reference_output.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2 - check on some short text and gradually increase length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2016])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_text = \"The invention of the printing press by Johannes Gutenberg in the 15th century revolutionized the way information was shared. Before this, books were copied by hand, making them rare and expensive. The printing press allowed for faster and cheaper production of books, leading to a wider spread of knowledge. This innovation played a key role in the Renaissance, the Reformation, and the Scientific Revolution by making texts more accessible to the general public.\"\n",
    "stacked_text = \" \".join([base_text]*200).strip()\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": stacked_text}\n",
    "]\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=False,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "input_ids = input_ids[..., :2*(segment_size-mem_size)]\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm on text with 1 segments: 0.0\n",
      "Norm on text with 2 segments: 0.0106201171875\n",
      "Norm on text with 3 segments: 0.01422119140625\n",
      "Norm on text with 4 segments: 0.01531982421875\n",
      "Norm on text with 5 segments: 0.0150146484375\n",
      "Norm on text with 6 segments: 0.01507568359375\n",
      "Norm on text with 7 segments: 0.01531982421875\n",
      "Norm on text with 8 segments: 0.015625\n",
      "Norm on text with 9 segments: 0.0155029296875\n",
      "Norm on text with 10 segments: 0.01544189453125\n",
      "Norm on text with 11 segments: 0.0157470703125\n",
      "Norm on text with 12 segments: 0.015625\n",
      "Norm on text with 13 segments: 0.01556396484375\n",
      "Norm on text with 14 segments: 0.015625\n",
      "Norm on text with 15 segments: 0.0157470703125\n",
      "Norm on text with 16 segments: 0.0157470703125\n"
     ]
    }
   ],
   "source": [
    "for segm in range(1,17):\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=False,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = input_ids[..., :segm*(segment_size-mem_size)]\n",
    "    original_model.memory_cell.zero_mem()\n",
    "    reference_output = original_model.forward(input_ids)\n",
    "    executor.armt_model.memory_cell.zero_mem()\n",
    "    output = executor.forward(input_ids)\n",
    "    diff = torch.norm(output.logits-reference_output.logits)/torch.norm(reference_output.logits)\n",
    "    print(f\"Norm on text with {segm} segments: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3 - check on BABILong qa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "armt_model = copy.deepcopy(original_model)\n",
    "grouped_states = get_grouped_states(armt_model)\n",
    "grouped_layer = make_grouped_layer_from_single_layer(\n",
    "    copy.deepcopy(armt_model.memory_cell.model.model.layers[0]), *grouped_states)\n",
    "# grouped_layer._grouped_execution = True\n",
    "# grouped_layer._skip_associating = True\n",
    "#grouped_layer.generate_mode = True\n",
    "armt_grouped_model, source_model_layers = make_grouped_model_from_naive(armt_model, grouped_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = GroupedBatcher(\n",
    "    armt_grouped_model, \n",
    "    n_layers=model_config.num_hidden_layers, \n",
    "    seg_size=segment_size, \n",
    "    hid_dim=model_config.hidden_size, \n",
    "    pos_embed_dim=model_config.hidden_size\n",
    ")\n",
    "executor = ArmtGroupedExecutor(armt_grouped_model, grouped_layer, batcher, original_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babilong.prompts import DEFAULT_PROMPTS, DEFAULT_TEMPLATE, get_formatted_input\n",
    "from tqdm import tqdm\n",
    "import datasets\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"qa1\"]\n",
    "split_names = [\"2k\", \"4k\", \"8k\"]\n",
    "dataset_name = \"RMT-team/babilong\"\n",
    "results_folder = \"./test_res\"\n",
    "model_name = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "use_instruction = True\n",
    "use_examples = True\n",
    "use_post_prompt = True\n",
    "use_chat_template = True\n",
    "api_url = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = executor\n",
    "model_cpt = \"mem_code_fix_executor_mem_patch_armt-1b-it-v2\"\n",
    "model.name_or_path = \"custom_rmt\"\n",
    "model.device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_kwargs = {\n",
    "    'max_new_tokens': 20,\n",
    "    'max_length': None,\n",
    "    'num_beams': 1,\n",
    "    'do_sample': False,\n",
    "    'temperature': None,\n",
    "    'top_p': None,\n",
    "    'top_k': None,\n",
    "    'pad_token_id': tokenizer.pad_token_id,\n",
    "    'eos_token_id': tokenizer.eos_token_id,\n",
    "    #'logits_processor': [NormLogitsWrapper()],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt template:\n",
      "{instruction}\n",
      "\n",
      "{examples}\n",
      "\n",
      "{post_prompt}\n",
      "\n",
      "<context>\n",
      "{context}\n",
      "</context>\n",
      "\n",
      "Question: {question}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tasks:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "lengths:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   1%|          | 1/100 [00:00<01:06,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   2%|▏         | 2/100 [00:01<01:02,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   3%|▎         | 3/100 [00:01<01:00,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   4%|▍         | 4/100 [00:02<00:58,  1.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   5%|▌         | 5/100 [00:03<00:57,  1.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   6%|▌         | 6/100 [00:03<00:56,  1.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   7%|▋         | 7/100 [00:04<00:56,  1.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   8%|▊         | 8/100 [00:04<00:49,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   9%|▉         | 9/100 [00:05<00:50,  1.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  10%|█         | 10/100 [00:05<00:51,  1.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  11%|█         | 11/100 [00:06<00:51,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  12%|█▏        | 12/100 [00:07<00:51,  1.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  13%|█▎        | 13/100 [00:07<00:51,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  14%|█▍        | 14/100 [00:08<00:51,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  15%|█▌        | 15/100 [00:08<00:50,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  16%|█▌        | 16/100 [00:09<00:49,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  17%|█▋        | 17/100 [00:10<00:49,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  18%|█▊        | 18/100 [00:10<00:48,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  19%|█▉        | 19/100 [00:11<00:48,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  20%|██        | 20/100 [00:11<00:47,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  21%|██        | 21/100 [00:12<00:46,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  22%|██▏       | 22/100 [00:13<00:45,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  23%|██▎       | 23/100 [00:13<00:45,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  24%|██▍       | 24/100 [00:14<00:44,  1.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  25%|██▌       | 25/100 [00:14<00:44,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  26%|██▌       | 26/100 [00:15<00:43,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  27%|██▋       | 27/100 [00:15<00:43,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  28%|██▊       | 28/100 [00:16<00:42,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  29%|██▉       | 29/100 [00:17<00:41,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  30%|███       | 30/100 [00:17<00:41,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  31%|███       | 31/100 [00:18<00:40,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  32%|███▏      | 32/100 [00:18<00:40,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  33%|███▎      | 33/100 [00:19<00:39,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  34%|███▍      | 34/100 [00:20<00:39,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  35%|███▌      | 35/100 [00:20<00:38,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  36%|███▌      | 36/100 [00:21<00:38,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  37%|███▋      | 37/100 [00:21<00:37,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  38%|███▊      | 38/100 [00:22<00:36,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  39%|███▉      | 39/100 [00:23<00:35,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  40%|████      | 40/100 [00:23<00:35,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  41%|████      | 41/100 [00:24<00:34,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  42%|████▏     | 42/100 [00:24<00:34,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  43%|████▎     | 43/100 [00:25<00:33,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  44%|████▍     | 44/100 [00:26<00:33,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  45%|████▌     | 45/100 [00:26<00:32,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  46%|████▌     | 46/100 [00:27<00:32,  1.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  47%|████▋     | 47/100 [00:27<00:31,  1.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  48%|████▊     | 48/100 [00:28<00:31,  1.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  49%|████▉     | 49/100 [00:28<00:27,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  50%|█████     | 50/100 [00:29<00:27,  1.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  51%|█████     | 51/100 [00:30<00:28,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  52%|█████▏    | 52/100 [00:30<00:27,  1.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  53%|█████▎    | 53/100 [00:31<00:27,  1.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  54%|█████▍    | 54/100 [00:31<00:27,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  55%|█████▌    | 55/100 [00:32<00:26,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  56%|█████▌    | 56/100 [00:33<00:25,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  57%|█████▋    | 57/100 [00:33<00:25,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  58%|█████▊    | 58/100 [00:34<00:24,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  59%|█████▉    | 59/100 [00:34<00:24,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  60%|██████    | 60/100 [00:35<00:23,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  61%|██████    | 61/100 [00:35<00:22,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  62%|██████▏   | 62/100 [00:36<00:22,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  63%|██████▎   | 63/100 [00:36<00:19,  1.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  64%|██████▍   | 64/100 [00:37<00:19,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  65%|██████▌   | 65/100 [00:38<00:19,  1.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  66%|██████▌   | 66/100 [00:38<00:17,  1.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  67%|██████▋   | 67/100 [00:39<00:18,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  68%|██████▊   | 68/100 [00:39<00:18,  1.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  69%|██████▉   | 69/100 [00:40<00:17,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  70%|███████   | 70/100 [00:40<00:17,  1.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  71%|███████   | 71/100 [00:41<00:17,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  72%|███████▏  | 72/100 [00:42<00:16,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  73%|███████▎  | 73/100 [00:42<00:15,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  74%|███████▍  | 74/100 [00:43<00:15,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  75%|███████▌  | 75/100 [00:43<00:14,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  76%|███████▌  | 76/100 [00:44<00:14,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  77%|███████▋  | 77/100 [00:45<00:13,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  78%|███████▊  | 78/100 [00:45<00:12,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  79%|███████▉  | 79/100 [00:46<00:12,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  80%|████████  | 80/100 [00:46<00:11,  1.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  81%|████████  | 81/100 [00:47<00:11,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  82%|████████▏ | 82/100 [00:48<00:10,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  83%|████████▎ | 83/100 [00:48<00:10,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  84%|████████▍ | 84/100 [00:49<00:09,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  85%|████████▌ | 85/100 [00:49<00:08,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  86%|████████▌ | 86/100 [00:50<00:08,  1.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  87%|████████▋ | 87/100 [00:51<00:07,  1.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  88%|████████▊ | 88/100 [00:51<00:07,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  89%|████████▉ | 89/100 [00:52<00:06,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  90%|█████████ | 90/100 [00:52<00:05,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  91%|█████████ | 91/100 [00:53<00:05,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  92%|█████████▏| 92/100 [00:53<00:04,  1.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  93%|█████████▎| 93/100 [00:54<00:04,  1.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  94%|█████████▍| 94/100 [00:55<00:03,  1.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  95%|█████████▌| 95/100 [00:55<00:02,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  96%|█████████▌| 96/100 [00:56<00:02,  1.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  97%|█████████▋| 97/100 [00:56<00:01,  1.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  98%|█████████▊| 98/100 [00:57<00:01,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  99%|█████████▉| 99/100 [00:58<00:00,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k: 100%|██████████| 100/100 [00:58<00:00,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "lengths:  33%|███▎      | 1/3 [01:01<02:02, 61.16s/it]\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   1%|          | 1/100 [00:00<01:04,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   2%|▏         | 2/100 [00:01<01:03,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   3%|▎         | 3/100 [00:01<01:02,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   4%|▍         | 4/100 [00:02<01:01,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   5%|▌         | 5/100 [00:03<01:01,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   6%|▌         | 6/100 [00:03<01:01,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   7%|▋         | 7/100 [00:04<01:00,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   8%|▊         | 8/100 [00:05<00:59,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   9%|▉         | 9/100 [00:05<00:59,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  10%|█         | 10/100 [00:06<00:58,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  11%|█         | 11/100 [00:07<00:57,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  12%|█▏        | 12/100 [00:07<00:57,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  13%|█▎        | 13/100 [00:08<00:56,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  14%|█▍        | 14/100 [00:09<00:56,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  15%|█▌        | 15/100 [00:09<00:55,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  16%|█▌        | 16/100 [00:10<00:54,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  17%|█▋        | 17/100 [00:11<00:53,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  18%|█▊        | 18/100 [00:11<00:52,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  19%|█▉        | 19/100 [00:12<00:52,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  20%|██        | 20/100 [00:12<00:51,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  21%|██        | 21/100 [00:13<00:50,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  22%|██▏       | 22/100 [00:14<00:50,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  23%|██▎       | 23/100 [00:14<00:49,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  24%|██▍       | 24/100 [00:15<00:48,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  25%|██▌       | 25/100 [00:16<00:48,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  26%|██▌       | 26/100 [00:16<00:47,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  27%|██▋       | 27/100 [00:17<00:47,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  28%|██▊       | 28/100 [00:17<00:42,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  29%|██▉       | 29/100 [00:18<00:43,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  30%|███       | 30/100 [00:19<00:43,  1.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  31%|███       | 31/100 [00:19<00:43,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  32%|███▏      | 32/100 [00:20<00:43,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  33%|███▎      | 33/100 [00:21<00:42,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  34%|███▍      | 34/100 [00:21<00:42,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  35%|███▌      | 35/100 [00:22<00:41,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  36%|███▌      | 36/100 [00:23<00:40,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  37%|███▋      | 37/100 [00:23<00:40,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  38%|███▊      | 38/100 [00:24<00:39,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  39%|███▉      | 39/100 [00:25<00:38,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  40%|████      | 40/100 [00:25<00:38,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  41%|████      | 41/100 [00:26<00:37,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  42%|████▏     | 42/100 [00:26<00:37,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  43%|████▎     | 43/100 [00:27<00:36,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  44%|████▍     | 44/100 [00:28<00:36,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  45%|████▌     | 45/100 [00:28<00:35,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  46%|████▌     | 46/100 [00:29<00:34,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  47%|████▋     | 47/100 [00:30<00:34,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  48%|████▊     | 48/100 [00:30<00:33,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  49%|████▉     | 49/100 [00:31<00:32,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  50%|█████     | 50/100 [00:32<00:32,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  51%|█████     | 51/100 [00:32<00:31,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  52%|█████▏    | 52/100 [00:33<00:30,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  53%|█████▎    | 53/100 [00:34<00:30,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  54%|█████▍    | 54/100 [00:34<00:29,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  55%|█████▌    | 55/100 [00:35<00:28,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  56%|█████▌    | 56/100 [00:35<00:25,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  57%|█████▋    | 57/100 [00:36<00:25,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  58%|█████▊    | 58/100 [00:36<00:25,  1.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  59%|█████▉    | 59/100 [00:37<00:25,  1.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  60%|██████    | 60/100 [00:38<00:24,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  61%|██████    | 61/100 [00:38<00:24,  1.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  62%|██████▏   | 62/100 [00:39<00:23,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  63%|██████▎   | 63/100 [00:40<00:23,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  64%|██████▍   | 64/100 [00:40<00:22,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  65%|██████▌   | 65/100 [00:41<00:22,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  66%|██████▌   | 66/100 [00:42<00:21,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  67%|██████▋   | 67/100 [00:42<00:20,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  68%|██████▊   | 68/100 [00:43<00:20,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  69%|██████▉   | 69/100 [00:43<00:19,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  70%|███████   | 70/100 [00:44<00:18,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  71%|███████   | 71/100 [00:45<00:18,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  72%|███████▏  | 72/100 [00:45<00:18,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  73%|███████▎  | 73/100 [00:46<00:17,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  74%|███████▍  | 74/100 [00:47<00:16,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  75%|███████▌  | 75/100 [00:47<00:15,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  76%|███████▌  | 76/100 [00:48<00:15,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  77%|███████▋  | 77/100 [00:49<00:14,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  78%|███████▊  | 78/100 [00:49<00:14,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  79%|███████▉  | 79/100 [00:50<00:13,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  80%|████████  | 80/100 [00:50<00:12,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  81%|████████  | 81/100 [00:51<00:12,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  82%|████████▏ | 82/100 [00:52<00:11,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  83%|████████▎ | 83/100 [00:52<00:10,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  84%|████████▍ | 84/100 [00:53<00:10,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  85%|████████▌ | 85/100 [00:54<00:09,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  86%|████████▌ | 86/100 [00:54<00:08,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  87%|████████▋ | 87/100 [00:55<00:08,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  88%|████████▊ | 88/100 [00:56<00:07,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  89%|████████▉ | 89/100 [00:56<00:07,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  90%|█████████ | 90/100 [00:57<00:06,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  91%|█████████ | 91/100 [00:58<00:05,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  92%|█████████▏| 92/100 [00:58<00:05,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  93%|█████████▎| 93/100 [00:59<00:04,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  94%|█████████▍| 94/100 [00:59<00:03,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  95%|█████████▌| 95/100 [01:00<00:03,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  96%|█████████▌| 96/100 [01:01<00:02,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  97%|█████████▋| 97/100 [01:01<00:01,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  98%|█████████▊| 98/100 [01:02<00:01,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  99%|█████████▉| 99/100 [01:03<00:00,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k: 100%|██████████| 100/100 [01:03<00:00,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "lengths:  67%|██████▋   | 2/3 [02:07<01:04, 64.24s/it]\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   1%|          | 1/100 [00:00<01:11,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   2%|▏         | 2/100 [00:01<01:02,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   3%|▎         | 3/100 [00:02<01:05,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   4%|▍         | 4/100 [00:02<01:06,  1.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   5%|▌         | 5/100 [00:03<01:06,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   6%|▌         | 6/100 [00:04<01:04,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   7%|▋         | 7/100 [00:04<01:04,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   8%|▊         | 8/100 [00:05<01:04,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   9%|▉         | 9/100 [00:06<01:04,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  10%|█         | 10/100 [00:06<01:03,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  11%|█         | 11/100 [00:07<01:03,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  12%|█▏        | 12/100 [00:08<01:02,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  13%|█▎        | 13/100 [00:09<01:01,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  14%|█▍        | 14/100 [00:09<01:00,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  15%|█▌        | 15/100 [00:10<00:59,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  16%|█▌        | 16/100 [00:11<00:59,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  17%|█▋        | 17/100 [00:11<00:59,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  18%|█▊        | 18/100 [00:12<00:58,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  19%|█▉        | 19/100 [00:13<00:58,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  20%|██        | 20/100 [00:14<00:57,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  21%|██        | 21/100 [00:14<00:56,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  22%|██▏       | 22/100 [00:15<00:55,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  23%|██▎       | 23/100 [00:16<00:54,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  24%|██▍       | 24/100 [00:16<00:53,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  25%|██▌       | 25/100 [00:17<00:52,  1.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  26%|██▌       | 26/100 [00:18<00:51,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  27%|██▋       | 27/100 [00:18<00:51,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  28%|██▊       | 28/100 [00:19<00:50,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  29%|██▉       | 29/100 [00:20<00:49,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  30%|███       | 30/100 [00:21<00:49,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  31%|███       | 31/100 [00:21<00:48,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  32%|███▏      | 32/100 [00:22<00:47,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  33%|███▎      | 33/100 [00:23<00:47,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  34%|███▍      | 34/100 [00:23<00:46,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  35%|███▌      | 35/100 [00:24<00:45,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  36%|███▌      | 36/100 [00:25<00:44,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  37%|███▋      | 37/100 [00:26<00:46,  1.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  38%|███▊      | 38/100 [00:26<00:45,  1.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  39%|███▉      | 39/100 [00:27<00:44,  1.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  40%|████      | 40/100 [00:28<00:43,  1.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  41%|████      | 41/100 [00:29<00:42,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  42%|████▏     | 42/100 [00:29<00:41,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  43%|████▎     | 43/100 [00:30<00:40,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  44%|████▍     | 44/100 [00:31<00:39,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  45%|████▌     | 45/100 [00:31<00:38,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  46%|████▌     | 46/100 [00:32<00:38,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  47%|████▋     | 47/100 [00:33<00:33,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  48%|████▊     | 48/100 [00:33<00:34,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  49%|████▉     | 49/100 [00:34<00:34,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  50%|█████     | 50/100 [00:35<00:33,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  51%|█████     | 51/100 [00:35<00:33,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  52%|█████▏    | 52/100 [00:36<00:32,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  53%|█████▎    | 53/100 [00:37<00:32,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  54%|█████▍    | 54/100 [00:37<00:31,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  55%|█████▌    | 55/100 [00:38<00:30,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  56%|█████▌    | 56/100 [00:39<00:30,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  57%|█████▋    | 57/100 [00:39<00:29,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  58%|█████▊    | 58/100 [00:40<00:29,  1.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  59%|█████▉    | 59/100 [00:41<00:28,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  60%|██████    | 60/100 [00:42<00:28,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  61%|██████    | 61/100 [00:42<00:27,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  62%|██████▏   | 62/100 [00:43<00:26,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  63%|██████▎   | 63/100 [00:44<00:25,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  64%|██████▍   | 64/100 [00:44<00:25,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  65%|██████▌   | 65/100 [00:45<00:24,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  66%|██████▌   | 66/100 [00:46<00:23,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  67%|██████▋   | 67/100 [00:46<00:23,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  68%|██████▊   | 68/100 [00:47<00:22,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  69%|██████▉   | 69/100 [00:48<00:21,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  70%|███████   | 70/100 [00:49<00:21,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  71%|███████   | 71/100 [00:49<00:20,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  72%|███████▏  | 72/100 [00:50<00:19,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  73%|███████▎  | 73/100 [00:51<00:19,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  74%|███████▍  | 74/100 [00:51<00:18,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  75%|███████▌  | 75/100 [00:52<00:17,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  76%|███████▌  | 76/100 [00:53<00:16,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  77%|███████▋  | 77/100 [00:53<00:16,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  78%|███████▊  | 78/100 [00:54<00:15,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  79%|███████▉  | 79/100 [00:55<00:14,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  80%|████████  | 80/100 [00:56<00:14,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  81%|████████  | 81/100 [00:56<00:13,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  82%|████████▏ | 82/100 [00:57<00:12,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  83%|████████▎ | 83/100 [00:58<00:11,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  84%|████████▍ | 84/100 [00:58<00:11,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  85%|████████▌ | 85/100 [00:59<00:10,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  86%|████████▌ | 86/100 [01:00<00:09,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  87%|████████▋ | 87/100 [01:01<00:09,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  88%|████████▊ | 88/100 [01:01<00:08,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  89%|████████▉ | 89/100 [01:02<00:07,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  90%|█████████ | 90/100 [01:03<00:06,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  91%|█████████ | 91/100 [01:03<00:06,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  92%|█████████▏| 92/100 [01:04<00:05,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  93%|█████████▎| 93/100 [01:05<00:04,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  94%|█████████▍| 94/100 [01:05<00:03,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  95%|█████████▌| 95/100 [01:06<00:03,  1.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  96%|█████████▌| 96/100 [01:06<00:02,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  97%|█████████▋| 97/100 [01:07<00:01,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  98%|█████████▊| 98/100 [01:08<00:01,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  99%|█████████▉| 99/100 [01:09<00:00,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k: 100%|██████████| 100/100 [01:09<00:00,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "lengths: 100%|██████████| 3/3 [03:19<00:00, 66.58s/it]\u001b[A\n",
      "tasks: 100%|██████████| 1/1 [03:19<00:00, 199.73s/it]\n"
     ]
    }
   ],
   "source": [
    "template_to_use = DEFAULT_TEMPLATE\n",
    "print(f'prompt template:\\n{template_to_use}')\n",
    "\n",
    "for task in tqdm(tasks, desc='tasks'):\n",
    "    # configure the prompt\n",
    "    prompt_cfg = {\n",
    "        'instruction': DEFAULT_PROMPTS[task]['instruction'] if use_instruction else '',\n",
    "        'examples': DEFAULT_PROMPTS[task]['examples'] if use_examples else '',\n",
    "        'post_prompt': DEFAULT_PROMPTS[task]['post_prompt'] if use_post_prompt else '',\n",
    "        'template': template_to_use,\n",
    "        'chat_template': use_chat_template,\n",
    "    }\n",
    "    prompt_name = [f'{k}_yes' if prompt_cfg[k] else f'{k}_no' for k in prompt_cfg if k != 'template']\n",
    "    prompt_name = '_'.join(prompt_name)\n",
    "\n",
    "    for split_name in tqdm(split_names, desc='lengths'):\n",
    "        # load dataset\n",
    "        data = datasets.load_dataset(dataset_name, split_name)\n",
    "        task_data = data[task]#.select([1])\n",
    "\n",
    "        # Prepare files with predictions, prompt, and generation configurations\n",
    "        outfile = Path(f'{results_folder}/{model_name.replace(\"../\", \"\")}/{model_cpt.replace(\"../\", \"\")}/{task}_{split_name}_{prompt_name}.csv')\n",
    "        outfile.parent.mkdir(parents=True, exist_ok=True)\n",
    "        cfg_file = f'./{results_folder}/{model_name.replace(\"../\", \"\")}/{model_cpt.replace(\"../\", \"\")}/{task}_{split_name}_{prompt_name}.json'\n",
    "        json.dump({'prompt': prompt_cfg, 'generate_kwargs': generate_kwargs}, open(cfg_file, 'w'), indent=4)\n",
    "\n",
    "        df = pd.DataFrame({'target': [], 'output': [], 'question': []})\n",
    "\n",
    "        for sample in tqdm(task_data, desc=f'task: {task} length: {split_name}'):\n",
    "            target = sample['target']\n",
    "            context = sample['input']\n",
    "            question = sample['question']\n",
    "\n",
    "            # format input text\n",
    "            input_text = get_formatted_input(context, question, prompt_cfg['examples'],\n",
    "                                             prompt_cfg['instruction'], prompt_cfg['post_prompt'],\n",
    "                                             template=prompt_cfg['template'])\n",
    "            if api_url:\n",
    "                # model is running via llamacpp's serve command\n",
    "                headers = {'Content-Type': 'application/json'}\n",
    "                if generate_kwargs['temperature'] is None:\n",
    "                    generate_kwargs['temperature'] = 0.0\n",
    "\n",
    "                if use_chat_template:\n",
    "                    input_text = [{'role': 'user', 'content': input_text}]\n",
    "                    model_inputs = tokenizer.apply_chat_template(input_text, tokenize=True,\n",
    "                                                                 add_generation_prompt=True)\n",
    "                else:\n",
    "                    model_inputs = tokenizer.encode(input_text, add_special_tokens=True)\n",
    "\n",
    "                request_data = {'prompt': model_inputs, 'temperature': generate_kwargs['temperature']}\n",
    "                response = requests.post(api_url, headers=headers, json=request_data).json()\n",
    "                output = response['content'].strip()\n",
    "            else:\n",
    "                # generate output using local model\n",
    "                if model.name_or_path in ['THUDM/chatglm3-6b-128k', 'THUDM/LongAlign-6B-64k-base', 'THUDM/LongAlign-6B-64k']:\n",
    "                    # have to add special code to run chatglm as tokenizer.chat_template tokenization is not\n",
    "                    # the same as in model.chat (recommended in https://huggingface.co/THUDM/chatglm3-6b-128k)\n",
    "                    with torch.no_grad():\n",
    "                        output, _ = model.chat(tokenizer, input_text, history=[], **generate_kwargs)\n",
    "                else:\n",
    "                    if use_chat_template:\n",
    "                        input_text = [{'role': 'user', 'content': input_text}]\n",
    "                        model_inputs = tokenizer.apply_chat_template(input_text, add_generation_prompt=True,\n",
    "                                                                     return_tensors='pt', return_dict=model.name_or_path==\"custom_rmt\").to(model.device)\n",
    "                        if model.name_or_path != \"custom_rmt\":\n",
    "                            model_inputs = {'input_ids': model_inputs}\n",
    "                    else:\n",
    "                        model_inputs = tokenizer(input_text, return_tensors='pt',\n",
    "                                                 add_special_tokens=True).to(model.device)\n",
    "\n",
    "                    sample_length = model_inputs['input_ids'].shape[1]\n",
    "                    with torch.no_grad():\n",
    "                        #print(model_inputs[\"input_ids\"].shape)\n",
    "                        #print(model_inputs)\n",
    "                        last_segm = model_inputs[\"input_ids\"].shape[-1] // (1024 - 16) * (1024 - 16)\n",
    "                        prev_ids = model_inputs[\"input_ids\"][..., :last_segm]\n",
    "                        #print(prev_ids.shape)\n",
    "                        #print(prev_ids)\n",
    "                        output = model.generate(**model_inputs, **generate_kwargs)\n",
    "                        # we need to reset memory states between samples for activation-beacon models\n",
    "                        if 'activation-beacon' in model.name_or_path and hasattr(model, 'memory'):\n",
    "                            model.memory.reset()\n",
    "                    if model.name_or_path != \"custom_rmt\":\n",
    "                        output = output[0][sample_length:]\n",
    "                    else:\n",
    "                        output = output[0]\n",
    "                    output = tokenizer.decode(output, skip_special_tokens=True).strip()\n",
    "\n",
    "            df.loc[len(df)] = [target, output, question]\n",
    "            # write results to csv file\n",
    "            df.to_csv(outfile, escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"qa1\"]\n",
    "split_names = [\"2k\", \"4k\", \"8k\"]\n",
    "dataset_name = \"RMT-team/babilong\"\n",
    "results_folder = \"./test_res\"\n",
    "model_name = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "use_instruction = True\n",
    "use_examples = True\n",
    "use_post_prompt = True\n",
    "use_chat_template = True\n",
    "api_url = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = original_model\n",
    "model_cpt = \"vanilla_armt-1b-it-v2\"\n",
    "model.name_or_path = \"custom_rmt\"\n",
    "model.device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_kwargs = {\n",
    "    'max_new_tokens': 20,\n",
    "    'max_length': None,\n",
    "    'num_beams': 1,\n",
    "    'do_sample': False,\n",
    "    'temperature': None,\n",
    "    'top_p': None,\n",
    "    'top_k': None,\n",
    "    'pad_token_id': tokenizer.pad_token_id,\n",
    "    'eos_token_id': tokenizer.eos_token_id,\n",
    "    #'logits_processor': [NormLogitsWrapper()],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt template:\n",
      "{instruction}\n",
      "\n",
      "{examples}\n",
      "\n",
      "{post_prompt}\n",
      "\n",
      "<context>\n",
      "{context}\n",
      "</context>\n",
      "\n",
      "Question: {question}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tasks:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "lengths:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   1%|          | 1/100 [00:00<00:58,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   2%|▏         | 2/100 [00:01<00:57,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   3%|▎         | 3/100 [00:01<00:56,  1.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   4%|▍         | 4/100 [00:02<00:56,  1.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   5%|▌         | 5/100 [00:02<00:55,  1.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   6%|▌         | 6/100 [00:03<00:54,  1.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   7%|▋         | 7/100 [00:04<00:54,  1.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   8%|▊         | 8/100 [00:04<00:53,  1.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:   9%|▉         | 9/100 [00:05<00:52,  1.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  10%|█         | 10/100 [00:05<00:52,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  11%|█         | 11/100 [00:06<00:51,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  12%|█▏        | 12/100 [00:06<00:50,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  13%|█▎        | 13/100 [00:07<00:50,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  14%|█▍        | 14/100 [00:08<00:49,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  15%|█▌        | 15/100 [00:08<00:49,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  16%|█▌        | 16/100 [00:09<00:48,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  17%|█▋        | 17/100 [00:09<00:47,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  18%|█▊        | 18/100 [00:10<00:47,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  19%|█▉        | 19/100 [00:11<00:46,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  20%|██        | 20/100 [00:11<00:46,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  21%|██        | 21/100 [00:12<00:45,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  22%|██▏       | 22/100 [00:12<00:44,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  23%|██▎       | 23/100 [00:13<00:44,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  24%|██▍       | 24/100 [00:13<00:43,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  25%|██▌       | 25/100 [00:14<00:42,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  26%|██▌       | 26/100 [00:15<00:42,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  27%|██▋       | 27/100 [00:15<00:41,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  28%|██▊       | 28/100 [00:16<00:41,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  29%|██▉       | 29/100 [00:16<00:40,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  30%|███       | 30/100 [00:17<00:40,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  31%|███       | 31/100 [00:17<00:39,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  32%|███▏      | 32/100 [00:18<00:39,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  33%|███▎      | 33/100 [00:19<00:38,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  34%|███▍      | 34/100 [00:19<00:37,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  35%|███▌      | 35/100 [00:20<00:37,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  36%|███▌      | 36/100 [00:20<00:36,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  37%|███▋      | 37/100 [00:21<00:36,  1.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  38%|███▊      | 38/100 [00:21<00:35,  1.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  39%|███▉      | 39/100 [00:22<00:35,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  40%|████      | 40/100 [00:23<00:34,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  41%|████      | 41/100 [00:23<00:33,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  42%|████▏     | 42/100 [00:24<00:33,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  43%|████▎     | 43/100 [00:24<00:32,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  44%|████▍     | 44/100 [00:25<00:32,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  45%|████▌     | 45/100 [00:25<00:31,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  46%|████▌     | 46/100 [00:26<00:31,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  47%|████▋     | 47/100 [00:27<00:30,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  48%|████▊     | 48/100 [00:27<00:29,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  49%|████▉     | 49/100 [00:28<00:29,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  50%|█████     | 50/100 [00:28<00:28,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  51%|█████     | 51/100 [00:29<00:28,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  52%|█████▏    | 52/100 [00:29<00:27,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  53%|█████▎    | 53/100 [00:30<00:26,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  54%|█████▍    | 54/100 [00:31<00:26,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  55%|█████▌    | 55/100 [00:31<00:25,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  56%|█████▌    | 56/100 [00:32<00:25,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  57%|█████▋    | 57/100 [00:32<00:24,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  58%|█████▊    | 58/100 [00:33<00:24,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  59%|█████▉    | 59/100 [00:33<00:23,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  60%|██████    | 60/100 [00:34<00:22,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  61%|██████    | 61/100 [00:35<00:22,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  62%|██████▏   | 62/100 [00:35<00:21,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  63%|██████▎   | 63/100 [00:36<00:21,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  64%|██████▍   | 64/100 [00:36<00:20,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  65%|██████▌   | 65/100 [00:37<00:20,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  66%|██████▌   | 66/100 [00:37<00:19,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  67%|██████▋   | 67/100 [00:38<00:18,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  68%|██████▊   | 68/100 [00:39<00:18,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  69%|██████▉   | 69/100 [00:39<00:17,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  70%|███████   | 70/100 [00:40<00:17,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  71%|███████   | 71/100 [00:40<00:16,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  72%|███████▏  | 72/100 [00:41<00:16,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  73%|███████▎  | 73/100 [00:41<00:15,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  74%|███████▍  | 74/100 [00:42<00:14,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  75%|███████▌  | 75/100 [00:43<00:14,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  76%|███████▌  | 76/100 [00:43<00:13,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  77%|███████▋  | 77/100 [00:44<00:13,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  78%|███████▊  | 78/100 [00:44<00:12,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  79%|███████▉  | 79/100 [00:45<00:12,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  80%|████████  | 80/100 [00:46<00:11,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  81%|████████  | 81/100 [00:46<00:10,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  82%|████████▏ | 82/100 [00:47<00:10,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  83%|████████▎ | 83/100 [00:47<00:09,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  84%|████████▍ | 84/100 [00:48<00:09,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  85%|████████▌ | 85/100 [00:48<00:08,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  86%|████████▌ | 86/100 [00:49<00:08,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  87%|████████▋ | 87/100 [00:50<00:07,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  88%|████████▊ | 88/100 [00:50<00:06,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  89%|████████▉ | 89/100 [00:51<00:06,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  90%|█████████ | 90/100 [00:51<00:05,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  91%|█████████ | 91/100 [00:52<00:05,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  92%|█████████▏| 92/100 [00:52<00:04,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  93%|█████████▎| 93/100 [00:53<00:04,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  94%|█████████▍| 94/100 [00:54<00:03,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  95%|█████████▌| 95/100 [00:54<00:02,  1.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  96%|█████████▌| 96/100 [00:55<00:02,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  97%|█████████▋| 97/100 [00:55<00:01,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  98%|█████████▊| 98/100 [00:56<00:01,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k:  99%|█████████▉| 99/100 [00:56<00:00,  1.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 2k: 100%|██████████| 100/100 [00:57<00:00,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "lengths:  33%|███▎      | 1/3 [01:00<02:00, 60.35s/it]\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   1%|          | 1/100 [00:00<01:08,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   2%|▏         | 2/100 [00:01<01:06,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   3%|▎         | 3/100 [00:02<01:06,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   4%|▍         | 4/100 [00:02<01:06,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   5%|▌         | 5/100 [00:03<01:05,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   6%|▌         | 6/100 [00:04<01:31,  1.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   7%|▋         | 7/100 [00:05<01:21,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   8%|▊         | 8/100 [00:06<01:15,  1.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:   9%|▉         | 9/100 [00:07<01:10,  1.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  10%|█         | 10/100 [00:07<01:07,  1.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  11%|█         | 11/100 [00:08<01:04,  1.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  12%|█▏        | 12/100 [00:09<01:02,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  13%|█▎        | 13/100 [00:09<01:01,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  14%|█▍        | 14/100 [00:10<00:59,  1.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  15%|█▌        | 15/100 [00:11<00:58,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  16%|█▌        | 16/100 [00:11<00:57,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  17%|█▋        | 17/100 [00:12<00:56,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  18%|█▊        | 18/100 [00:13<00:55,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  19%|█▉        | 19/100 [00:13<00:54,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  20%|██        | 20/100 [00:14<00:54,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  21%|██        | 21/100 [00:15<00:54,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  22%|██▏       | 22/100 [00:15<00:55,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  23%|██▎       | 23/100 [00:16<00:53,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  24%|██▍       | 24/100 [00:17<00:52,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  25%|██▌       | 25/100 [00:17<00:51,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  26%|██▌       | 26/100 [00:18<00:50,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  27%|██▋       | 27/100 [00:19<00:49,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  28%|██▊       | 28/100 [00:20<00:49,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  29%|██▉       | 29/100 [00:20<00:48,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  30%|███       | 30/100 [00:21<00:47,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  31%|███       | 31/100 [00:22<00:46,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  32%|███▏      | 32/100 [00:22<00:45,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  33%|███▎      | 33/100 [00:23<00:45,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  34%|███▍      | 34/100 [00:24<00:45,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  35%|███▌      | 35/100 [00:24<00:44,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  36%|███▌      | 36/100 [00:25<00:43,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  37%|███▋      | 37/100 [00:26<00:42,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  38%|███▊      | 38/100 [00:26<00:41,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  39%|███▉      | 39/100 [00:27<00:40,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  40%|████      | 40/100 [00:28<00:40,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  41%|████      | 41/100 [00:28<00:39,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  42%|████▏     | 42/100 [00:29<00:38,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  43%|████▎     | 43/100 [00:30<00:38,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  44%|████▍     | 44/100 [00:30<00:37,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  45%|████▌     | 45/100 [00:31<00:36,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  46%|████▌     | 46/100 [00:32<00:36,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  47%|████▋     | 47/100 [00:32<00:35,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  48%|████▊     | 48/100 [00:33<00:34,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  49%|████▉     | 49/100 [00:34<00:34,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  50%|█████     | 50/100 [00:34<00:33,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  51%|█████     | 51/100 [00:35<00:33,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  52%|█████▏    | 52/100 [00:36<00:32,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  53%|█████▎    | 53/100 [00:36<00:31,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  54%|█████▍    | 54/100 [00:37<00:30,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  55%|█████▌    | 55/100 [00:38<00:30,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  56%|█████▌    | 56/100 [00:38<00:29,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  57%|█████▋    | 57/100 [00:39<00:28,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  58%|█████▊    | 58/100 [00:40<00:27,  1.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  59%|█████▉    | 59/100 [00:40<00:27,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  60%|██████    | 60/100 [00:41<00:26,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  61%|██████    | 61/100 [00:42<00:25,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  62%|██████▏   | 62/100 [00:42<00:25,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  63%|██████▎   | 63/100 [00:43<00:24,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  64%|██████▍   | 64/100 [00:44<00:24,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  65%|██████▌   | 65/100 [00:44<00:23,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  66%|██████▌   | 66/100 [00:45<00:22,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  67%|██████▋   | 67/100 [00:46<00:22,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  68%|██████▊   | 68/100 [00:46<00:21,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  69%|██████▉   | 69/100 [00:47<00:20,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  70%|███████   | 70/100 [00:48<00:20,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  71%|███████   | 71/100 [00:48<00:19,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  72%|███████▏  | 72/100 [00:49<00:18,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  73%|███████▎  | 73/100 [00:50<00:18,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  74%|███████▍  | 74/100 [00:50<00:17,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  75%|███████▌  | 75/100 [00:51<00:16,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  76%|███████▌  | 76/100 [00:52<00:16,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  77%|███████▋  | 77/100 [00:52<00:15,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  78%|███████▊  | 78/100 [00:53<00:14,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  79%|███████▉  | 79/100 [00:54<00:14,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  80%|████████  | 80/100 [00:54<00:13,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  81%|████████  | 81/100 [00:55<00:12,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  82%|████████▏ | 82/100 [00:56<00:12,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  83%|████████▎ | 83/100 [00:56<00:11,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  84%|████████▍ | 84/100 [00:57<00:10,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  85%|████████▌ | 85/100 [00:58<00:10,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  86%|████████▌ | 86/100 [00:58<00:09,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  87%|████████▋ | 87/100 [00:59<00:08,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  88%|████████▊ | 88/100 [01:00<00:08,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  89%|████████▉ | 89/100 [01:00<00:07,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  90%|█████████ | 90/100 [01:01<00:06,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  91%|█████████ | 91/100 [01:02<00:06,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  92%|█████████▏| 92/100 [01:03<00:05,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  93%|█████████▎| 93/100 [01:03<00:04,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  94%|█████████▍| 94/100 [01:04<00:04,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  95%|█████████▌| 95/100 [01:05<00:03,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  96%|█████████▌| 96/100 [01:05<00:02,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  97%|█████████▋| 97/100 [01:06<00:02,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  98%|█████████▊| 98/100 [01:07<00:01,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k:  99%|█████████▉| 99/100 [01:07<00:00,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 4k: 100%|██████████| 100/100 [01:08<00:00,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "lengths:  67%|██████▋   | 2/3 [02:11<01:06, 66.59s/it]\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   1%|          | 1/100 [00:00<01:27,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   2%|▏         | 2/100 [00:01<01:26,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   3%|▎         | 3/100 [00:02<01:26,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   4%|▍         | 4/100 [00:03<01:25,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   5%|▌         | 5/100 [00:04<01:22,  1.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   6%|▌         | 6/100 [00:05<01:23,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   7%|▋         | 7/100 [00:06<01:23,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   8%|▊         | 8/100 [00:07<01:22,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:   9%|▉         | 9/100 [00:08<01:21,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  10%|█         | 10/100 [00:08<01:19,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  11%|█         | 11/100 [00:09<01:18,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  12%|█▏        | 12/100 [00:10<01:17,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  13%|█▎        | 13/100 [00:11<01:14,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  14%|█▍        | 14/100 [00:12<01:13,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  15%|█▌        | 15/100 [00:13<01:12,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  16%|█▌        | 16/100 [00:14<01:11,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  17%|█▋        | 17/100 [00:14<01:11,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  18%|█▊        | 18/100 [00:15<01:10,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  19%|█▉        | 19/100 [00:16<01:09,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  20%|██        | 20/100 [00:17<01:08,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  21%|██        | 21/100 [00:18<01:07,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  22%|██▏       | 22/100 [00:19<01:06,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  23%|██▎       | 23/100 [00:20<01:05,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  24%|██▍       | 24/100 [00:20<01:03,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  25%|██▌       | 25/100 [00:21<01:01,  1.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  26%|██▌       | 26/100 [00:22<01:01,  1.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  27%|██▋       | 27/100 [00:23<01:01,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  28%|██▊       | 28/100 [00:24<01:01,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  29%|██▉       | 29/100 [00:25<01:00,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  30%|███       | 30/100 [00:25<00:59,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  31%|███       | 31/100 [00:26<00:58,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  32%|███▏      | 32/100 [00:27<00:57,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  33%|███▎      | 33/100 [00:28<00:57,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  34%|███▍      | 34/100 [00:29<00:55,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  35%|███▌      | 35/100 [00:30<00:54,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  36%|███▌      | 36/100 [00:30<00:54,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  37%|███▋      | 37/100 [00:31<00:54,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  38%|███▊      | 38/100 [00:32<00:53,  1.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  39%|███▉      | 39/100 [00:33<00:53,  1.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  40%|████      | 40/100 [00:34<00:52,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  41%|████      | 41/100 [00:35<00:51,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  42%|████▏     | 42/100 [00:36<00:50,  1.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  43%|████▎     | 43/100 [00:37<00:49,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  44%|████▍     | 44/100 [00:37<00:47,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  45%|████▌     | 45/100 [00:38<00:46,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  46%|████▌     | 46/100 [00:39<00:45,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  47%|████▋     | 47/100 [00:40<00:44,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  48%|████▊     | 48/100 [00:41<00:44,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  49%|████▉     | 49/100 [00:42<00:43,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  50%|█████     | 50/100 [00:42<00:42,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  51%|█████     | 51/100 [00:43<00:41,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  52%|█████▏    | 52/100 [00:44<00:40,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  53%|█████▎    | 53/100 [00:45<00:39,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  54%|█████▍    | 54/100 [00:46<00:39,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  55%|█████▌    | 55/100 [00:47<00:38,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  56%|█████▌    | 56/100 [00:48<00:37,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  57%|█████▋    | 57/100 [00:48<00:36,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  58%|█████▊    | 58/100 [00:49<00:35,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  59%|█████▉    | 59/100 [00:50<00:34,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  60%|██████    | 60/100 [00:51<00:34,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  61%|██████    | 61/100 [00:52<00:33,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  62%|██████▏   | 62/100 [00:53<00:32,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  63%|██████▎   | 63/100 [00:54<00:31,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  64%|██████▍   | 64/100 [00:54<00:31,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  65%|██████▌   | 65/100 [00:55<00:30,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  66%|██████▌   | 66/100 [00:56<00:29,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  67%|██████▋   | 67/100 [00:57<00:28,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  68%|██████▊   | 68/100 [00:58<00:27,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  69%|██████▉   | 69/100 [00:59<00:26,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  70%|███████   | 70/100 [01:00<00:25,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  71%|███████   | 71/100 [01:00<00:24,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  72%|███████▏  | 72/100 [01:01<00:23,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  73%|███████▎  | 73/100 [01:02<00:22,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  74%|███████▍  | 74/100 [01:03<00:21,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  75%|███████▌  | 75/100 [01:04<00:21,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  76%|███████▌  | 76/100 [01:05<00:20,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  77%|███████▋  | 77/100 [01:05<00:19,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  78%|███████▊  | 78/100 [01:06<00:18,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  79%|███████▉  | 79/100 [01:07<00:17,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  80%|████████  | 80/100 [01:08<00:16,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  81%|████████  | 81/100 [01:09<00:16,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  82%|████████▏ | 82/100 [01:10<00:15,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  83%|████████▎ | 83/100 [01:11<00:14,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  84%|████████▍ | 84/100 [01:11<00:13,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  85%|████████▌ | 85/100 [01:12<00:12,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  86%|████████▌ | 86/100 [01:13<00:11,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  87%|████████▋ | 87/100 [01:14<00:11,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  88%|████████▊ | 88/100 [01:15<00:10,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  89%|████████▉ | 89/100 [01:16<00:09,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  90%|█████████ | 90/100 [01:16<00:08,  1.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  91%|█████████ | 91/100 [01:17<00:07,  1.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  92%|█████████▏| 92/100 [01:18<00:06,  1.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  93%|█████████▎| 93/100 [01:19<00:05,  1.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  94%|█████████▍| 94/100 [01:20<00:04,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  95%|█████████▌| 95/100 [01:21<00:04,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  96%|█████████▌| 96/100 [01:21<00:03,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  97%|█████████▋| 97/100 [01:22<00:02,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  98%|█████████▊| 98/100 [01:23<00:01,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k:  99%|█████████▉| 99/100 [01:24<00:00,  1.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "task: qa1 length: 8k: 100%|██████████| 100/100 [01:25<00:00,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "lengths: 100%|██████████| 3/3 [03:38<00:00, 72.97s/it]\u001b[A\n",
      "tasks: 100%|██████████| 1/1 [03:38<00:00, 218.92s/it]\n"
     ]
    }
   ],
   "source": [
    "template_to_use = DEFAULT_TEMPLATE\n",
    "print(f'prompt template:\\n{template_to_use}')\n",
    "\n",
    "for task in tqdm(tasks, desc='tasks'):\n",
    "    # configure the prompt\n",
    "    prompt_cfg = {\n",
    "        'instruction': DEFAULT_PROMPTS[task]['instruction'] if use_instruction else '',\n",
    "        'examples': DEFAULT_PROMPTS[task]['examples'] if use_examples else '',\n",
    "        'post_prompt': DEFAULT_PROMPTS[task]['post_prompt'] if use_post_prompt else '',\n",
    "        'template': template_to_use,\n",
    "        'chat_template': use_chat_template,\n",
    "    }\n",
    "    prompt_name = [f'{k}_yes' if prompt_cfg[k] else f'{k}_no' for k in prompt_cfg if k != 'template']\n",
    "    prompt_name = '_'.join(prompt_name)\n",
    "\n",
    "    for split_name in tqdm(split_names, desc='lengths'):\n",
    "        # load dataset\n",
    "        data = datasets.load_dataset(dataset_name, split_name)\n",
    "        task_data = data[task]#.select([1])\n",
    "\n",
    "        # Prepare files with predictions, prompt, and generation configurations\n",
    "        outfile = Path(f'{results_folder}/{model_name.replace(\"../\", \"\")}/{model_cpt.replace(\"../\", \"\")}/{task}_{split_name}_{prompt_name}.csv')\n",
    "        outfile.parent.mkdir(parents=True, exist_ok=True)\n",
    "        cfg_file = f'./{results_folder}/{model_name.replace(\"../\", \"\")}/{model_cpt.replace(\"../\", \"\")}/{task}_{split_name}_{prompt_name}.json'\n",
    "        json.dump({'prompt': prompt_cfg, 'generate_kwargs': generate_kwargs}, open(cfg_file, 'w'), indent=4)\n",
    "\n",
    "        df = pd.DataFrame({'target': [], 'output': [], 'question': []})\n",
    "\n",
    "        for sample in tqdm(task_data, desc=f'task: {task} length: {split_name}'):\n",
    "            target = sample['target']\n",
    "            context = sample['input']\n",
    "            question = sample['question']\n",
    "\n",
    "            # format input text\n",
    "            input_text = get_formatted_input(context, question, prompt_cfg['examples'],\n",
    "                                             prompt_cfg['instruction'], prompt_cfg['post_prompt'],\n",
    "                                             template=prompt_cfg['template'])\n",
    "            if api_url:\n",
    "                # model is running via llamacpp's serve command\n",
    "                headers = {'Content-Type': 'application/json'}\n",
    "                if generate_kwargs['temperature'] is None:\n",
    "                    generate_kwargs['temperature'] = 0.0\n",
    "\n",
    "                if use_chat_template:\n",
    "                    input_text = [{'role': 'user', 'content': input_text}]\n",
    "                    model_inputs = tokenizer.apply_chat_template(input_text, tokenize=True,\n",
    "                                                                 add_generation_prompt=True)\n",
    "                else:\n",
    "                    model_inputs = tokenizer.encode(input_text, add_special_tokens=True)\n",
    "\n",
    "                request_data = {'prompt': model_inputs, 'temperature': generate_kwargs['temperature']}\n",
    "                response = requests.post(api_url, headers=headers, json=request_data).json()\n",
    "                output = response['content'].strip()\n",
    "            else:\n",
    "                # generate output using local model\n",
    "                if model.name_or_path in ['THUDM/chatglm3-6b-128k', 'THUDM/LongAlign-6B-64k-base', 'THUDM/LongAlign-6B-64k']:\n",
    "                    # have to add special code to run chatglm as tokenizer.chat_template tokenization is not\n",
    "                    # the same as in model.chat (recommended in https://huggingface.co/THUDM/chatglm3-6b-128k)\n",
    "                    with torch.no_grad():\n",
    "                        output, _ = model.chat(tokenizer, input_text, history=[], **generate_kwargs)\n",
    "                else:\n",
    "                    if use_chat_template:\n",
    "                        input_text = [{'role': 'user', 'content': input_text}]\n",
    "                        model_inputs = tokenizer.apply_chat_template(input_text, add_generation_prompt=True,\n",
    "                                                                     return_tensors='pt', return_dict=model.name_or_path==\"custom_rmt\").to(model.device)\n",
    "                        if model.name_or_path != \"custom_rmt\":\n",
    "                            model_inputs = {'input_ids': model_inputs}\n",
    "                    else:\n",
    "                        model_inputs = tokenizer(input_text, return_tensors='pt',\n",
    "                                                 add_special_tokens=True).to(model.device)\n",
    "\n",
    "                    sample_length = model_inputs['input_ids'].shape[1]\n",
    "                    with torch.no_grad():\n",
    "                        #print(model_inputs[\"input_ids\"].shape)\n",
    "                        #print(model_inputs)\n",
    "                        last_segm = model_inputs[\"input_ids\"].shape[-1] // (1024 - 16) * (1024 - 16)\n",
    "                        prev_ids = model_inputs[\"input_ids\"][..., :last_segm]\n",
    "                        #print(prev_ids.shape)\n",
    "                        #print(prev_ids)\n",
    "                        output = model.generate(**model_inputs, **generate_kwargs)\n",
    "                        # we need to reset memory states between samples for activation-beacon models\n",
    "                        if 'activation-beacon' in model.name_or_path and hasattr(model, 'memory'):\n",
    "                            model.memory.reset()\n",
    "                    if model.name_or_path != \"custom_rmt\":\n",
    "                        output = output[0][sample_length:]\n",
    "                    else:\n",
    "                        output = output[0]\n",
    "                    output = tokenizer.decode(output, skip_special_tokens=True).strip()\n",
    "\n",
    "            df.loc[len(df)] = [target, output, question]\n",
    "            # write results to csv file\n",
    "            df.to_csv(outfile, escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compare_generated_ids(orig, opt, tokenizer):\n",
    "    toks_orig = np.array(tokenizer(orig)[\"input_ids\"])\n",
    "    toks_opt = np.array(tokenizer(opt)[\"input_ids\"])\n",
    "    length = min([len(toks_opt), len(toks_orig)])\n",
    "    #print(toks_opt, toks_orig, length)\n",
    "    #print(np.where(toks_orig[:length] == toks_opt[:length]))\n",
    "    match = np.mean(toks_orig[:length] == toks_opt[:length])\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2k 8.4%\n",
      "4k 6.3%\n",
      "8k 6.5%\n"
     ]
    }
   ],
   "source": [
    "for split in split_names:\n",
    "    path_orig = f\"./test_res/unsloth/Llama-3.2-1B-Instruct/vanilla_armt-1b-it-v2/qa1_{split}_instruction_yes_examples_yes_post_prompt_yes_chat_template_yes.csv\"\n",
    "    path_opt = f\"./test_res/unsloth/Llama-3.2-1B-Instruct/mem_code_fix_executor_mem_patch_armt-1b-it-v2/qa1_{split}_instruction_yes_examples_yes_post_prompt_yes_chat_template_yes.csv\"\n",
    "    orig_answers = pd.read_csv(path_orig)[\"output\"]\n",
    "    opt_answers = pd.read_csv(path_opt)[\"output\"]\n",
    "    scores = []\n",
    "    for orig, opt in zip(orig_answers, opt_answers):\n",
    "        scores.append(compare_generated_ids(orig, opt, tokenizer))\n",
    "    print(split, f\"{np.round(np.mean(scores)*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda_rmt_it_venv]",
   "language": "python",
   "name": "conda-env-conda_rmt_it_venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
