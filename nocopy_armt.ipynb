{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956207bd-c572-4554-bdf9-65b313e7ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jovyan/shares/SR006.nfs1/sivtsov/armt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0951666e-ff46-405e-89ea-ec5aec422244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fdfdd544710>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31b622f-b851-456e-8bc0-064d643156c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from group_gemm import group_gemm_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c50488ed-a4e4-4c5e-bfd1-da8f32f162cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_dim = 512\n",
    "segment_size = 128\n",
    "mem_size = 128\n",
    "\n",
    "proj_dim = hid_dim\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0ba132-1abc-4fb0-b6cb-f9d48b9006f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = torch.rand((mem_size, hid_dim), device=device, dtype=torch.float32)\n",
    "prev_segment = torch.rand((segment_size, hid_dim), device=device, dtype=torch.float32)\n",
    "segment = torch.rand((segment_size, hid_dim), device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aebf063d-e9e0-47f4-be4d-07f7874f7a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_proj = torch.rand((hid_dim, proj_dim), device=device, dtype=torch.float32)\n",
    "k_proj = torch.rand((hid_dim, proj_dim), device=device, dtype=torch.float32)\n",
    "v_proj = torch.rand((hid_dim, hid_dim), device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa648d0b-d904-4856-a003-6427181188c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_ref = torch.concat([memory, segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52904c33-b4b8-43fa-851f-4088cee94ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = concated_ref @ q_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab4e844d-d41f-4a0d-8320-c17ce3a844c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[129.8166, 133.8074, 119.1817,  ..., 127.0881, 127.8358, 122.8069],\n",
       "        [121.9021, 125.1182, 115.5519,  ..., 125.2113, 121.3747, 120.9387],\n",
       "        [129.3303, 129.0235, 118.8091,  ..., 126.3715, 126.9246, 122.2639],\n",
       "        ...,\n",
       "        [126.2679, 131.9058, 116.8035,  ..., 121.5519, 122.8329, 120.3719],\n",
       "        [128.5999, 129.5410, 116.9284,  ..., 125.7963, 123.7666, 121.1420],\n",
       "        [122.5388, 132.4052, 121.2210,  ..., 129.2840, 129.2532, 120.6156]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7294b228-f4fa-4771-b47b-37978ac1f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_list = group_gemm_fn([memory, segment], [q_proj, q_proj])\n",
    "k_list = group_gemm_fn([memory, segment], [k_proj, k_proj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4227481-acbf-4155-9695-9939fa2bb1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ([0, 0, 1, 1], [0, 1, 0, 1])\n",
    "\n",
    "q_attn_mul = [q_list[i] for i in range(len(q_list)) for j in range(len(k_list))]\n",
    "k_tr_attn_mul = [k_list[j].T.contiguous() for i in range(len(q_list)) for j in range(len(k_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1d4cd0b-e476-46fd-89c3-6a3363b05fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([128, 512]),\n",
       "  torch.Size([128, 512]),\n",
       "  torch.Size([128, 512]),\n",
       "  torch.Size([128, 512])],\n",
       " [torch.Size([512, 128]),\n",
       "  torch.Size([512, 128]),\n",
       "  torch.Size([512, 128]),\n",
       "  torch.Size([512, 128])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[bl.shape for bl in q_attn_mul], [bl.shape for bl in k_tr_attn_mul]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "232a6a37-0009-40c4-a00a-f626faee02dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rowwise attention\n",
    "attn_list = group_gemm_fn(q_attn_mul, k_tr_attn_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de2c6783-edc0-4ad7-b2ba-368ecc2d717d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([128, 128]),\n",
       " torch.Size([128, 128]),\n",
       " torch.Size([128, 128]),\n",
       " torch.Size([128, 128])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[bl.shape for bl in attn_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1537bb-ec2c-4007-92ae-2ed2d8b10499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2146c99-3083-4d1f-b642-b22e311546f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for aligning\n",
    "attn_list = [100*a/a.mean() for a in attn_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46474aa4-8407-4aed-9d19-aee080d1106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_list_matr = [attn_list[i:i+2] for i in range(0, 4, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e625bc17-d22a-4156-b90f-60acb468899f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[torch.Size([128, 128]), torch.Size([128, 128])],\n",
       " [torch.Size([128, 128]), torch.Size([128, 128])]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[bl.shape for bl in row] for row in attn_list_matr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "199c2188-6b80-4944-8118-c62c4a5892ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_softmax(x):\n",
    "    \"\"\"Compute row-wise softmax of X using native pytorch\n",
    "\n",
    "    We subtract the maximum element in order to avoid overflows. Softmax is invariant to\n",
    "    this shift.\n",
    "    \"\"\"\n",
    "    # read  MN elements ; write M  elements\n",
    "    x_max = x.max(dim=1)[0]\n",
    "    # read MN + M elements ; write MN elements\n",
    "    z = x - x_max[:, None]\n",
    "    # read  MN elements ; write MN elements\n",
    "    numerator = torch.exp(z)\n",
    "    # read  MN elements ; write M  elements\n",
    "    denominator = numerator.sum(dim=1)\n",
    "    # read MN + M elements ; write MN elements\n",
    "    ret = numerator / denominator[:, None]\n",
    "    # in total: read 5MN + 2M elements ; wrote 3MN + 2M elements\n",
    "    return ret\n",
    "\n",
    "def concat_block_matr(matr):\n",
    "    return torch.concat(\n",
    "        [torch.concat(el, dim=1) for el in matr], \n",
    "        dim=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56c24a28-6ee6-4831-98b0-f07f82637137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "def block_softmax(x_matr):\n",
    "    \"\"\"Compute row-wise softmax of X using native pytorch\n",
    "\n",
    "    We subtract the maximum element in order to avoid overflows. Softmax is invariant to\n",
    "    this shift.\n",
    "    \"\"\"\n",
    "    # read  MN elements ; write M  elements\n",
    "    block_max_matr = [[bl.max(dim=1)[0] for bl in row] for row in x_matr]\n",
    "    x_max_matr = [reduce(lambda x,y: torch.max(x,y), row) for row in block_max_matr]\n",
    "    # read MN + M elements ; write MN elements\n",
    "    z_matr = [[block-max_row[:, None] for block in row] for row, max_row in zip(x_matr, x_max_matr)]\n",
    "    # read  MN elements ; write MN elements\n",
    "    numerator_matr = [[torch.exp(bl) for bl in row] for row in z_matr]\n",
    "    # read  MN elements ; write M  elements\n",
    "    denominator_vec = [sum([bl.sum(dim=1) for bl in row]) for row in numerator_matr]\n",
    "    # read MN + M elements ; write MN elements\n",
    "    ret_matr = [[bl / denom_bl[:, None] for bl in row] for row, denom_bl in zip(numerator_matr, denominator_vec)]\n",
    "    # in total: read 5MN + 2M elements ; wrote 3MN + 2M elements\n",
    "    return ret_matr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ca71d20-3696-455b-a822-b62fda26c1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[torch.Size([128, 128]), torch.Size([128, 128])],\n",
       " [torch.Size([128, 128]), torch.Size([128, 128])]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[bl.shape for bl in row] for row in attn_list_matr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77242ef7-a0de-4cfd-947b-d549b5cc897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_impl = block_softmax(attn_list_matr)\n",
    "concat_impl = naive_softmax(concat_block_matr(attn_list_matr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "911a1868-6e03-4bd5-b6ee-24da099df8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(concat_block_matr(block_impl), concat_impl, atol=1e-2, rtol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "516d5507-78cc-49aa-bbe7-ec0d270dd664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3.1463e-04, 2.9836e-06, 5.5897e-05,  ..., 6.8722e-06, 5.2913e-05,\n",
       "          1.3089e-04],\n",
       "         [3.8445e-04, 4.5194e-06, 7.3921e-05,  ..., 1.0048e-05, 7.0312e-05,\n",
       "          1.6648e-04],\n",
       "         [3.3720e-04, 3.4580e-06, 6.1579e-05,  ..., 7.8434e-06, 5.8520e-05,\n",
       "          1.4254e-04],\n",
       "         ...,\n",
       "         [3.6734e-04, 4.1386e-06, 6.9611e-05,  ..., 9.2297e-06, 6.6116e-05,\n",
       "          1.5825e-04],\n",
       "         [3.3702e-04, 3.4340e-06, 6.1504e-05,  ..., 7.8204e-06, 5.8175e-05,\n",
       "          1.4222e-04],\n",
       "         [3.2280e-04, 3.1444e-06, 5.7867e-05,  ..., 7.2134e-06, 5.4843e-05,\n",
       "          1.3492e-04]], device='cuda:0'),\n",
       " tensor([[3.1463e-04, 2.9836e-06, 5.5897e-05,  ..., 6.8722e-06, 5.2913e-05,\n",
       "          1.3089e-04],\n",
       "         [3.8445e-04, 4.5194e-06, 7.3921e-05,  ..., 1.0048e-05, 7.0312e-05,\n",
       "          1.6648e-04],\n",
       "         [3.3720e-04, 3.4580e-06, 6.1579e-05,  ..., 7.8434e-06, 5.8520e-05,\n",
       "          1.4254e-04],\n",
       "         ...,\n",
       "         [3.6734e-04, 4.1386e-06, 6.9611e-05,  ..., 9.2297e-06, 6.6116e-05,\n",
       "          1.5825e-04],\n",
       "         [3.3702e-04, 3.4340e-06, 6.1504e-05,  ..., 7.8204e-06, 5.8175e-05,\n",
       "          1.4222e-04],\n",
       "         [3.2280e-04, 3.1444e-06, 5.7867e-05,  ..., 7.2134e-06, 5.4843e-05,\n",
       "          1.3492e-04]], device='cuda:0'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_block_matr(block_impl), concat_impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "956c2f95-33be-4d8c-af8b-1ea92de4a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_matr_on_vec(matr, vec):\n",
    "    assert len(matr[0]) == len(vec), \"be carefull, not implemented\"\n",
    "    result_acc = None # [torch.zeros_like(t) for t in vec]\n",
    "    \n",
    "    for i in range(len(vec)):\n",
    "        l = [row[i] for row in matr]\n",
    "        r = [vec[i] for _ in range(len(matr))]\n",
    "        \n",
    "        partial = group_gemm_fn(l, r)\n",
    "\n",
    "        if result_acc is None:\n",
    "            result_acc = partial\n",
    "        else:\n",
    "            result_acc = [acc + partial for acc, partial in zip(result_acc, partial)]\n",
    "\n",
    "    return result_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4852a08b-46c9-4d20-909e-50b97978f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_matr = block_softmax(attn_list_matr)\n",
    "attn_concat = concat_block_matr(attn_matr)\n",
    "\n",
    "# v_projdd\n",
    "v_mart = [memory, segment]\n",
    "v = torch.concat(v_mart)\n",
    "\n",
    "result_ref = attn_concat @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1226ee6-c9cc-4c48-b607-f04ae9fb8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_acc = multiply_matr_on_vec(attn_matr, v_mart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54c2ab30-ec9d-440f-a935-e490d5c308d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(torch.concat(result_acc), result_ref, atol=1e-2, rtol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a319d60-964e-4f47-b1c6-e051fa872ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.3752, 0.5069, 0.5463,  ..., 0.5801, 0.5423, 0.4103],\n",
       "         [0.3845, 0.5047, 0.5441,  ..., 0.5775, 0.5420, 0.4160],\n",
       "         [0.3785, 0.5061, 0.5454,  ..., 0.5792, 0.5422, 0.4122],\n",
       "         ...,\n",
       "         [0.3792, 0.5060, 0.5453,  ..., 0.5790, 0.5423, 0.4127],\n",
       "         [0.3712, 0.5079, 0.5472,  ..., 0.5811, 0.5424, 0.4078],\n",
       "         [0.3756, 0.5069, 0.5461,  ..., 0.5801, 0.5424, 0.4105]],\n",
       "        device='cuda:0'),\n",
       " tensor([[0.3770, 0.5064, 0.5457,  ..., 0.5796, 0.5423, 0.4114],\n",
       "         [0.3729, 0.5074, 0.5468,  ..., 0.5807, 0.5424, 0.4089],\n",
       "         [0.3709, 0.5079, 0.5473,  ..., 0.5812, 0.5424, 0.4076],\n",
       "         ...,\n",
       "         [0.3825, 0.5052, 0.5445,  ..., 0.5781, 0.5422, 0.4148],\n",
       "         [0.3784, 0.5061, 0.5454,  ..., 0.5793, 0.5421, 0.4121],\n",
       "         [0.3763, 0.5066, 0.5460,  ..., 0.5796, 0.5422, 0.4109]],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6cdbc7-7361-4683-9ff0-ddac90602eb7",
   "metadata": {},
   "source": [
    "### Generate input for layer\n",
    "\n",
    "inp - memory, prev_segment, segment   \n",
    "weights - q_proj, k_proj, v_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab8ad15b-5fe9-4f86-b208-8c8b3ea02e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_dim = 512\n",
    "segment_size = 128\n",
    "mem_size = 128\n",
    "\n",
    "proj_dim = hid_dim\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad637b9b-646b-46dc-8d19-7ba814587dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = torch.rand((mem_size, hid_dim), device=device, dtype=torch.float32)\n",
    "prev_segment = torch.rand((segment_size, hid_dim), device=device, dtype=torch.float32)\n",
    "segment = torch.rand((segment_size, hid_dim), device=device, dtype=torch.float32)\n",
    "\n",
    "q_proj = torch.rand((hid_dim, proj_dim), device=device, dtype=torch.float32)\n",
    "k_proj = torch.rand((hid_dim, proj_dim), device=device, dtype=torch.float32)\n",
    "v_proj = torch.rand((hid_dim, hid_dim), device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b779f77-043c-4ef3-900a-7c55cf3748fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ca53ea1-6ec3-4031-bb68-c7e1c7d5f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_list = group_gemm_fn([memory, segment], [q_proj, q_proj])\n",
    "k_list = group_gemm_fn([memory, segment], [k_proj, k_proj])\n",
    "v_list = group_gemm_fn([memory, segment], [v_proj, v_proj])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e61f27-4b0c-4f1f-9c64-fbd61d2e0661",
   "metadata": {},
   "source": [
    "### Generate blocked attention matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88a2f27b-0d5d-426b-86ec-cec49673cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [memory, segment] x [prev, memory, segment]\n",
    "ones_bl = torch.ones(())\n",
    "attn_mask_matr = [\n",
    "    [torch.zeros((mem_size, segment_size)), torch.ones((mem_size, mem_size)), torch.ones((mem_size, segment_size))],\n",
    "    [torch.ones((segment_size, segment_size)).triu(), torch.ones((segment_size, mem_size)), torch.ones((segment_size, segment_size)).tril()],\n",
    "]\n",
    "\n",
    "attn_mask_matr = [[bl.type(torch.bool).to(\"cuda\") for bl in row] for row in attn_mask_matr]\n",
    "\n",
    "# effectivelly, window size \"segment+1\", tune accordingly\n",
    "\n",
    "# 000 111 111\n",
    "# 000 111 111\n",
    "# 000 111 111\n",
    "\n",
    "# 111 111 100\n",
    "# 011 111 110\n",
    "# 001 111 111"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc1a28-5034-4d09-adfb-a6d1cd0fc95b",
   "metadata": {},
   "source": [
    "## Make simple armt attention with merging input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05309cbc-d081-4de1-8b23-5add5fd7de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMergeArmtAttention(nn.Module):\n",
    "    def __init__(self, k_proj, q_proj, v_proj):\n",
    "        self.k_proj = k_proj\n",
    "        self.q_proj = q_proj\n",
    "        self.v_proj = v_proj\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, segment, memory, prev_kv_proj = None, attn_mask = None):\n",
    "        memory_seq_len = memory.shape[-2]\n",
    "        segment_seq_len = segment.shape[-2]\n",
    "        \n",
    "        mem_segm_merged = torch.concat((memory, segment), dim=-2)\n",
    "\n",
    "        q = mem_segm_merged @ q_proj\n",
    "        k = mem_segm_merged @ k_proj\n",
    "        v = mem_segm_merged @ v_proj\n",
    "\n",
    "        if prev_kv_proj is not None:\n",
    "            prev_segment_proj_k, prev_segment_proj_v = prev_kv_proj\n",
    "            k = torch.concat((prev_segment_proj_k, k), dim=-2)\n",
    "            v = torch.concat((prev_segment_proj_v, v), dim=-2)\n",
    "\n",
    "        attn = q@k.T\n",
    "        dk = k.shape[-1]\n",
    "        attn = attn / dk**0.5\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            attn.masked_fill_(~attn_mask, -1e9)\n",
    "\n",
    "        attn = torch.softmax(attn, dim=-1)\n",
    "        out = attn @ v\n",
    "\n",
    "        out_segment = out[..., -segment_seq_len:, :]\n",
    "        out_memory = out[..., -segment_seq_len-memory_seq_len:-segment_seq_len, :]\n",
    "\n",
    "        cache_k_activation = k[..., -segment_seq_len:, :]\n",
    "        cache_v_activation = v[..., -segment_seq_len:, :]\n",
    "        return out_segment, out_memory, [cache_k_activation, cache_v_activation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0467062e-1fb2-4c2d-8e1b-5043903bd50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask = concat_block_matr(attn_mask_matr)\n",
    "attn_mask_matr_first = [el[1:] for el in attn_mask_matr]\n",
    "attn_mask_first = concat_block_matr(attn_mask_matr_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "194a8597-a991-4fe5-9eba-362aa4b3c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_armt = SimpleMergeArmtAttention(k_proj, q_proj, v_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a0b6891-a998-4b22-b532-a3de529a24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_segment, out_memory, segm_kv = simple_armt(segment, memory, prev_kv_proj = None, attn_mask = attn_mask_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "275cf5d0-c0e2-4b06-817c-f87476c53a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_segment, out_memory, segm_kv  = simple_armt(segment, out_memory, prev_kv_proj = segm_kv, attn_mask = attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d88ba-7261-4fed-8468-16c442d0fcf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ceef9eaa-8749-4f12-b922-a5706602e4b2",
   "metadata": {},
   "source": [
    "## Make group gemm armt attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c192bfd4-9549-43ea-be14-2356153bd5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84afa5d4-86f6-45a5-8d8e-121fcd8a4ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_tensor_mask(mask_matr, tensor_mask):\n",
    "    return [\n",
    "        [torch.where(mask_bl, tensor_bl, -torch.inf) for mask_bl, tensor_bl in zip(mask_row, tensor_row)]\n",
    "        for mask_row, tensor_row in zip(mask_matr, tensor_mask)       \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd534d-5b8e-4f95-aa0b-b18c31d6a233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c90cc438-0bd1-4c64-9a6c-d13f7fdf5e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArmtAttention(nn.Module):\n",
    "    def __init__(self, k_proj, q_proj, v_proj):\n",
    "        self.k_proj = k_proj\n",
    "        self.q_proj = q_proj\n",
    "        self.v_proj = v_proj\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, segment, memory, prev_kv_proj = None, attn_mask_matr = None):\n",
    "        \"\"\"\n",
    "        There are no concatenation or excess copy (probably some because of implementation, like contiguous, but...)\n",
    "        It handles all matrix multiplication as grouped one without explicit torch.concat\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply projections\n",
    "        q_list = group_gemm_fn([memory, segment], [self.q_proj, self.q_proj])\n",
    "        k_list = group_gemm_fn([memory, segment], [self.k_proj, self.k_proj])\n",
    "        v_list = group_gemm_fn([memory, segment], [self.v_proj, self.v_proj])\n",
    "\n",
    "        # if not first, then concat projected KV from previous iteration\n",
    "        if prev_kv_proj is not None:\n",
    "            prev_segment_proj_k, prev_segment_proj_v = prev_kv_proj\n",
    "            k_list = [prev_segment_proj_k, ] + k_list\n",
    "            v_list = [prev_segment_proj_v, ] + v_list\n",
    "\n",
    "        # Q@K.T but in grouped format\n",
    "        q_attn_mul = [q_list[i] for i in range(len(q_list)) for j in range(len(k_list))]\n",
    "        k_tr_attn_mul = [\n",
    "            k_list[j].T.contiguous() # this implementation of group_gemm faulty if memory is not contiguous\n",
    "            for i in range(len(q_list)) for j in range(len(k_list))\n",
    "        ]\n",
    "        \n",
    "        attn_list = group_gemm_fn(q_attn_mul, k_tr_attn_mul)\n",
    "\n",
    "        # Reshape result of Q@K.T to matrix \n",
    "        blocks_in_row = len(k_list)\n",
    "        rows_total = len(q_list)\n",
    "        attn_list_matr = [attn_list[i:i+blocks_in_row] for i in range(0, blocks_in_row*rows_total, blocks_in_row)]\n",
    "\n",
    "        # Scale\n",
    "        # scale = (attn_list_matr[0][0].shape[-1]) ** 0.5\n",
    "        scale = (k_list[0][0].shape[-1]) ** 0.5\n",
    "        attn_list_matr = [[bl/scale for bl in row] for row in attn_list_matr]\n",
    "\n",
    "        # Mask. Note, mask is also tiled\n",
    "        if attn_mask_matr is not None:\n",
    "            attn_list_matr = group_tensor_mask(attn_mask_matr, attn_list_matr)\n",
    "                \n",
    "        # Softmax\n",
    "        attn_matr_softmax = block_softmax(attn_list_matr)\n",
    "\n",
    "        # get block output\n",
    "        result = multiply_matr_on_vec(attn_matr_softmax, v_list)\n",
    "\n",
    "        # return result and projection of current segment for next iteration\n",
    "        return result[1], result[0], [k_list[-1], v_list[-1]]\n",
    "\n",
    "    def backward(self, grad):\n",
    "        raise Exception(\"For now not implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03d906aa-ca6d-4c5e-89df-f9fb5ebfda2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = ArmtAttention(k_proj, q_proj, v_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2b16860-9e2d-4c86-980a-59afe8e87068",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask_matr_first = [\n",
    "    row[1:] for row in attn_mask_matr\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d873de41-bde0-423d-8e0a-42099ddcf580",
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_out_matr, mem_out_matr, segm_kv_matr = layer(segment, memory, attn_mask_matr=attn_mask_matr_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36e23e2e-5af6-4505-b24a-e57ed704b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_out_matr2, kv_segment2, segm_kv_matr_1 = layer(segment, mem_out_matr, prev_kv_proj=segm_kv_matr, attn_mask_matr=attn_mask_matr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb46d9-7bc3-4292-b0f1-e2f3fa074743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce61068-ff41-4ef2-964f-85e0627af859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90700afd-ac9d-4da9-ada6-cd87459d23f0",
   "metadata": {},
   "source": [
    "## Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e73f1b82-22bb-43bd-84c8-c633db427f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_dim = 4096\n",
    "segment_size = 128\n",
    "mem_size = 64\n",
    "\n",
    "proj_dim = hid_dim\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "memory = torch.rand((mem_size, hid_dim), device=device, dtype=torch.float32)\n",
    "prev_segment = torch.rand((segment_size, hid_dim), device=device, dtype=torch.float32)\n",
    "segment = torch.rand((segment_size, hid_dim), device=device, dtype=torch.float32)\n",
    "\n",
    "q_proj = torch.rand((hid_dim, proj_dim), device=device, dtype=torch.float32)\n",
    "k_proj = torch.rand((hid_dim, proj_dim), device=device, dtype=torch.float32)\n",
    "v_proj = torch.rand((hid_dim, hid_dim), device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "23f706d6-a45c-4ee1-83c9-b210f10f3554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 128, 64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hid_dim, segment_size, mem_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "72005aa4-581c-4f72-a76a-8cf47c7c2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_bl = torch.ones(())\n",
    "attn_mask_matr = [\n",
    "    [torch.zeros((mem_size, segment_size)), torch.ones((mem_size, mem_size)), torch.ones((mem_size, segment_size))],\n",
    "    [torch.ones((segment_size, segment_size)).triu(), torch.ones((segment_size, mem_size)), torch.ones((segment_size, segment_size)).tril()],\n",
    "]\n",
    "\n",
    "attn_mask_matr = [[bl.type(torch.bool).to(\"cuda\") for bl in row] for row in attn_mask_matr]\n",
    "attn_mask_matr_first = [row[1:] for row in attn_mask_matr]\n",
    "\n",
    "attn_mask = concat_block_matr(attn_mask_matr)\n",
    "attn_mask_first = concat_block_matr(attn_mask_matr_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6bef483a-472e-47cb-bf5b-a6da0f6de413",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_armt = SimpleMergeArmtAttention(k_proj, q_proj, v_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6248a790-9fbd-4b86-a2cd-571083f67e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.64 ms, sys: 172 μs, total: 2.81 ms\n",
      "Wall time: 2.17 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "out_segment, out_memory, segm_kv = simple_armt(segment, memory, prev_kv_proj = None, attn_mask = attn_mask_first)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43fcf88e-847f-4b6e-9215-505aacb03b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.51 ms, sys: 4 μs, total: 2.52 ms\n",
      "Wall time: 1.98 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "out_segment, out_memory, segm_kv  = simple_armt(segment, out_memory, prev_kv_proj = segm_kv, attn_mask = attn_mask)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ab7f9725-18eb-4eaa-ae32-b82f6fa04603",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters_measure = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1ec9d292-5240-4cca-b149-2a76ed27847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9e0729d9-f1d7-474e-a623-c2167f5d8d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(n_iters_measure):\n",
    "    out_segment, out_memory, segm_kv  = simple_armt(segment, out_memory, prev_kv_proj = segm_kv, attn_mask = attn_mask)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "26a981c1-a427-4ffc-9b90-5a276eeb1a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.5942347049713135, 0.0015314115683237712)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end-start, (end-start)/n_iters_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f98b3-605c-44b6-815a-75355ee6ee98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f77cc-240d-4c8e-9d9e-f177e92a029e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d21bdc59-47e4-47e2-af68-7d6c542c3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = ArmtAttention(k_proj, q_proj, v_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dc475f6d-bbb1-4ef4-8e9a-de81d76765b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.58 ms, sys: 90 μs, total: 4.67 ms\n",
      "Wall time: 4.53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "segm_out_matr, mem_out_matr, segm_kv_matr = layer(segment, memory, attn_mask_matr=attn_mask_matr_first)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "550dae45-9bdc-4159-9ef8-07c98d7cb362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.53 ms, sys: 82 μs, total: 4.62 ms\n",
      "Wall time: 4.46 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "segm_out_matr, mem_out_matr, segm_kv_matr = layer(segment, mem_out_matr, prev_kv_proj=segm_kv_matr, attn_mask_matr=attn_mask_matr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "950727ce-74d9-4b50-ae78-c7a67798e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(n_iters_measure):\n",
    "    segm_out_matr, mem_out_matr, segm_kv_matr = layer(segment, mem_out_matr, prev_kv_proj=segm_kv_matr, attn_mask_matr=attn_mask_matr)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e48b97dd-6c39-4349-895b-560bb0391a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.51606798171997, 0.0041720226605733235)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end-start, (end-start)/n_iters_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f0ab73-5a7e-4a89-bff2-a03db38c5924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c6a73-6ef7-43dd-ae3d-c8ef37fd10fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4d7c8a61-1ae0-4179-befe-e44aef222efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8cdcbeb7-7a3b-4dcd-a80f-92e00a5f921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters_bench = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c40f4d3e-ebc0-4541-aa17-1c22ea39698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True, with_stack=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        for i in range(n_iters_bench):\n",
    "            out_segment, out_memory, segm_kv  = simple_armt(segment, out_memory, prev_kv_proj = segm_kv, attn_mask = attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f985d886-ab79-4b13-acb3-cc2a63acfd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      60.074ms       102.10%      60.074ms      60.074ms             1  \n",
      "                                        model_inference         8.46%       5.329ms        33.44%      21.075ms      21.075ms       0.000us         0.00%      58.836ms      58.836ms             1  \n",
      "                                           aten::matmul         0.72%     453.610us         8.58%       5.410ms      27.052us       0.000us         0.00%      57.407ms     287.035us           200  \n",
      "                                               aten::mm         5.08%       3.204ms         7.87%       4.957ms      24.784us      57.407ms        97.57%      57.407ms     287.035us           200  \n",
      "                       ampere_sgemm_128x32_sliced1x4_nn         0.00%       0.000us         0.00%       0.000us       0.000us      53.400ms        90.76%      53.400ms     444.999us           120  \n",
      "                        ampere_sgemm_32x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.954ms         3.32%       1.954ms      48.845us            40  \n",
      "                                 ampere_sgemm_128x32_nn         0.00%       0.000us         0.00%       0.000us       0.000us       1.643ms         2.79%       1.643ms      41.084us            40  \n",
      "                                           aten::concat         0.47%     299.195us         8.79%       5.542ms      46.180us       0.000us         0.00%     912.541us       7.605us           120  \n",
      "                                              aten::cat         4.96%       3.127ms         8.32%       5.242ms      43.687us     912.541us         1.55%     912.541us       7.605us           120  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     912.541us         1.55%     912.541us       7.605us           120  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     248.896us         0.42%     248.896us       2.074us           120  \n",
      "                                          aten::softmax         0.16%      99.867us         1.21%     761.010us      19.025us       0.000us         0.00%     203.745us       5.094us            40  \n",
      "                                         aten::_softmax         0.72%     456.375us         1.05%     661.143us      16.529us     203.745us         0.35%     203.745us       5.094us            40  \n",
      "void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us     203.745us         0.35%     203.745us       5.094us            40  \n",
      "void splitKreduce_kernel<32, 16, int, float, float, ...         0.00%       0.000us         0.00%       0.000us       0.000us     161.022us         0.27%     161.022us       4.026us            40  \n",
      "                                      aten::bitwise_not         0.76%     479.640us         1.09%     687.001us      17.175us     112.160us         0.19%     112.160us       2.804us            40  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     112.160us         0.19%     112.160us       2.804us            40  \n",
      "                                     aten::masked_fill_         0.57%     362.275us         0.92%     578.978us      14.474us     100.416us         0.17%     100.416us       2.510us            40  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     100.416us         0.17%     100.416us       2.510us            40  \n",
      "                                              aten::div         1.03%     646.958us         1.38%     866.667us      21.667us     100.031us         0.17%     100.031us       2.501us            40  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 63.023ms\n",
      "Self CUDA time total: 58.836ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "31ffce38-d88c-46b5-9792-a18cae165272",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_by_keyword = \"self_\" + device + \"_time_total\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ecf44ce1-33e6-4e54-b6eb-2dfe76110ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us      60.074ms       102.10%      60.074ms      60.074ms             1  \n",
      "                                               aten::mm         5.08%       3.204ms         7.87%       4.957ms      24.784us      57.407ms        97.57%      57.407ms     287.035us           200  \n",
      "                       ampere_sgemm_128x32_sliced1x4_nn         0.00%       0.000us         0.00%       0.000us       0.000us      53.400ms        90.76%      53.400ms     444.999us           120  \n",
      "                        ampere_sgemm_32x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.954ms         3.32%       1.954ms      48.845us            40  \n",
      "                                 ampere_sgemm_128x32_nn         0.00%       0.000us         0.00%       0.000us       0.000us       1.643ms         2.79%       1.643ms      41.084us            40  \n",
      "                                              aten::cat         4.96%       3.127ms         8.32%       5.242ms      43.687us     912.541us         1.55%     912.541us       7.605us           120  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     912.541us         1.55%     912.541us       7.605us           120  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     248.896us         0.42%     248.896us       2.074us           120  \n",
      "                                         aten::_softmax         0.72%     456.375us         1.05%     661.143us      16.529us     203.745us         0.35%     203.745us       5.094us            40  \n",
      "void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us     203.745us         0.35%     203.745us       5.094us            40  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 63.023ms\n",
      "Self CUDA time total: 58.836ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with_stack=True,\n",
    "# Print aggregated stats\n",
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by=sort_by_keyword, row_limit=10))\n",
    "\n",
    "prof.export_chrome_trace(\"/home/jovyan/sivtsov/armt/simple_armt_trace_onelayer_4096_128_64.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289a126-b3bc-444b-b579-9b394cc2959a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf999b-e940-4cb5-8a67-7cd7ec1ef632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5a3f7-0743-4827-9b18-ba59a6bf2ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d4766fc9-fd15-430d-a70c-6c1e7988af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], with_stack=True, record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        for i in range(n_iters_bench):\n",
    "            segm_out_matr, mem_out_matr, segm_kv_matr = layer(\n",
    "                segment, mem_out_matr, prev_kv_proj=segm_kv_matr, attn_mask_matr=attn_mask_matr\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f86aa8ab-b377-42ed-9342-e12f3d1ed595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us     245.721ms       283.83%     245.721ms     245.721ms             1  \n",
      "                                  grouped_matmul_kernel         0.00%       0.000us         0.00%       0.000us       0.000us      75.015ms        86.65%      75.015ms     267.910us           280  \n",
      "                                            aten::copy_         3.68%       9.124ms        29.50%      73.196ms      44.632us       3.754ms         4.34%       3.754ms       2.289us          1640  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       2.015ms         2.33%       2.015ms       8.394us           240  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       1.739ms         2.01%       1.739ms       1.242us          1400  \n",
      "                                              aten::div         2.10%       5.213ms         3.15%       7.814ms      16.280us       1.424ms         1.64%       1.424ms       2.966us           480  \n",
      "                                              aten::max         2.14%       5.301ms         3.76%       9.337ms      23.343us       1.397ms         1.61%       1.670ms       4.174us           400  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.397ms         1.61%       1.397ms       5.821us           240  \n",
      "                                              aten::sum         1.49%       3.693ms         2.09%       5.192ms      21.632us       1.124ms         1.30%       1.124ms       4.683us           240  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.124ms         1.30%       1.124ms       4.683us           240  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 248.123ms\n",
      "Self CUDA time total: 86.574ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print aggregated stats\n",
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by=sort_by_keyword, row_limit=10))\n",
    "\n",
    "prof.export_chrome_trace(\"/home/jovyan/sivtsov/armt/nocopy_armt_trace_onelayer_4096_128_64.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1506a2-40ef-4d79-9b39-889111fcc9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b0d741-fab3-4418-a7fe-ca5ee6c55b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "5a1cd50b-d8e7-4d4a-ab22-26beb03675ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_dim = 512\n",
    "segment_size = 128\n",
    "mem_size = 32\n",
    "\n",
    "proj_dim = hid_dim\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "segment = torch.rand((segment_size, hid_dim), device=device, dtype=torch.float32)\n",
    "q_proj = torch.rand((hid_dim, proj_dim), device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0aef4761-0830-4986-b478-394f752992c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mults_at_once = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "277397b7-8627-4291-8920-93f69ed5ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inps_dups = [torch.rand((segment_size, hid_dim), device=device, dtype=torch.float32) for i in range(n_mults_at_once)]\n",
    "outs = [None for i in range(n_mults_at_once)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dd9d281f-2e44-4f35-b9ab-46017229a85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.56 ms, sys: 0 ns, total: 2.56 ms\n",
      "Wall time: 2.13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(len(inps_dups)):\n",
    "    o = inps_dups[i] @ q_proj\n",
    "    outs[i] = o\n",
    "\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ea1412b4-3d67-46fa-a003-c9e6e819bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = [q_proj for i in range(len(inps_dups))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "04197e55-3a28-4c84-88f7-b57d0a177e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.3 ms, sys: 0 ns, total: 2.3 ms\n",
      "Wall time: 2.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "outs = group_gemm_fn(inps_dups, ws)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e206984-ac49-4b9f-96a7-6ce84a4233fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09eeeaa-9b23-45da-ad23-73725e1781ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-svtdanny]",
   "language": "python",
   "name": "conda-env-.mlspace-svtdanny-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
