{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3374c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot lines y = line_slope * x + line_bias for each row in df_scaled_fit\n",
    "# Colors:\n",
    "# - Names containing \"Diagonal Batching\": green\n",
    "# - Names containing \"armt\" and not \"Diagonal Batching\": blue\n",
    "# - All others: gray\n",
    "# Model names are annotated to the right of each line.\n",
    "\n",
    "# Ensure the DataFrame exists\n",
    "try:\n",
    "    df = df_scaled_fit.copy()\n",
    "except NameError as exc:\n",
    "    raise NameError(\"df_scaled_fit is not defined in the current notebook scope.\") from exc\n",
    "\n",
    "required_cols = {\"line_slope\", \"line_bias\"}\n",
    "missing = required_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise KeyError(f\"df_scaled_fit is missing required columns: {missing}\")\n",
    "\n",
    "# Try to find a model/name column for annotation\n",
    "name_col = None\n",
    "for candidate in [\"model_name\", \"model\", \"name\", \"Model\", \"Model Name\"]:\n",
    "    if candidate in df.columns:\n",
    "        name_col = candidate\n",
    "        break\n",
    "if name_col is None:\n",
    "    candidates = [c for c in df.columns if (\"model\" in c.lower()) or (\"name\" in c.lower())]\n",
    "    if candidates:\n",
    "        name_col = candidates[0]\n",
    "    else:\n",
    "        # Fallback to using the index as a name\n",
    "        df = df.assign(__name__=df.index.astype(str))\n",
    "        name_col = \"__name__\"\n",
    "\n",
    "# Determine y-limits based on y at x=0 and x=1 to keep lines visible\n",
    "y_at_0 = df[\"line_bias\"].to_numpy()\n",
    "# y(1) = slope * 1 + bias\n",
    "y_at_1 = (df[\"line_slope\"].to_numpy() + df[\"line_bias\"].to_numpy())\n",
    "all_y = np.concatenate([y_at_0, y_at_1])\n",
    "y_min = np.nanmin(all_y) if all_y.size else 0.0\n",
    "y_max = np.nanmax(all_y) if all_y.size else 1.0\n",
    "y_span = (y_max - y_min) if np.isfinite(y_max - y_min) else 1.0\n",
    "margin = 0.05 * y_span if y_span > 0 else 0.5\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, max(4, min(12, 0.35 * len(df)))))\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    slope = float(row[\"line_slope\"])\n",
    "    bias = float(row[\"line_bias\"])\n",
    "    name = str(row[name_col])\n",
    "    lower_name = name.lower()\n",
    "\n",
    "    if \"diagonal batching\" in lower_name:\n",
    "        color = \"green\"\n",
    "    elif \"armt\" in lower_name:\n",
    "        color = \"blue\"\n",
    "    else:\n",
    "        color = \"gray\"\n",
    "\n",
    "    x_vals = np.array([0.0, 1.0])\n",
    "    y_vals = slope * x_vals + bias\n",
    "    ax.plot(x_vals, y_vals, color=color, linewidth=2, alpha=0.9)\n",
    "\n",
    "    # Place label slightly to the right of x=1 using data coordinates\n",
    "    y_right = slope * 1.0 + bias\n",
    "    ax.text(1.02, y_right, name, color=color, va=\"center\", ha=\"left\", fontsize=9)\n",
    "\n",
    "ax.set_xlim(0.0, 1.15)\n",
    "ax.set_ylim(y_min - margin, y_max + margin)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y = slope * x + bias\")\n",
    "ax.set_title(\"Lines from df_scaled_fit (color-coded by model name)\")\n",
    "ax.grid(True, linestyle=\":\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b74909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebaa715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_all.csv\n",
      "result_fla-hub__rwkv7-0.4B-world.csv\n",
      "result_fla-hub__rwkv7-0.4B-world_torch.bfloat16.csv\n",
      "result_fla-hub__rwkv7-1.5B-world.csv\n",
      "result_fla-hub__rwkv7-1.5B-world_torch.bfloat16.csv\n",
      "result_fla-hub__rwkv7-2.9B-world.csv\n",
      "result_fla-hub__rwkv7-2.9B-world_torch.bfloat16.csv\n",
      "result_state-spaces__mamba-1.4b-hf_torch.bfloat16.csv\n",
      "result_state-spaces__mamba-1.4b-hf_torch.float32.csv\n",
      "result_state-spaces__mamba-2.8b-hf_torch.bfloat16.csv\n",
      "result_state-spaces__mamba-2.8b-hf_torch.float32.csv\n",
      "result_state-spaces__mamba-370m-hf_torch.bfloat16.csv\n",
      "result_state-spaces__mamba-370m-hf_torch.float32.csv\n",
      "result_state-spaces__mamba-790m-hf_torch.bfloat16.csv\n",
      "result_state-spaces__mamba-790m-hf_torch.float32.csv\n"
     ]
    }
   ],
   "source": [
    "!ls *csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781dd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c46fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dfs_paths = [f for f in os.listdir('/home/jovyan/sivtsov/diagonal-batching/linear_comparision') \n",
    "             if f.endswith('.csv') and 'result_all' not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a2f268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee3b821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2001520/363832592.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_all = pd.concat([df_all, pd.DataFrame([append_row])], ignore_index=True)\n",
      "/tmp/ipykernel_2001520/363832592.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_all = pd.concat([df_all, pd.DataFrame([append_row])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.DataFrame(columns=['model', 'dtype', 4096, 8192, 12288, 16384, 24576, 32768, 65536])\n",
    "\n",
    "for p in dfs_paths:\n",
    "    df = pd.read_csv(p)\n",
    "    \n",
    "    if \"float\" in p:\n",
    "        model_name = p.rsplit('_', 1)[-2]\n",
    "        dtype_used = p.split('.')[-2]\n",
    "    else:\n",
    "        model_name = p.rsplit('.', 1)[-2]\n",
    "        dtype_used = \"float32\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df_use = df[df['is_warmup'] == False]\n",
    "    df_use = df_use[df_use['iter'] > 0]\n",
    "    \n",
    "    df_agg = df_use.groupby('input_size').agg({'time': 'mean'}).reset_index()\n",
    "    \n",
    "    append_row = {'model': model_name, 'dtype': dtype_used}\n",
    "    for i in df_agg['input_size']:\n",
    "        append_row[i] = df_agg[df_agg['input_size'] == i]['time'].iloc[0]\n",
    "    df_all = pd.concat([df_all, pd.DataFrame([append_row])], ignore_index=True)\n",
    "    \n",
    "# df_all.to_csv('result_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4120d3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dtype</th>\n",
       "      <th>4096</th>\n",
       "      <th>8192</th>\n",
       "      <th>12288</th>\n",
       "      <th>16384</th>\n",
       "      <th>24576</th>\n",
       "      <th>32768</th>\n",
       "      <th>65536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLama-3.2-1B-ARMT (512, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.290</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.861</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LLama-3.2-1B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.150</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LLama-3.2-1B-ARMT (2048, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LLama-3.2-1B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              model     dtype   4096   8192  \\\n",
       "0                                      Llama-3.2-1B  bfloat16  0.024  0.026   \n",
       "1                      LLama-3.2-1B-ARMT (512, 128)  bfloat16  0.147  0.574   \n",
       "2   Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)  bfloat16  0.283  0.248   \n",
       "3                     LLama-3.2-1B-ARMT (1024, 128)  bfloat16  0.149  0.291   \n",
       "4  Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)  bfloat16  0.119  0.196   \n",
       "5                     LLama-3.2-1B-ARMT (2048, 128)  bfloat16  0.094  0.177   \n",
       "6  Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)  bfloat16  0.108  0.176   \n",
       "7                     LLama-3.2-1B-ARMT (4096, 128)  bfloat16  0.082  0.155   \n",
       "8  Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)  bfloat16  0.102  0.172   \n",
       "\n",
       "   12288  16384  24576  32768  65536  \n",
       "0    NaN  0.376    NaN  0.926   2.46  \n",
       "1    NaN  1.150    NaN  2.290   4.52  \n",
       "2    NaN  0.454    NaN  0.861   1.67  \n",
       "3    NaN  0.578    NaN  1.150   2.30  \n",
       "4    NaN  0.351    NaN  0.656   1.27  \n",
       "5    NaN  0.344    NaN  0.679   1.35  \n",
       "6    NaN  0.304    NaN  0.571   1.11  \n",
       "7    NaN  0.301    NaN  0.594   1.18  \n",
       "8    NaN  0.295    NaN  0.553   1.07  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def parse_latex_table(latex_text):\n",
    "    \"\"\"\n",
    "    Parse a LaTeX table and extract performance data into a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        latex_text (str): LaTeX table text containing performance data\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns ['model', 'dtype', 4096, 8192, 12288, 16384, 24576, 32768, 65536]\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"^\\s*(?!\\\\)(?!.*Configuration)(?!.*toprule)(?!.*midrule)(?!.*bottomrule)(?!.*textbf)(?!.*cmidrule)(?!.*rowcolor)(.+?)\\s*&\\s*([0-9.]+)\\s*&\\s*([0-9.]+)\\s*&\\s*([0-9.]+)\\s*&\\s*([0-9.]+)\\s*&\\s*([0-9.]+)\\s*&\\s*([0-9.]+)\\s*\\\\\\\\\",\n",
    "                             flags=re.MULTILINE)\n",
    "\n",
    "    # Extract configuration pattern\n",
    "    config_pattern = re.compile(r\"Configuration:\\s*\\((\\d+),\\s*(\\d+)\\)\")\n",
    "\n",
    "    rows = []\n",
    "    current_config = \"\"\n",
    "\n",
    "    # Split text by lines and track configurations\n",
    "    lines = latex_text.split('\\n')\n",
    "    for line in lines:\n",
    "        # Check for configuration\n",
    "        config_match = config_pattern.search(line)\n",
    "        if config_match:\n",
    "            current_config = f\"({config_match.group(1)}, {config_match.group(2)})\"\n",
    "            continue\n",
    "        \n",
    "        # Check for data rows\n",
    "        match = pattern.match(line)\n",
    "        if match:\n",
    "            name = match.group(1).strip()\n",
    "            \n",
    "            # Add configuration to model name if we have one\n",
    "            if current_config and name != \"Llama-3.2-1B\":  # Don't add config to baseline\n",
    "                name = f\"{name} {current_config}\"\n",
    "            \n",
    "            v4096 = float(match.group(2))\n",
    "            v8192 = float(match.group(3))\n",
    "            v16384 = float(match.group(4))\n",
    "            v32768 = float(match.group(5))\n",
    "            v65536 = float(match.group(6))\n",
    "            v131072 = float(match.group(7))  # parsed but not used in requested columns\n",
    "            rows.append({\n",
    "                'model': name,\n",
    "                'dtype': 'bfloat16',\n",
    "                4096: v4096,\n",
    "                8192: v8192,\n",
    "                12288: np.nan,  # not present in table\n",
    "                16384: v16384,\n",
    "                24576: np.nan,  # not present in table\n",
    "                32768: v32768,\n",
    "                65536: v65536,\n",
    "            })\n",
    "\n",
    "    cols_out = ['model', 'dtype', 4096, 8192, 12288, 16384, 24576, 32768, 65536]\n",
    "    df_latex = pd.DataFrame(rows)[cols_out]\n",
    "    return df_latex\n",
    "\n",
    "latex_text = r\"\"\"\n",
    "\\begin{table}[h]\n",
    "  \\centering\n",
    "  \\renewcommand{\\arraystretch}{1.2}\n",
    "  \\resizebox{\\textwidth}{!}{%\n",
    "  \\begin{tabular}{l*{6}{S[table-format=3.3]}}\n",
    "  \\toprule\n",
    "  \\textbf{Method} & \\multicolumn{6}{c}{\\textbf{Sequence Length}} \\\\\n",
    "  \\cmidrule(lr){2-7}\n",
    "   & {\\textbf{4096}} & {\\textbf{8192}} & {\\textbf{16384}} & {\\textbf{32768}} & {\\textbf{65536}} & {\\textbf{131072}} \\\\\n",
    "  \\midrule\n",
    "  Llama-3.2-1B & 0.024 & 0.026 & 0.376 & 0.926 & 2.460 & 8.160 \\\\\n",
    "  \\rowcolor{gray!10} \\textbf{Configuration: (512, 128)} \\\\\n",
    "  LLama-3.2-1B-ARMT & 0.147 & 0.574 & 1.15 & 2.29 & 4.52 & 8.98 \\\\\n",
    "  Diagonal Batching: LLama-3.2-1B-ARMT & 0.283 & 0.248 & 0.454 & 0.861 & 1.67 & 3.3 \\\\\n",
    "  \\midrule\n",
    "  \\rowcolor{gray!10} \\textbf{Configuration: (1024, 128)} \\\\\n",
    "  LLama-3.2-1B-ARMT & 0.149 & 0.291 & 0.578 & 1.15 & 2.3 & 4.48 \\\\\n",
    "  Diagonal Batching: LLama-3.2-1B-ARMT & 0.119 & 0.196 & 0.351 & 0.656 & 1.27 & 2.48\\\\\n",
    "  \\midrule\n",
    "  \\rowcolor{gray!10} \\textbf{Configuration: (2048, 128)} \\\\\n",
    "  LLama-3.2-1B-ARMT & 0.094 & 0.177 & 0.344 & 0.679 & 1.35 & 2.68 \\\\\n",
    "  Diagonal Batching: LLama-3.2-1B-ARMT & 0.108 & 0.176 & 0.304 & 0.571 & 1.11 & 2.18 \\\\\n",
    "  \\midrule\n",
    "  \\rowcolor{gray!10} \\textbf{Configuration: (4096, 128)} \\\\\n",
    "  LLama-3.2-1B-ARMT & 0.082 & 0.155 & 0.301 & 0.594 & 1.18 & 2.35 \\\\\n",
    "  Diagonal Batching: LLama-3.2-1B-ARMT & 0.102 & 0.172 & 0.295 & 0.553 & 1.07 & 2.1 \\\\\n",
    "  \\bottomrule\n",
    "  \\end{tabular}%\n",
    "  }\n",
    "  \\caption{Diagonal batching allows to speed-up the execution for longer sequences - from 1.1 times to 2.7 times with respect to base ARMT for 131072 sequence length. Executor comparison of execution times (in seconds) for different methods across sequence lengths for Llama-3.2-1B. Configuration in format (segment_size, memory_tokens). Nvidia A100.}\n",
    "  \\label{tab:perf_comparison_llama1b}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "df_latex = parse_latex_table(latex_text)\n",
    "df_latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8669460c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dtype</th>\n",
       "      <th>4096</th>\n",
       "      <th>8192</th>\n",
       "      <th>12288</th>\n",
       "      <th>16384</th>\n",
       "      <th>24576</th>\n",
       "      <th>32768</th>\n",
       "      <th>65536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.95</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLama-3.2-3B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.02</td>\n",
       "      <td>4.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.58</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LLama-3.2-3B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.52</td>\n",
       "      <td>3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              model     dtype   4096   8192  \\\n",
       "0                                      Llama-3.2-3B  bfloat16  0.168  0.344   \n",
       "1                     LLama-3.2-3B-ARMT (1024, 128)  bfloat16  0.272  0.537   \n",
       "2  Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)  bfloat16  0.274  0.454   \n",
       "3                     LLama-3.2-3B-ARMT (4096, 128)  bfloat16  0.203  0.390   \n",
       "4  Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)  bfloat16  0.239  0.411   \n",
       "\n",
       "   12288  16384  24576  32768  65536  \n",
       "0    NaN  0.769    NaN   1.95   5.59  \n",
       "1    NaN  1.050    NaN   2.02   4.09  \n",
       "2    NaN  0.833    NaN   1.58   3.10  \n",
       "3    NaN  0.765    NaN   1.52   3.01  \n",
       "4    NaN  0.739    NaN   1.40   2.72  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latex_text_3b = r\"\"\"\n",
    "\\begin{table}[h]\n",
    "  \\centering\n",
    "  \\resizebox{\\textwidth}{!}{%\n",
    "  \\renewcommand{\\arraystretch}{1.2}\n",
    "  \\begin{tabular}{l*{6}{S[table-format=3.3]}}\n",
    "  \\toprule\n",
    "  \\textbf{Method} & \\multicolumn{6}{c}{\\textbf{Sequence Length}} \\\\\n",
    "  \\cmidrule(lr){2-7}\n",
    "   & {\\textbf{4096}} & {\\textbf{8192}} & {\\textbf{16384}} & {\\textbf{32768}} & {\\textbf{65536}} & {\\textbf{131072}} \\\\\n",
    "  \\midrule\n",
    "  Llama-3.2-3B & 0.168 & 0.344 & 0.769 & 1.95 & 5.59 & 18.2 \\\\\n",
    "  \\rowcolor{gray!10} \\textbf{Configuration: (1024, 128)} \\\\\n",
    "  LLama-3.2-3B-ARMT & 0.272 & 0.537 & 1.05 & 2.02 & 4.09 & 8.23 \\\\\n",
    "  Diagonal Batching: LLama-3.1-3B-ARMT & 0.274 & 0.454 & 0.833 & 1.58 & 3.1 & 6.14 \\\\\n",
    "  \\rowcolor{gray!10} \\textbf{Configuration: (4096, 128)} \\\\\n",
    "  LLama-3.2-3B-ARMT & 0.203 & 0.39 & 0.765 & 1.52 & 3.01 & 6.01 \\\\\n",
    "  Diagonal Batching: LLama-3.2-3B-ARMT & 0.239 & 0.411 & 0.739 & 1.4 & 2.72 & 5.37 \\\\\n",
    "  \\midrule\n",
    "  \\end{tabular}%\n",
    "  }\n",
    "  \\caption{Diagonal batching speed-ups the execution - from 1.1 to 1.3 times comparing to base ARMT for 131072 sequence length. Executor comparison of execution times (in seconds) for different methods across sequence lengths for Llama-3.2-3B. Configuration in format (segment\\_size, memory\\_tokens). Nvidia A100}\n",
    "  \\label{tab:perf_comparison_llama3b}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "df_latex_3b = parse_latex_table(latex_text_3b)\n",
    "df_latex_3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95265a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dtype</th>\n",
       "      <th>4096</th>\n",
       "      <th>8192</th>\n",
       "      <th>12288</th>\n",
       "      <th>16384</th>\n",
       "      <th>24576</th>\n",
       "      <th>32768</th>\n",
       "      <th>65536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-160M</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLama-160M-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.877</td>\n",
       "      <td>1.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diagonal Batching: LLama-160M-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LLama-160M-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diagonal Batching: LLama-160M-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            model     dtype   4096   8192  \\\n",
       "0                                      Llama-160M  bfloat16  0.017  0.033   \n",
       "1                     LLama-160M-ARMT (1024, 128)  bfloat16  0.105  0.211   \n",
       "2  Diagonal Batching: LLama-160M-ARMT (1024, 128)  bfloat16  0.061  0.087   \n",
       "3                     LLama-160M-ARMT (4096, 128)  bfloat16  0.031  0.057   \n",
       "4  Diagonal Batching: LLama-160M-ARMT (4096, 128)  bfloat16  0.046  0.062   \n",
       "\n",
       "   12288  16384  24576  32768  65536  \n",
       "0    NaN  0.075    NaN  0.196  0.594  \n",
       "1    NaN  0.422    NaN  0.877  1.720  \n",
       "2    NaN  0.138    NaN  0.243  0.451  \n",
       "3    NaN  0.111    NaN  0.216  0.432  \n",
       "4    NaN  0.094    NaN  0.156  0.284  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latex_text_160m = r\"\"\"\n",
    "\\begin{table}[h]\n",
    "  \\centering\n",
    "  \\renewcommand{\\arraystretch}{1.2}\n",
    "  \\resizebox{\\textwidth}{!}{%\n",
    "  \\begin{tabular}{l*{6}{S[table-format=3.3]}}\n",
    "  \\toprule\n",
    "  \\textbf{Method} & \\multicolumn{6}{c}{\\textbf{Sequence Length}} \\\\\n",
    "  \\cmidrule(lr){2-7}\n",
    "   & {\\textbf{4096}} & {\\textbf{8192}} & {\\textbf{16384}} & {\\textbf{32768}} & {\\textbf{65536}} & {\\textbf{131072}} \\\\\n",
    "  \\midrule\n",
    "  Llama-160M & 0.017 & 0.033 & 0.075 & 0.196 & 0.594 & 2.03 \\\\\n",
    "  \\rowcolor{gray!10} \\textbf{Configuration: (1024, 128)} \\\\\n",
    "  LLama-160M-ARMT & 0.105 & 0.211 & 0.422 & 0.877 & 1.72 & 3.37 \\\\\n",
    "  Diagonal Batching: LLama-160M-ARMT & 0.061 & 0.087 & 0.138 & 0.243 & 0.451 & 0.855 \\\\\n",
    "  \\rowcolor{gray!10} \\textbf{Configuration: (4096, 128)} \\\\\n",
    "  LLama-160M-ARMT & 0.031 & 0.057 & 0.111 & 0.216 & 0.432 & 0.855 \\\\\n",
    "  Diagonal Batching: LLama-160M-ARMT & 0.046 & 0.062 & 0.094 & 0.156 & 0.284 & 0.537 \\\\\n",
    "  \\midrule\n",
    "  \\end{tabular}%\n",
    "  }\n",
    "  \\caption{Diagonal batching speed-ups the execution - from 1.6 to 3.9 times comparing to base ARMT for 131072 sequence length. Executor comparison of execution times (in seconds) for different methods across sequence lengths for Llama-160M. Configuration in format (segment\\_size, memory\\_tokens). Nvidia A100}\n",
    "  \\label{tab:perf_comparison_llama160m}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "df_latex_160m = parse_latex_table(latex_text_160m)\n",
    "df_latex_160m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8770ce81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dtype</th>\n",
       "      <th>4096</th>\n",
       "      <th>8192</th>\n",
       "      <th>12288</th>\n",
       "      <th>16384</th>\n",
       "      <th>24576</th>\n",
       "      <th>32768</th>\n",
       "      <th>65536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.61</td>\n",
       "      <td>9.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLama-3.1-8B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.63</td>\n",
       "      <td>7.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.20</td>\n",
       "      <td>6.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LLama-3.1-8B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.95</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.83</td>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              model     dtype   4096   8192  \\\n",
       "0                                      Llama-3.1-8B  bfloat16  0.332  0.682   \n",
       "1                     LLama-3.1-8B-ARMT (1024, 128)  bfloat16  0.497  0.936   \n",
       "2  Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)  bfloat16  0.478  0.860   \n",
       "3                     LLama-3.1-8B-ARMT (4096, 128)  bfloat16  0.384  0.754   \n",
       "4  Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)  bfloat16  0.432  0.781   \n",
       "\n",
       "   12288  16384  24576  32768  65536  \n",
       "0    NaN   1.48    NaN   3.61   9.82  \n",
       "1    NaN   1.82    NaN   3.63   7.22  \n",
       "2    NaN   1.64    NaN   3.20   6.34  \n",
       "3    NaN   1.48    NaN   2.95   5.86  \n",
       "4    NaN   1.46    NaN   2.83   5.60  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latex_text_8b = r\"\"\"\n",
    "\\begin{table}[h]\n",
    "  \\centering\n",
    "  \\renewcommand{\\arraystretch}{1.2}\n",
    "  \\resizebox{\\textwidth}{!}{%\n",
    "  \\begin{tabular}{l*{6}{S[table-format=3.3]}}\n",
    "  \\toprule\n",
    "  \\textbf{Method} & \\multicolumn{6}{c}{\\textbf{Sequence Length}} \\\\\n",
    "  \\cmidrule(lr){2-7}\n",
    "   & {\\textbf{4096}} & {\\textbf{8192}} & {\\textbf{16384}} & {\\textbf{32768}} & {\\textbf{65536}} & {\\textbf{131072}} \\\\\n",
    "  \\midrule\n",
    "  Llama-3.1-8B & 0.332 & 0.682 & 1.48 & 3.61 & 9.82 & 30.4 \\\\\n",
    "  \\rowcolor{gray!10} \\textbf{Configuration: (1024, 128)} \\\\\n",
    "  LLama-3.1-8B-ARMT & 0.497 & 0.936 & 1.82 & 3.63 & 7.22 & 14.4 \\\\\n",
    "  Diagonal Batching: LLama-3.1-8B-ARMT & 0.478 & 0.86 & 1.64 & 3.2 & 6.34 & 12.6 \\\\\n",
    "  \\rowcolor{gray!10} \\textbf{Configuration: (4096, 128)} \\\\\n",
    "  LLama-3.1-8B-ARMT& 0.384 & 0.754 & 1.48 & 2.95 & 5.86 & 11.7 \\\\\n",
    "  Diagonal Batching: LLama-3.1-8B-ARMT & 0.432 & 0.781 & 1.46 & 2.83 & 5.6 & 11.1 \\\\\n",
    "  \\midrule\n",
    "  \\end{tabular}%\n",
    "  }\n",
    "  \\caption{Diagonal batching speed-ups the execution - from 1.05 to 1.14 times comparing to base ARMT for 131072 sequence length. Executor comparison of execution times (in seconds) for different methods across sequence lengths for Llama-3.1-8B. Configuration in format (segment\\_size, memory\\_tokens). Nvidia A100}\n",
    "  \\label{tab:perf_comparison_llama8b}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "df_latex_8b = parse_latex_table(latex_text_8b)\n",
    "df_latex_8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7758ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_all, df_latex], ignore_index=True)\n",
    "df_all = pd.concat([df_all, df_latex_160m], ignore_index=True)\n",
    "df_all = pd.concat([df_all, df_latex_3b], ignore_index=True)\n",
    "df_all = pd.concat([df_all, df_latex_8b], ignore_index=True)\n",
    "\n",
    "df_all.to_csv('result_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2ff8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf27381f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dtype</th>\n",
       "      <th>4096</th>\n",
       "      <th>8192</th>\n",
       "      <th>12288</th>\n",
       "      <th>16384</th>\n",
       "      <th>24576</th>\n",
       "      <th>32768</th>\n",
       "      <th>65536</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>result_fla-hub__rwkv7-0.4B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.508055</td>\n",
       "      <td>0.991270</td>\n",
       "      <td>1.467115</td>\n",
       "      <td>1.859422</td>\n",
       "      <td>2.805683</td>\n",
       "      <td>3.716381</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>result_fla-hub__rwkv7-1.5B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.666058</td>\n",
       "      <td>3.118853</td>\n",
       "      <td>4.657660</td>\n",
       "      <td>6.209821</td>\n",
       "      <td>9.226034</td>\n",
       "      <td>12.608575</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>result_fla-hub__rwkv7-2.9B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.419686</td>\n",
       "      <td>2.795940</td>\n",
       "      <td>4.228404</td>\n",
       "      <td>5.574663</td>\n",
       "      <td>8.406351</td>\n",
       "      <td>11.186028</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>result_fla-hub__rwkv7-2.9B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.205387</td>\n",
       "      <td>0.387402</td>\n",
       "      <td>0.577086</td>\n",
       "      <td>0.765386</td>\n",
       "      <td>1.142162</td>\n",
       "      <td>1.519346</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>result_fla-hub__rwkv7-1.5B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.289255</td>\n",
       "      <td>0.513334</td>\n",
       "      <td>0.767381</td>\n",
       "      <td>1.000250</td>\n",
       "      <td>1.478250</td>\n",
       "      <td>1.948466</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>result_fla-hub__rwkv7-0.4B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.154438</td>\n",
       "      <td>0.276561</td>\n",
       "      <td>0.396253</td>\n",
       "      <td>0.458832</td>\n",
       "      <td>0.732718</td>\n",
       "      <td>0.965903</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>result_state-spaces__mamba-370m-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.324087</td>\n",
       "      <td>0.387467</td>\n",
       "      <td>0.577039</td>\n",
       "      <td>0.636340</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>1.138121</td>\n",
       "      <td>2.268204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>result_state-spaces__mamba-1.4b-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.163566</td>\n",
       "      <td>0.296213</td>\n",
       "      <td>0.438505</td>\n",
       "      <td>0.573810</td>\n",
       "      <td>1.769796</td>\n",
       "      <td>1.115349</td>\n",
       "      <td>2.217252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>result_state-spaces__mamba-790m-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.364515</td>\n",
       "      <td>0.592927</td>\n",
       "      <td>0.818261</td>\n",
       "      <td>1.044761</td>\n",
       "      <td>1.370421</td>\n",
       "      <td>1.953040</td>\n",
       "      <td>3.641980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>result_state-spaces__mamba-2.8b-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.758202</td>\n",
       "      <td>1.339150</td>\n",
       "      <td>1.751778</td>\n",
       "      <td>2.502645</td>\n",
       "      <td>3.495352</td>\n",
       "      <td>4.645297</td>\n",
       "      <td>8.967827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>result_state-spaces__mamba-370m-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.574138</td>\n",
       "      <td>1.166106</td>\n",
       "      <td>1.679633</td>\n",
       "      <td>2.182511</td>\n",
       "      <td>3.337381</td>\n",
       "      <td>4.344779</td>\n",
       "      <td>8.711257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>result_state-spaces__mamba-790m-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.497716</td>\n",
       "      <td>0.962784</td>\n",
       "      <td>1.425659</td>\n",
       "      <td>1.881444</td>\n",
       "      <td>2.807039</td>\n",
       "      <td>3.730150</td>\n",
       "      <td>7.477307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>result_state-spaces__mamba-1.4b-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.841422</td>\n",
       "      <td>3.645328</td>\n",
       "      <td>5.272279</td>\n",
       "      <td>7.146885</td>\n",
       "      <td>10.429221</td>\n",
       "      <td>13.933506</td>\n",
       "      <td>27.872370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>result_state-spaces__mamba-2.8b-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.553447</td>\n",
       "      <td>3.067802</td>\n",
       "      <td>4.581770</td>\n",
       "      <td>6.090829</td>\n",
       "      <td>9.101565</td>\n",
       "      <td>12.116529</td>\n",
       "      <td>24.317709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>2.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LLama-3.2-1B-ARMT (512, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.147000</td>\n",
       "      <td>0.574000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.290000</td>\n",
       "      <td>4.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.283000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>1.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LLama-3.2-1B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>1.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LLama-3.2-1B-ARMT (2048, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>1.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>1.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LLama-3.2-1B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>1.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553000</td>\n",
       "      <td>1.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Llama-160M</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.594000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LLama-160M-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>1.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Diagonal Batching: LLama-160M-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LLama-160M-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Diagonal Batching: LLama-160M-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.284000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>5.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LLama-3.2-3B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>4.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>3.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LLama-3.2-3B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>3.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>2.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.610000</td>\n",
       "      <td>9.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LLama-3.1-8B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>7.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.478000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>6.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LLama-3.1-8B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>5.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.781000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.830000</td>\n",
       "      <td>5.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model     dtype      4096  \\\n",
       "0                   result_fla-hub__rwkv7-0.4B-world   float32  0.508055   \n",
       "1                   result_fla-hub__rwkv7-1.5B-world   float32  1.666058   \n",
       "2                   result_fla-hub__rwkv7-2.9B-world   float32  1.419686   \n",
       "3                   result_fla-hub__rwkv7-2.9B-world  bfloat16  0.205387   \n",
       "4                   result_fla-hub__rwkv7-1.5B-world  bfloat16  0.289255   \n",
       "5                   result_fla-hub__rwkv7-0.4B-world  bfloat16  0.154438   \n",
       "6                 result_state-spaces__mamba-370m-hf  bfloat16  0.324087   \n",
       "7                 result_state-spaces__mamba-1.4b-hf  bfloat16  0.163566   \n",
       "8                 result_state-spaces__mamba-790m-hf  bfloat16  0.364515   \n",
       "9                 result_state-spaces__mamba-2.8b-hf  bfloat16  0.758202   \n",
       "10                result_state-spaces__mamba-370m-hf   float32  0.574138   \n",
       "11                result_state-spaces__mamba-790m-hf   float32  0.497716   \n",
       "12                result_state-spaces__mamba-1.4b-hf   float32  1.841422   \n",
       "13                result_state-spaces__mamba-2.8b-hf   float32  1.553447   \n",
       "14                                      Llama-3.2-1B  bfloat16  0.024000   \n",
       "15                      LLama-3.2-1B-ARMT (512, 128)  bfloat16  0.147000   \n",
       "16   Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)  bfloat16  0.283000   \n",
       "17                     LLama-3.2-1B-ARMT (1024, 128)  bfloat16  0.149000   \n",
       "18  Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)  bfloat16  0.119000   \n",
       "19                     LLama-3.2-1B-ARMT (2048, 128)  bfloat16  0.094000   \n",
       "20  Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)  bfloat16  0.108000   \n",
       "21                     LLama-3.2-1B-ARMT (4096, 128)  bfloat16  0.082000   \n",
       "22  Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)  bfloat16  0.102000   \n",
       "23                                        Llama-160M  bfloat16  0.017000   \n",
       "24                       LLama-160M-ARMT (1024, 128)  bfloat16  0.105000   \n",
       "25    Diagonal Batching: LLama-160M-ARMT (1024, 128)  bfloat16  0.061000   \n",
       "26                       LLama-160M-ARMT (4096, 128)  bfloat16  0.031000   \n",
       "27    Diagonal Batching: LLama-160M-ARMT (4096, 128)  bfloat16  0.046000   \n",
       "28                                      Llama-3.2-3B  bfloat16  0.168000   \n",
       "29                     LLama-3.2-3B-ARMT (1024, 128)  bfloat16  0.272000   \n",
       "30  Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)  bfloat16  0.274000   \n",
       "31                     LLama-3.2-3B-ARMT (4096, 128)  bfloat16  0.203000   \n",
       "32  Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)  bfloat16  0.239000   \n",
       "33                                      Llama-3.1-8B  bfloat16  0.332000   \n",
       "34                     LLama-3.1-8B-ARMT (1024, 128)  bfloat16  0.497000   \n",
       "35  Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)  bfloat16  0.478000   \n",
       "36                     LLama-3.1-8B-ARMT (4096, 128)  bfloat16  0.384000   \n",
       "37  Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)  bfloat16  0.432000   \n",
       "\n",
       "        8192     12288     16384      24576      32768      65536  \n",
       "0   0.991270  1.467115  1.859422   2.805683   3.716381        NaN  \n",
       "1   3.118853  4.657660  6.209821   9.226034  12.608575        NaN  \n",
       "2   2.795940  4.228404  5.574663   8.406351  11.186028        NaN  \n",
       "3   0.387402  0.577086  0.765386   1.142162   1.519346        NaN  \n",
       "4   0.513334  0.767381  1.000250   1.478250   1.948466        NaN  \n",
       "5   0.276561  0.396253  0.458832   0.732718   0.965903        NaN  \n",
       "6   0.387467  0.577039  0.636340   0.891995   1.138121   2.268204  \n",
       "7   0.296213  0.438505  0.573810   1.769796   1.115349   2.217252  \n",
       "8   0.592927  0.818261  1.044761   1.370421   1.953040   3.641980  \n",
       "9   1.339150  1.751778  2.502645   3.495352   4.645297   8.967827  \n",
       "10  1.166106  1.679633  2.182511   3.337381   4.344779   8.711257  \n",
       "11  0.962784  1.425659  1.881444   2.807039   3.730150   7.477307  \n",
       "12  3.645328  5.272279  7.146885  10.429221  13.933506  27.872370  \n",
       "13  3.067802  4.581770  6.090829   9.101565  12.116529  24.317709  \n",
       "14  0.026000       NaN  0.376000        NaN   0.926000   2.460000  \n",
       "15  0.574000       NaN  1.150000        NaN   2.290000   4.520000  \n",
       "16  0.248000       NaN  0.454000        NaN   0.861000   1.670000  \n",
       "17  0.291000       NaN  0.578000        NaN   1.150000   2.300000  \n",
       "18  0.196000       NaN  0.351000        NaN   0.656000   1.270000  \n",
       "19  0.177000       NaN  0.344000        NaN   0.679000   1.350000  \n",
       "20  0.176000       NaN  0.304000        NaN   0.571000   1.110000  \n",
       "21  0.155000       NaN  0.301000        NaN   0.594000   1.180000  \n",
       "22  0.172000       NaN  0.295000        NaN   0.553000   1.070000  \n",
       "23  0.033000       NaN  0.075000        NaN   0.196000   0.594000  \n",
       "24  0.211000       NaN  0.422000        NaN   0.877000   1.720000  \n",
       "25  0.087000       NaN  0.138000        NaN   0.243000   0.451000  \n",
       "26  0.057000       NaN  0.111000        NaN   0.216000   0.432000  \n",
       "27  0.062000       NaN  0.094000        NaN   0.156000   0.284000  \n",
       "28  0.344000       NaN  0.769000        NaN   1.950000   5.590000  \n",
       "29  0.537000       NaN  1.050000        NaN   2.020000   4.090000  \n",
       "30  0.454000       NaN  0.833000        NaN   1.580000   3.100000  \n",
       "31  0.390000       NaN  0.765000        NaN   1.520000   3.010000  \n",
       "32  0.411000       NaN  0.739000        NaN   1.400000   2.720000  \n",
       "33  0.682000       NaN  1.480000        NaN   3.610000   9.820000  \n",
       "34  0.936000       NaN  1.820000        NaN   3.630000   7.220000  \n",
       "35  0.860000       NaN  1.640000        NaN   3.200000   6.340000  \n",
       "36  0.754000       NaN  1.480000        NaN   2.950000   5.860000  \n",
       "37  0.781000       NaN  1.460000        NaN   2.830000   5.600000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e51da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_params_billion(model_name: str) -> float:\n",
    "    matches = re.findall(r'(\\d+(?:\\.\\d+)?)\\s*([mMbB])', str(model_name))\n",
    "    if not matches:\n",
    "        return float('nan')\n",
    "    num_str, suffix = matches[-1]\n",
    "    value = float(num_str)\n",
    "    return value / 1000.0 if suffix.lower() == 'm' else value\n",
    "\n",
    "df_all_scaled = df_all.copy()\n",
    "\n",
    "# Add new column to df_fit\n",
    "if 'model' in df_all_scaled.columns:\n",
    "    df_all['params_billion'] = df_all['model'].apply(parse_params_billion)\n",
    "    df_all_scaled['params_billion'] = df_all_scaled['model'].apply(parse_params_billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85a1d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6751c664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('float32', 'result_state-spaces__mamba-2.8b-hf')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.split('.')[-2], p.rsplit('_', 1)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f356d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([         'model',          'dtype',             4096,             8192,\n",
       "                  12288,            16384,            24576,            32768,\n",
       "                  65536, 'params_billion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f24a8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bae5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28b5438e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dtype</th>\n",
       "      <th>4096</th>\n",
       "      <th>8192</th>\n",
       "      <th>12288</th>\n",
       "      <th>16384</th>\n",
       "      <th>24576</th>\n",
       "      <th>32768</th>\n",
       "      <th>65536</th>\n",
       "      <th>params_billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>result_fla-hub__rwkv7-0.4B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.508055</td>\n",
       "      <td>0.991270</td>\n",
       "      <td>1.467115</td>\n",
       "      <td>1.859422</td>\n",
       "      <td>2.805683</td>\n",
       "      <td>3.716381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>result_fla-hub__rwkv7-1.5B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.666058</td>\n",
       "      <td>3.118853</td>\n",
       "      <td>4.657660</td>\n",
       "      <td>6.209821</td>\n",
       "      <td>9.226034</td>\n",
       "      <td>12.608575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>result_fla-hub__rwkv7-2.9B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.419686</td>\n",
       "      <td>2.795940</td>\n",
       "      <td>4.228404</td>\n",
       "      <td>5.574663</td>\n",
       "      <td>8.406351</td>\n",
       "      <td>11.186028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>result_fla-hub__rwkv7-2.9B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.205387</td>\n",
       "      <td>0.387402</td>\n",
       "      <td>0.577086</td>\n",
       "      <td>0.765386</td>\n",
       "      <td>1.142162</td>\n",
       "      <td>1.519346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>result_fla-hub__rwkv7-1.5B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.289255</td>\n",
       "      <td>0.513334</td>\n",
       "      <td>0.767381</td>\n",
       "      <td>1.000250</td>\n",
       "      <td>1.478250</td>\n",
       "      <td>1.948466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>result_fla-hub__rwkv7-0.4B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.154438</td>\n",
       "      <td>0.276561</td>\n",
       "      <td>0.396253</td>\n",
       "      <td>0.458832</td>\n",
       "      <td>0.732718</td>\n",
       "      <td>0.965903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>result_state-spaces__mamba-370m-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.324087</td>\n",
       "      <td>0.387467</td>\n",
       "      <td>0.577039</td>\n",
       "      <td>0.636340</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>1.138121</td>\n",
       "      <td>2.268204</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>result_state-spaces__mamba-1.4b-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.163566</td>\n",
       "      <td>0.296213</td>\n",
       "      <td>0.438505</td>\n",
       "      <td>0.573810</td>\n",
       "      <td>1.769796</td>\n",
       "      <td>1.115349</td>\n",
       "      <td>2.217252</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>result_state-spaces__mamba-790m-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.364515</td>\n",
       "      <td>0.592927</td>\n",
       "      <td>0.818261</td>\n",
       "      <td>1.044761</td>\n",
       "      <td>1.370421</td>\n",
       "      <td>1.953040</td>\n",
       "      <td>3.641980</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>result_state-spaces__mamba-2.8b-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.758202</td>\n",
       "      <td>1.339150</td>\n",
       "      <td>1.751778</td>\n",
       "      <td>2.502645</td>\n",
       "      <td>3.495352</td>\n",
       "      <td>4.645297</td>\n",
       "      <td>8.967827</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>result_state-spaces__mamba-370m-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.574138</td>\n",
       "      <td>1.166106</td>\n",
       "      <td>1.679633</td>\n",
       "      <td>2.182511</td>\n",
       "      <td>3.337381</td>\n",
       "      <td>4.344779</td>\n",
       "      <td>8.711257</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>result_state-spaces__mamba-790m-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.497716</td>\n",
       "      <td>0.962784</td>\n",
       "      <td>1.425659</td>\n",
       "      <td>1.881444</td>\n",
       "      <td>2.807039</td>\n",
       "      <td>3.730150</td>\n",
       "      <td>7.477307</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>result_state-spaces__mamba-1.4b-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.841422</td>\n",
       "      <td>3.645328</td>\n",
       "      <td>5.272279</td>\n",
       "      <td>7.146885</td>\n",
       "      <td>10.429221</td>\n",
       "      <td>13.933506</td>\n",
       "      <td>27.872370</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>result_state-spaces__mamba-2.8b-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.553447</td>\n",
       "      <td>3.067802</td>\n",
       "      <td>4.581770</td>\n",
       "      <td>6.090829</td>\n",
       "      <td>9.101565</td>\n",
       "      <td>12.116529</td>\n",
       "      <td>24.317709</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>2.460000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LLama-3.2-1B-ARMT (512, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.147000</td>\n",
       "      <td>0.574000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.290000</td>\n",
       "      <td>4.520000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.283000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LLama-3.2-1B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LLama-3.2-1B-ARMT (2048, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LLama-3.2-1B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Llama-160M</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LLama-160M-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Diagonal Batching: LLama-160M-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.451000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LLama-160M-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Diagonal Batching: LLama-160M-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>5.590000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LLama-3.2-3B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LLama-3.2-3B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>3.010000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.610000</td>\n",
       "      <td>9.820000</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LLama-3.1-8B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>7.220000</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.478000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>6.340000</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LLama-3.1-8B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>5.860000</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.781000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.830000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model     dtype      4096  \\\n",
       "0                   result_fla-hub__rwkv7-0.4B-world   float32  0.508055   \n",
       "1                   result_fla-hub__rwkv7-1.5B-world   float32  1.666058   \n",
       "2                   result_fla-hub__rwkv7-2.9B-world   float32  1.419686   \n",
       "3                   result_fla-hub__rwkv7-2.9B-world  bfloat16  0.205387   \n",
       "4                   result_fla-hub__rwkv7-1.5B-world  bfloat16  0.289255   \n",
       "5                   result_fla-hub__rwkv7-0.4B-world  bfloat16  0.154438   \n",
       "6                 result_state-spaces__mamba-370m-hf  bfloat16  0.324087   \n",
       "7                 result_state-spaces__mamba-1.4b-hf  bfloat16  0.163566   \n",
       "8                 result_state-spaces__mamba-790m-hf  bfloat16  0.364515   \n",
       "9                 result_state-spaces__mamba-2.8b-hf  bfloat16  0.758202   \n",
       "10                result_state-spaces__mamba-370m-hf   float32  0.574138   \n",
       "11                result_state-spaces__mamba-790m-hf   float32  0.497716   \n",
       "12                result_state-spaces__mamba-1.4b-hf   float32  1.841422   \n",
       "13                result_state-spaces__mamba-2.8b-hf   float32  1.553447   \n",
       "14                                      Llama-3.2-1B  bfloat16  0.024000   \n",
       "15                      LLama-3.2-1B-ARMT (512, 128)  bfloat16  0.147000   \n",
       "16   Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)  bfloat16  0.283000   \n",
       "17                     LLama-3.2-1B-ARMT (1024, 128)  bfloat16  0.149000   \n",
       "18  Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)  bfloat16  0.119000   \n",
       "19                     LLama-3.2-1B-ARMT (2048, 128)  bfloat16  0.094000   \n",
       "20  Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)  bfloat16  0.108000   \n",
       "21                     LLama-3.2-1B-ARMT (4096, 128)  bfloat16  0.082000   \n",
       "22  Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)  bfloat16  0.102000   \n",
       "23                                        Llama-160M  bfloat16  0.017000   \n",
       "24                       LLama-160M-ARMT (1024, 128)  bfloat16  0.105000   \n",
       "25    Diagonal Batching: LLama-160M-ARMT (1024, 128)  bfloat16  0.061000   \n",
       "26                       LLama-160M-ARMT (4096, 128)  bfloat16  0.031000   \n",
       "27    Diagonal Batching: LLama-160M-ARMT (4096, 128)  bfloat16  0.046000   \n",
       "28                                      Llama-3.2-3B  bfloat16  0.168000   \n",
       "29                     LLama-3.2-3B-ARMT (1024, 128)  bfloat16  0.272000   \n",
       "30  Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)  bfloat16  0.274000   \n",
       "31                     LLama-3.2-3B-ARMT (4096, 128)  bfloat16  0.203000   \n",
       "32  Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)  bfloat16  0.239000   \n",
       "33                                      Llama-3.1-8B  bfloat16  0.332000   \n",
       "34                     LLama-3.1-8B-ARMT (1024, 128)  bfloat16  0.497000   \n",
       "35  Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)  bfloat16  0.478000   \n",
       "36                     LLama-3.1-8B-ARMT (4096, 128)  bfloat16  0.384000   \n",
       "37  Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)  bfloat16  0.432000   \n",
       "\n",
       "        8192     12288     16384      24576      32768      65536  \\\n",
       "0   0.991270  1.467115  1.859422   2.805683   3.716381        NaN   \n",
       "1   3.118853  4.657660  6.209821   9.226034  12.608575        NaN   \n",
       "2   2.795940  4.228404  5.574663   8.406351  11.186028        NaN   \n",
       "3   0.387402  0.577086  0.765386   1.142162   1.519346        NaN   \n",
       "4   0.513334  0.767381  1.000250   1.478250   1.948466        NaN   \n",
       "5   0.276561  0.396253  0.458832   0.732718   0.965903        NaN   \n",
       "6   0.387467  0.577039  0.636340   0.891995   1.138121   2.268204   \n",
       "7   0.296213  0.438505  0.573810   1.769796   1.115349   2.217252   \n",
       "8   0.592927  0.818261  1.044761   1.370421   1.953040   3.641980   \n",
       "9   1.339150  1.751778  2.502645   3.495352   4.645297   8.967827   \n",
       "10  1.166106  1.679633  2.182511   3.337381   4.344779   8.711257   \n",
       "11  0.962784  1.425659  1.881444   2.807039   3.730150   7.477307   \n",
       "12  3.645328  5.272279  7.146885  10.429221  13.933506  27.872370   \n",
       "13  3.067802  4.581770  6.090829   9.101565  12.116529  24.317709   \n",
       "14  0.026000       NaN  0.376000        NaN   0.926000   2.460000   \n",
       "15  0.574000       NaN  1.150000        NaN   2.290000   4.520000   \n",
       "16  0.248000       NaN  0.454000        NaN   0.861000   1.670000   \n",
       "17  0.291000       NaN  0.578000        NaN   1.150000   2.300000   \n",
       "18  0.196000       NaN  0.351000        NaN   0.656000   1.270000   \n",
       "19  0.177000       NaN  0.344000        NaN   0.679000   1.350000   \n",
       "20  0.176000       NaN  0.304000        NaN   0.571000   1.110000   \n",
       "21  0.155000       NaN  0.301000        NaN   0.594000   1.180000   \n",
       "22  0.172000       NaN  0.295000        NaN   0.553000   1.070000   \n",
       "23  0.033000       NaN  0.075000        NaN   0.196000   0.594000   \n",
       "24  0.211000       NaN  0.422000        NaN   0.877000   1.720000   \n",
       "25  0.087000       NaN  0.138000        NaN   0.243000   0.451000   \n",
       "26  0.057000       NaN  0.111000        NaN   0.216000   0.432000   \n",
       "27  0.062000       NaN  0.094000        NaN   0.156000   0.284000   \n",
       "28  0.344000       NaN  0.769000        NaN   1.950000   5.590000   \n",
       "29  0.537000       NaN  1.050000        NaN   2.020000   4.090000   \n",
       "30  0.454000       NaN  0.833000        NaN   1.580000   3.100000   \n",
       "31  0.390000       NaN  0.765000        NaN   1.520000   3.010000   \n",
       "32  0.411000       NaN  0.739000        NaN   1.400000   2.720000   \n",
       "33  0.682000       NaN  1.480000        NaN   3.610000   9.820000   \n",
       "34  0.936000       NaN  1.820000        NaN   3.630000   7.220000   \n",
       "35  0.860000       NaN  1.640000        NaN   3.200000   6.340000   \n",
       "36  0.754000       NaN  1.480000        NaN   2.950000   5.860000   \n",
       "37  0.781000       NaN  1.460000        NaN   2.830000   5.600000   \n",
       "\n",
       "    params_billion  \n",
       "0             0.40  \n",
       "1             1.50  \n",
       "2             2.90  \n",
       "3             2.90  \n",
       "4             1.50  \n",
       "5             0.40  \n",
       "6             0.37  \n",
       "7             1.40  \n",
       "8             0.79  \n",
       "9             2.80  \n",
       "10            0.37  \n",
       "11            0.79  \n",
       "12            1.40  \n",
       "13            2.80  \n",
       "14            1.00  \n",
       "15            1.00  \n",
       "16            1.00  \n",
       "17            1.00  \n",
       "18            1.00  \n",
       "19            1.00  \n",
       "20            1.00  \n",
       "21            1.00  \n",
       "22            1.00  \n",
       "23            0.16  \n",
       "24            0.16  \n",
       "25            0.16  \n",
       "26            0.16  \n",
       "27            0.16  \n",
       "28            3.00  \n",
       "29            3.00  \n",
       "30            3.00  \n",
       "31            3.00  \n",
       "32            3.00  \n",
       "33            8.00  \n",
       "34            8.00  \n",
       "35            8.00  \n",
       "36            8.00  \n",
       "37            8.00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c729d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit_linear_models(df):\n",
    "    cols = [4096, 8192, 12288, 16384, 24576, 32768, 65536]\n",
    "    fit_rows = []\n",
    "\n",
    "    for _, r in df.iterrows():\n",
    "        x_vals = []\n",
    "        y_vals = []\n",
    "        for c in cols:\n",
    "            val = r.get(c, None)\n",
    "            if pd.notna(val):\n",
    "                x_vals.append(float(c))\n",
    "                y_vals.append(float(val))\n",
    "        if len(x_vals) >= 2:\n",
    "            slope, intercept = np.polyfit(x_vals, y_vals, 1)\n",
    "        else:\n",
    "            slope, intercept = (float('nan'), float('nan'))\n",
    "        fit_rows.append({\n",
    "            'model_name': r['model'],\n",
    "            'dtype': r['dtype'],\n",
    "            'params_billion': r['params_billion'],\n",
    "            'line_slope': slope,\n",
    "            'line_bias': intercept,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(fit_rows)\n",
    "\n",
    "df_fit = fit_linear_models(df_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "320fb338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>dtype</th>\n",
       "      <th>params_billion</th>\n",
       "      <th>line_slope</th>\n",
       "      <th>line_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Diagonal Batching: LLama-160M-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.030167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Diagonal Batching: LLama-160M-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.034708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LLama-160M-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.003667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Llama-160M</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.057917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.039250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.039792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LLama-3.2-1B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.042875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LLama-3.2-1B-ARMT (2048, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.103042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LLama-160M-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.002750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>result_fla-hub__rwkv7-0.4B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.036703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>result_state-spaces__mamba-370m-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.142675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>result_state-spaces__mamba-1.4b-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.147350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LLama-3.2-1B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.004375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.077583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.267333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LLama-3.2-3B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.016875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>result_fla-hub__rwkv7-2.9B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.013933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.079042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>result_state-spaces__mamba-790m-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.149955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>result_fla-hub__rwkv7-1.5B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.047895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LLama-3.2-3B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.021375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LLama-3.2-1B-ARMT (512, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-0.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.085792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>-0.497542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LLama-3.1-8B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.022333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.079167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LLama-3.1-8B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>result_fla-hub__rwkv7-0.4B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.067430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>result_state-spaces__mamba-790m-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.025440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>result_state-spaces__mamba-370m-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>result_state-spaces__mamba-2.8b-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.220301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>-0.768833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>result_fla-hub__rwkv7-2.9B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.016260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>result_state-spaces__mamba-2.8b-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.021179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>result_fla-hub__rwkv7-1.5B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.013383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>result_state-spaces__mamba-1.4b-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.120617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name     dtype  \\\n",
       "27    Diagonal Batching: LLama-160M-ARMT (4096, 128)  bfloat16   \n",
       "25    Diagonal Batching: LLama-160M-ARMT (1024, 128)  bfloat16   \n",
       "26                       LLama-160M-ARMT (4096, 128)  bfloat16   \n",
       "23                                        Llama-160M  bfloat16   \n",
       "22  Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)  bfloat16   \n",
       "20  Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)  bfloat16   \n",
       "21                     LLama-3.2-1B-ARMT (4096, 128)  bfloat16   \n",
       "18  Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)  bfloat16   \n",
       "19                     LLama-3.2-1B-ARMT (2048, 128)  bfloat16   \n",
       "16   Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)  bfloat16   \n",
       "24                       LLama-160M-ARMT (1024, 128)  bfloat16   \n",
       "5                   result_fla-hub__rwkv7-0.4B-world  bfloat16   \n",
       "6                 result_state-spaces__mamba-370m-hf  bfloat16   \n",
       "7                 result_state-spaces__mamba-1.4b-hf  bfloat16   \n",
       "17                     LLama-3.2-1B-ARMT (1024, 128)  bfloat16   \n",
       "32  Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)  bfloat16   \n",
       "14                                      Llama-3.2-1B  bfloat16   \n",
       "31                     LLama-3.2-3B-ARMT (4096, 128)  bfloat16   \n",
       "3                   result_fla-hub__rwkv7-2.9B-world  bfloat16   \n",
       "30  Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)  bfloat16   \n",
       "8                 result_state-spaces__mamba-790m-hf  bfloat16   \n",
       "4                   result_fla-hub__rwkv7-1.5B-world  bfloat16   \n",
       "29                     LLama-3.2-3B-ARMT (1024, 128)  bfloat16   \n",
       "15                      LLama-3.2-1B-ARMT (512, 128)  bfloat16   \n",
       "37  Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)  bfloat16   \n",
       "28                                      Llama-3.2-3B  bfloat16   \n",
       "36                     LLama-3.1-8B-ARMT (4096, 128)  bfloat16   \n",
       "35  Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)  bfloat16   \n",
       "34                     LLama-3.1-8B-ARMT (1024, 128)  bfloat16   \n",
       "0                   result_fla-hub__rwkv7-0.4B-world   float32   \n",
       "11                result_state-spaces__mamba-790m-hf   float32   \n",
       "10                result_state-spaces__mamba-370m-hf   float32   \n",
       "9                 result_state-spaces__mamba-2.8b-hf  bfloat16   \n",
       "33                                      Llama-3.1-8B  bfloat16   \n",
       "2                   result_fla-hub__rwkv7-2.9B-world   float32   \n",
       "13                result_state-spaces__mamba-2.8b-hf   float32   \n",
       "1                   result_fla-hub__rwkv7-1.5B-world   float32   \n",
       "12                result_state-spaces__mamba-1.4b-hf   float32   \n",
       "\n",
       "    params_billion  line_slope  line_bias  \n",
       "27            0.16    0.000004   0.030167  \n",
       "25            0.16    0.000006   0.034708  \n",
       "26            0.16    0.000007   0.003667  \n",
       "23            0.16    0.000009  -0.057917  \n",
       "22            1.00    0.000016   0.039250  \n",
       "20            1.00    0.000016   0.039792  \n",
       "21            1.00    0.000018   0.008500  \n",
       "18            1.00    0.000019   0.042875  \n",
       "19            1.00    0.000020   0.009500  \n",
       "16            1.00    0.000024   0.103042  \n",
       "24            0.16    0.000026  -0.002750  \n",
       "5             0.40    0.000028   0.036703  \n",
       "6             0.37    0.000032   0.142675  \n",
       "7             1.40    0.000034   0.147350  \n",
       "17            1.00    0.000035   0.004375  \n",
       "32            3.00    0.000040   0.077583  \n",
       "14            1.00    0.000041  -0.267333  \n",
       "31            3.00    0.000046   0.016875  \n",
       "3             2.90    0.000046   0.013933  \n",
       "30            3.00    0.000046   0.079042  \n",
       "8             0.79    0.000053   0.149955  \n",
       "4             1.50    0.000058   0.047895  \n",
       "29            3.00    0.000062   0.021375  \n",
       "15            1.00    0.000070  -0.043500  \n",
       "37            8.00    0.000084   0.085792  \n",
       "28            3.00    0.000089  -0.497542  \n",
       "36            8.00    0.000089   0.022333  \n",
       "35            8.00    0.000095   0.079167  \n",
       "34            8.00    0.000110   0.038500  \n",
       "0             0.40    0.000111   0.067430  \n",
       "11            0.79    0.000114   0.025440  \n",
       "10            0.37    0.000132   0.051600  \n",
       "9             2.80    0.000134   0.220301  \n",
       "33            8.00    0.000156  -0.768833  \n",
       "2             2.90    0.000341   0.016260  \n",
       "13            2.80    0.000370   0.021179  \n",
       "1             1.50    0.000381   0.013383  \n",
       "12            1.40    0.000423   0.120617  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fit.sort_values('line_slope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815b39c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9108c085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     result_fla-hub__rwkv7-0.4B-world\n",
       "1                     result_fla-hub__rwkv7-1.5B-world\n",
       "2                     result_fla-hub__rwkv7-2.9B-world\n",
       "3                     result_fla-hub__rwkv7-2.9B-world\n",
       "4                     result_fla-hub__rwkv7-1.5B-world\n",
       "5                     result_fla-hub__rwkv7-0.4B-world\n",
       "6                   result_state-spaces__mamba-370m-hf\n",
       "7                   result_state-spaces__mamba-1.4b-hf\n",
       "8                   result_state-spaces__mamba-790m-hf\n",
       "9                   result_state-spaces__mamba-2.8b-hf\n",
       "10                  result_state-spaces__mamba-370m-hf\n",
       "11                  result_state-spaces__mamba-790m-hf\n",
       "12                  result_state-spaces__mamba-1.4b-hf\n",
       "13                  result_state-spaces__mamba-2.8b-hf\n",
       "14                                        Llama-3.2-1B\n",
       "15                        LLama-3.2-1B-ARMT (512, 128)\n",
       "16     Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)\n",
       "17                       LLama-3.2-1B-ARMT (1024, 128)\n",
       "18    Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)\n",
       "19                       LLama-3.2-1B-ARMT (2048, 128)\n",
       "20    Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)\n",
       "21                       LLama-3.2-1B-ARMT (4096, 128)\n",
       "22    Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)\n",
       "23                                          Llama-160M\n",
       "24                         LLama-160M-ARMT (1024, 128)\n",
       "25      Diagonal Batching: LLama-160M-ARMT (1024, 128)\n",
       "26                         LLama-160M-ARMT (4096, 128)\n",
       "27      Diagonal Batching: LLama-160M-ARMT (4096, 128)\n",
       "28                                        Llama-3.2-3B\n",
       "29                       LLama-3.2-3B-ARMT (1024, 128)\n",
       "30    Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)\n",
       "31                       LLama-3.2-3B-ARMT (4096, 128)\n",
       "32    Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)\n",
       "33                                        Llama-3.1-8B\n",
       "34                       LLama-3.1-8B-ARMT (1024, 128)\n",
       "35    Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)\n",
       "36                       LLama-3.1-8B-ARMT (4096, 128)\n",
       "37    Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)\n",
       "Name: model_name, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fit['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ce1d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f3eb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbfc62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51274f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dtype</th>\n",
       "      <th>4096</th>\n",
       "      <th>8192</th>\n",
       "      <th>12288</th>\n",
       "      <th>16384</th>\n",
       "      <th>24576</th>\n",
       "      <th>32768</th>\n",
       "      <th>65536</th>\n",
       "      <th>params_billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>result_fla-hub__rwkv7-0.4B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.508055</td>\n",
       "      <td>0.991270</td>\n",
       "      <td>1.467115</td>\n",
       "      <td>1.859422</td>\n",
       "      <td>2.805683</td>\n",
       "      <td>3.716381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>result_fla-hub__rwkv7-1.5B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.666058</td>\n",
       "      <td>3.118853</td>\n",
       "      <td>4.657660</td>\n",
       "      <td>6.209821</td>\n",
       "      <td>9.226034</td>\n",
       "      <td>12.608575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>result_fla-hub__rwkv7-2.9B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.419686</td>\n",
       "      <td>2.795940</td>\n",
       "      <td>4.228404</td>\n",
       "      <td>5.574663</td>\n",
       "      <td>8.406351</td>\n",
       "      <td>11.186028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>result_fla-hub__rwkv7-2.9B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.205387</td>\n",
       "      <td>0.387402</td>\n",
       "      <td>0.577086</td>\n",
       "      <td>0.765386</td>\n",
       "      <td>1.142162</td>\n",
       "      <td>1.519346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>result_fla-hub__rwkv7-1.5B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.289255</td>\n",
       "      <td>0.513334</td>\n",
       "      <td>0.767381</td>\n",
       "      <td>1.000250</td>\n",
       "      <td>1.478250</td>\n",
       "      <td>1.948466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>result_fla-hub__rwkv7-0.4B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.154438</td>\n",
       "      <td>0.276561</td>\n",
       "      <td>0.396253</td>\n",
       "      <td>0.458832</td>\n",
       "      <td>0.732718</td>\n",
       "      <td>0.965903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>result_state-spaces__mamba-370m-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.324087</td>\n",
       "      <td>0.387467</td>\n",
       "      <td>0.577039</td>\n",
       "      <td>0.636340</td>\n",
       "      <td>0.891995</td>\n",
       "      <td>1.138121</td>\n",
       "      <td>2.268204</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>result_state-spaces__mamba-1.4b-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.163566</td>\n",
       "      <td>0.296213</td>\n",
       "      <td>0.438505</td>\n",
       "      <td>0.573810</td>\n",
       "      <td>1.769796</td>\n",
       "      <td>1.115349</td>\n",
       "      <td>2.217252</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>result_state-spaces__mamba-790m-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.364515</td>\n",
       "      <td>0.592927</td>\n",
       "      <td>0.818261</td>\n",
       "      <td>1.044761</td>\n",
       "      <td>1.370421</td>\n",
       "      <td>1.953040</td>\n",
       "      <td>3.641980</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>result_state-spaces__mamba-2.8b-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.758202</td>\n",
       "      <td>1.339150</td>\n",
       "      <td>1.751778</td>\n",
       "      <td>2.502645</td>\n",
       "      <td>3.495352</td>\n",
       "      <td>4.645297</td>\n",
       "      <td>8.967827</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>result_state-spaces__mamba-370m-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.574138</td>\n",
       "      <td>1.166106</td>\n",
       "      <td>1.679633</td>\n",
       "      <td>2.182511</td>\n",
       "      <td>3.337381</td>\n",
       "      <td>4.344779</td>\n",
       "      <td>8.711257</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>result_state-spaces__mamba-790m-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.497716</td>\n",
       "      <td>0.962784</td>\n",
       "      <td>1.425659</td>\n",
       "      <td>1.881444</td>\n",
       "      <td>2.807039</td>\n",
       "      <td>3.730150</td>\n",
       "      <td>7.477307</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>result_state-spaces__mamba-1.4b-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.841422</td>\n",
       "      <td>3.645328</td>\n",
       "      <td>5.272279</td>\n",
       "      <td>7.146885</td>\n",
       "      <td>10.429221</td>\n",
       "      <td>13.933506</td>\n",
       "      <td>27.872370</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>result_state-spaces__mamba-2.8b-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.553447</td>\n",
       "      <td>3.067802</td>\n",
       "      <td>4.581770</td>\n",
       "      <td>6.090829</td>\n",
       "      <td>9.101565</td>\n",
       "      <td>12.116529</td>\n",
       "      <td>24.317709</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>2.460000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LLama-3.2-1B-ARMT (512, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.147000</td>\n",
       "      <td>0.574000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.290000</td>\n",
       "      <td>4.520000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.283000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LLama-3.2-1B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LLama-3.2-1B-ARMT (2048, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LLama-3.2-1B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Llama-160M</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LLama-160M-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Diagonal Batching: LLama-160M-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.451000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LLama-160M-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Diagonal Batching: LLama-160M-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>5.590000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LLama-3.2-3B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LLama-3.2-3B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>3.010000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.610000</td>\n",
       "      <td>9.820000</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LLama-3.1-8B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>7.220000</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.478000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>6.340000</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LLama-3.1-8B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>5.860000</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.781000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.830000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model     dtype      4096  \\\n",
       "0                   result_fla-hub__rwkv7-0.4B-world   float32  0.508055   \n",
       "1                   result_fla-hub__rwkv7-1.5B-world   float32  1.666058   \n",
       "2                   result_fla-hub__rwkv7-2.9B-world   float32  1.419686   \n",
       "3                   result_fla-hub__rwkv7-2.9B-world  bfloat16  0.205387   \n",
       "4                   result_fla-hub__rwkv7-1.5B-world  bfloat16  0.289255   \n",
       "5                   result_fla-hub__rwkv7-0.4B-world  bfloat16  0.154438   \n",
       "6                 result_state-spaces__mamba-370m-hf  bfloat16  0.324087   \n",
       "7                 result_state-spaces__mamba-1.4b-hf  bfloat16  0.163566   \n",
       "8                 result_state-spaces__mamba-790m-hf  bfloat16  0.364515   \n",
       "9                 result_state-spaces__mamba-2.8b-hf  bfloat16  0.758202   \n",
       "10                result_state-spaces__mamba-370m-hf   float32  0.574138   \n",
       "11                result_state-spaces__mamba-790m-hf   float32  0.497716   \n",
       "12                result_state-spaces__mamba-1.4b-hf   float32  1.841422   \n",
       "13                result_state-spaces__mamba-2.8b-hf   float32  1.553447   \n",
       "14                                      Llama-3.2-1B  bfloat16  0.024000   \n",
       "15                      LLama-3.2-1B-ARMT (512, 128)  bfloat16  0.147000   \n",
       "16   Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)  bfloat16  0.283000   \n",
       "17                     LLama-3.2-1B-ARMT (1024, 128)  bfloat16  0.149000   \n",
       "18  Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)  bfloat16  0.119000   \n",
       "19                     LLama-3.2-1B-ARMT (2048, 128)  bfloat16  0.094000   \n",
       "20  Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)  bfloat16  0.108000   \n",
       "21                     LLama-3.2-1B-ARMT (4096, 128)  bfloat16  0.082000   \n",
       "22  Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)  bfloat16  0.102000   \n",
       "23                                        Llama-160M  bfloat16  0.017000   \n",
       "24                       LLama-160M-ARMT (1024, 128)  bfloat16  0.105000   \n",
       "25    Diagonal Batching: LLama-160M-ARMT (1024, 128)  bfloat16  0.061000   \n",
       "26                       LLama-160M-ARMT (4096, 128)  bfloat16  0.031000   \n",
       "27    Diagonal Batching: LLama-160M-ARMT (4096, 128)  bfloat16  0.046000   \n",
       "28                                      Llama-3.2-3B  bfloat16  0.168000   \n",
       "29                     LLama-3.2-3B-ARMT (1024, 128)  bfloat16  0.272000   \n",
       "30  Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)  bfloat16  0.274000   \n",
       "31                     LLama-3.2-3B-ARMT (4096, 128)  bfloat16  0.203000   \n",
       "32  Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)  bfloat16  0.239000   \n",
       "33                                      Llama-3.1-8B  bfloat16  0.332000   \n",
       "34                     LLama-3.1-8B-ARMT (1024, 128)  bfloat16  0.497000   \n",
       "35  Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)  bfloat16  0.478000   \n",
       "36                     LLama-3.1-8B-ARMT (4096, 128)  bfloat16  0.384000   \n",
       "37  Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)  bfloat16  0.432000   \n",
       "\n",
       "        8192     12288     16384      24576      32768      65536  \\\n",
       "0   0.991270  1.467115  1.859422   2.805683   3.716381        NaN   \n",
       "1   3.118853  4.657660  6.209821   9.226034  12.608575        NaN   \n",
       "2   2.795940  4.228404  5.574663   8.406351  11.186028        NaN   \n",
       "3   0.387402  0.577086  0.765386   1.142162   1.519346        NaN   \n",
       "4   0.513334  0.767381  1.000250   1.478250   1.948466        NaN   \n",
       "5   0.276561  0.396253  0.458832   0.732718   0.965903        NaN   \n",
       "6   0.387467  0.577039  0.636340   0.891995   1.138121   2.268204   \n",
       "7   0.296213  0.438505  0.573810   1.769796   1.115349   2.217252   \n",
       "8   0.592927  0.818261  1.044761   1.370421   1.953040   3.641980   \n",
       "9   1.339150  1.751778  2.502645   3.495352   4.645297   8.967827   \n",
       "10  1.166106  1.679633  2.182511   3.337381   4.344779   8.711257   \n",
       "11  0.962784  1.425659  1.881444   2.807039   3.730150   7.477307   \n",
       "12  3.645328  5.272279  7.146885  10.429221  13.933506  27.872370   \n",
       "13  3.067802  4.581770  6.090829   9.101565  12.116529  24.317709   \n",
       "14  0.026000       NaN  0.376000        NaN   0.926000   2.460000   \n",
       "15  0.574000       NaN  1.150000        NaN   2.290000   4.520000   \n",
       "16  0.248000       NaN  0.454000        NaN   0.861000   1.670000   \n",
       "17  0.291000       NaN  0.578000        NaN   1.150000   2.300000   \n",
       "18  0.196000       NaN  0.351000        NaN   0.656000   1.270000   \n",
       "19  0.177000       NaN  0.344000        NaN   0.679000   1.350000   \n",
       "20  0.176000       NaN  0.304000        NaN   0.571000   1.110000   \n",
       "21  0.155000       NaN  0.301000        NaN   0.594000   1.180000   \n",
       "22  0.172000       NaN  0.295000        NaN   0.553000   1.070000   \n",
       "23  0.033000       NaN  0.075000        NaN   0.196000   0.594000   \n",
       "24  0.211000       NaN  0.422000        NaN   0.877000   1.720000   \n",
       "25  0.087000       NaN  0.138000        NaN   0.243000   0.451000   \n",
       "26  0.057000       NaN  0.111000        NaN   0.216000   0.432000   \n",
       "27  0.062000       NaN  0.094000        NaN   0.156000   0.284000   \n",
       "28  0.344000       NaN  0.769000        NaN   1.950000   5.590000   \n",
       "29  0.537000       NaN  1.050000        NaN   2.020000   4.090000   \n",
       "30  0.454000       NaN  0.833000        NaN   1.580000   3.100000   \n",
       "31  0.390000       NaN  0.765000        NaN   1.520000   3.010000   \n",
       "32  0.411000       NaN  0.739000        NaN   1.400000   2.720000   \n",
       "33  0.682000       NaN  1.480000        NaN   3.610000   9.820000   \n",
       "34  0.936000       NaN  1.820000        NaN   3.630000   7.220000   \n",
       "35  0.860000       NaN  1.640000        NaN   3.200000   6.340000   \n",
       "36  0.754000       NaN  1.480000        NaN   2.950000   5.860000   \n",
       "37  0.781000       NaN  1.460000        NaN   2.830000   5.600000   \n",
       "\n",
       "    params_billion  \n",
       "0             0.40  \n",
       "1             1.50  \n",
       "2             2.90  \n",
       "3             2.90  \n",
       "4             1.50  \n",
       "5             0.40  \n",
       "6             0.37  \n",
       "7             1.40  \n",
       "8             0.79  \n",
       "9             2.80  \n",
       "10            0.37  \n",
       "11            0.79  \n",
       "12            1.40  \n",
       "13            2.80  \n",
       "14            1.00  \n",
       "15            1.00  \n",
       "16            1.00  \n",
       "17            1.00  \n",
       "18            1.00  \n",
       "19            1.00  \n",
       "20            1.00  \n",
       "21            1.00  \n",
       "22            1.00  \n",
       "23            0.16  \n",
       "24            0.16  \n",
       "25            0.16  \n",
       "26            0.16  \n",
       "27            0.16  \n",
       "28            3.00  \n",
       "29            3.00  \n",
       "30            3.00  \n",
       "31            3.00  \n",
       "32            3.00  \n",
       "33            8.00  \n",
       "34            8.00  \n",
       "35            8.00  \n",
       "36            8.00  \n",
       "37            8.00  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6784a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled_fit = fit_linear_models(df_all_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d12ff5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>dtype</th>\n",
       "      <th>params_billion</th>\n",
       "      <th>line_slope</th>\n",
       "      <th>line_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>result_fla-hub__rwkv7-0.4B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.067430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>result_fla-hub__rwkv7-1.5B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.013383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>result_fla-hub__rwkv7-2.9B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.016260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>result_fla-hub__rwkv7-2.9B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.013933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>result_fla-hub__rwkv7-1.5B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.047895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>result_fla-hub__rwkv7-0.4B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.036703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>result_state-spaces__mamba-370m-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.142675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>result_state-spaces__mamba-1.4b-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.147350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>result_state-spaces__mamba-790m-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.149955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>result_state-spaces__mamba-2.8b-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.220301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>result_state-spaces__mamba-370m-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>result_state-spaces__mamba-790m-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.025440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>result_state-spaces__mamba-1.4b-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.120617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>result_state-spaces__mamba-2.8b-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.021179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.267333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LLama-3.2-1B-ARMT (512, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-0.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.103042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LLama-3.2-1B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.004375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.042875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LLama-3.2-1B-ARMT (2048, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.039792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LLama-3.2-1B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.039250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Llama-160M</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.057917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LLama-160M-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.002750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Diagonal Batching: LLama-160M-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.034708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LLama-160M-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.003667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Diagonal Batching: LLama-160M-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.030167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>-0.497542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LLama-3.2-3B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.021375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.079042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LLama-3.2-3B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.016875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.077583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>-0.768833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LLama-3.1-8B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.079167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LLama-3.1-8B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.022333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.085792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name     dtype  \\\n",
       "0                   result_fla-hub__rwkv7-0.4B-world   float32   \n",
       "1                   result_fla-hub__rwkv7-1.5B-world   float32   \n",
       "2                   result_fla-hub__rwkv7-2.9B-world   float32   \n",
       "3                   result_fla-hub__rwkv7-2.9B-world  bfloat16   \n",
       "4                   result_fla-hub__rwkv7-1.5B-world  bfloat16   \n",
       "5                   result_fla-hub__rwkv7-0.4B-world  bfloat16   \n",
       "6                 result_state-spaces__mamba-370m-hf  bfloat16   \n",
       "7                 result_state-spaces__mamba-1.4b-hf  bfloat16   \n",
       "8                 result_state-spaces__mamba-790m-hf  bfloat16   \n",
       "9                 result_state-spaces__mamba-2.8b-hf  bfloat16   \n",
       "10                result_state-spaces__mamba-370m-hf   float32   \n",
       "11                result_state-spaces__mamba-790m-hf   float32   \n",
       "12                result_state-spaces__mamba-1.4b-hf   float32   \n",
       "13                result_state-spaces__mamba-2.8b-hf   float32   \n",
       "14                                      Llama-3.2-1B  bfloat16   \n",
       "15                      LLama-3.2-1B-ARMT (512, 128)  bfloat16   \n",
       "16   Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)  bfloat16   \n",
       "17                     LLama-3.2-1B-ARMT (1024, 128)  bfloat16   \n",
       "18  Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)  bfloat16   \n",
       "19                     LLama-3.2-1B-ARMT (2048, 128)  bfloat16   \n",
       "20  Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)  bfloat16   \n",
       "21                     LLama-3.2-1B-ARMT (4096, 128)  bfloat16   \n",
       "22  Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)  bfloat16   \n",
       "23                                        Llama-160M  bfloat16   \n",
       "24                       LLama-160M-ARMT (1024, 128)  bfloat16   \n",
       "25    Diagonal Batching: LLama-160M-ARMT (1024, 128)  bfloat16   \n",
       "26                       LLama-160M-ARMT (4096, 128)  bfloat16   \n",
       "27    Diagonal Batching: LLama-160M-ARMT (4096, 128)  bfloat16   \n",
       "28                                      Llama-3.2-3B  bfloat16   \n",
       "29                     LLama-3.2-3B-ARMT (1024, 128)  bfloat16   \n",
       "30  Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)  bfloat16   \n",
       "31                     LLama-3.2-3B-ARMT (4096, 128)  bfloat16   \n",
       "32  Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)  bfloat16   \n",
       "33                                      Llama-3.1-8B  bfloat16   \n",
       "34                     LLama-3.1-8B-ARMT (1024, 128)  bfloat16   \n",
       "35  Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)  bfloat16   \n",
       "36                     LLama-3.1-8B-ARMT (4096, 128)  bfloat16   \n",
       "37  Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)  bfloat16   \n",
       "\n",
       "    params_billion  line_slope  line_bias  \n",
       "0             0.40    0.000111   0.067430  \n",
       "1             1.50    0.000381   0.013383  \n",
       "2             2.90    0.000341   0.016260  \n",
       "3             2.90    0.000046   0.013933  \n",
       "4             1.50    0.000058   0.047895  \n",
       "5             0.40    0.000028   0.036703  \n",
       "6             0.37    0.000032   0.142675  \n",
       "7             1.40    0.000034   0.147350  \n",
       "8             0.79    0.000053   0.149955  \n",
       "9             2.80    0.000134   0.220301  \n",
       "10            0.37    0.000132   0.051600  \n",
       "11            0.79    0.000114   0.025440  \n",
       "12            1.40    0.000423   0.120617  \n",
       "13            2.80    0.000370   0.021179  \n",
       "14            1.00    0.000041  -0.267333  \n",
       "15            1.00    0.000070  -0.043500  \n",
       "16            1.00    0.000024   0.103042  \n",
       "17            1.00    0.000035   0.004375  \n",
       "18            1.00    0.000019   0.042875  \n",
       "19            1.00    0.000020   0.009500  \n",
       "20            1.00    0.000016   0.039792  \n",
       "21            1.00    0.000018   0.008500  \n",
       "22            1.00    0.000016   0.039250  \n",
       "23            0.16    0.000009  -0.057917  \n",
       "24            0.16    0.000026  -0.002750  \n",
       "25            0.16    0.000006   0.034708  \n",
       "26            0.16    0.000007   0.003667  \n",
       "27            0.16    0.000004   0.030167  \n",
       "28            3.00    0.000089  -0.497542  \n",
       "29            3.00    0.000062   0.021375  \n",
       "30            3.00    0.000046   0.079042  \n",
       "31            3.00    0.000046   0.016875  \n",
       "32            3.00    0.000040   0.077583  \n",
       "33            8.00    0.000156  -0.768833  \n",
       "34            8.00    0.000110   0.038500  \n",
       "35            8.00    0.000095   0.079167  \n",
       "36            8.00    0.000089   0.022333  \n",
       "37            8.00    0.000084   0.085792  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ff774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68edf84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a2923f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_name', 'dtype', 'params_billion', 'line_slope', 'line_bias'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fit.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770c9019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>dtype</th>\n",
       "      <th>params_billion</th>\n",
       "      <th>line_slope</th>\n",
       "      <th>line_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>result_fla-hub__rwkv7-0.4B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.067430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>result_fla-hub__rwkv7-1.5B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.013383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>result_fla-hub__rwkv7-2.9B-world</td>\n",
       "      <td>float32</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.016260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>result_fla-hub__rwkv7-2.9B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.013933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>result_fla-hub__rwkv7-1.5B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.047895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>result_fla-hub__rwkv7-0.4B-world</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.036703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>result_state-spaces__mamba-370m-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.142675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>result_state-spaces__mamba-1.4b-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.147350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>result_state-spaces__mamba-790m-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.149955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>result_state-spaces__mamba-2.8b-hf</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.220301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>result_state-spaces__mamba-370m-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>result_state-spaces__mamba-790m-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.025440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>result_state-spaces__mamba-1.4b-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.120617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>result_state-spaces__mamba-2.8b-hf</td>\n",
       "      <td>float32</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.021179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.267333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LLama-3.2-1B-ARMT (512, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-0.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.103042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LLama-3.2-1B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.004375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.042875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LLama-3.2-1B-ARMT (2048, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.039792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LLama-3.2-1B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.039250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Llama-160M</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.057917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LLama-160M-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.002750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Diagonal Batching: LLama-160M-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.034708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LLama-160M-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.003667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Diagonal Batching: LLama-160M-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.030167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>-0.497542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LLama-3.2-3B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.021375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.079042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LLama-3.2-3B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.016875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.077583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>-0.768833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LLama-3.1-8B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.079167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LLama-3.1-8B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.022333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)</td>\n",
       "      <td>bfloat16</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.085792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name     dtype  \\\n",
       "0                   result_fla-hub__rwkv7-0.4B-world   float32   \n",
       "1                   result_fla-hub__rwkv7-1.5B-world   float32   \n",
       "2                   result_fla-hub__rwkv7-2.9B-world   float32   \n",
       "3                   result_fla-hub__rwkv7-2.9B-world  bfloat16   \n",
       "4                   result_fla-hub__rwkv7-1.5B-world  bfloat16   \n",
       "5                   result_fla-hub__rwkv7-0.4B-world  bfloat16   \n",
       "6                 result_state-spaces__mamba-370m-hf  bfloat16   \n",
       "7                 result_state-spaces__mamba-1.4b-hf  bfloat16   \n",
       "8                 result_state-spaces__mamba-790m-hf  bfloat16   \n",
       "9                 result_state-spaces__mamba-2.8b-hf  bfloat16   \n",
       "10                result_state-spaces__mamba-370m-hf   float32   \n",
       "11                result_state-spaces__mamba-790m-hf   float32   \n",
       "12                result_state-spaces__mamba-1.4b-hf   float32   \n",
       "13                result_state-spaces__mamba-2.8b-hf   float32   \n",
       "14                                      Llama-3.2-1B  bfloat16   \n",
       "15                      LLama-3.2-1B-ARMT (512, 128)  bfloat16   \n",
       "16   Diagonal Batching: LLama-3.2-1B-ARMT (512, 128)  bfloat16   \n",
       "17                     LLama-3.2-1B-ARMT (1024, 128)  bfloat16   \n",
       "18  Diagonal Batching: LLama-3.2-1B-ARMT (1024, 128)  bfloat16   \n",
       "19                     LLama-3.2-1B-ARMT (2048, 128)  bfloat16   \n",
       "20  Diagonal Batching: LLama-3.2-1B-ARMT (2048, 128)  bfloat16   \n",
       "21                     LLama-3.2-1B-ARMT (4096, 128)  bfloat16   \n",
       "22  Diagonal Batching: LLama-3.2-1B-ARMT (4096, 128)  bfloat16   \n",
       "23                                        Llama-160M  bfloat16   \n",
       "24                       LLama-160M-ARMT (1024, 128)  bfloat16   \n",
       "25    Diagonal Batching: LLama-160M-ARMT (1024, 128)  bfloat16   \n",
       "26                       LLama-160M-ARMT (4096, 128)  bfloat16   \n",
       "27    Diagonal Batching: LLama-160M-ARMT (4096, 128)  bfloat16   \n",
       "28                                      Llama-3.2-3B  bfloat16   \n",
       "29                     LLama-3.2-3B-ARMT (1024, 128)  bfloat16   \n",
       "30  Diagonal Batching: LLama-3.1-3B-ARMT (1024, 128)  bfloat16   \n",
       "31                     LLama-3.2-3B-ARMT (4096, 128)  bfloat16   \n",
       "32  Diagonal Batching: LLama-3.2-3B-ARMT (4096, 128)  bfloat16   \n",
       "33                                      Llama-3.1-8B  bfloat16   \n",
       "34                     LLama-3.1-8B-ARMT (1024, 128)  bfloat16   \n",
       "35  Diagonal Batching: LLama-3.1-8B-ARMT (1024, 128)  bfloat16   \n",
       "36                     LLama-3.1-8B-ARMT (4096, 128)  bfloat16   \n",
       "37  Diagonal Batching: LLama-3.1-8B-ARMT (4096, 128)  bfloat16   \n",
       "\n",
       "    params_billion  line_slope  line_bias  \n",
       "0             0.40    0.000111   0.067430  \n",
       "1             1.50    0.000381   0.013383  \n",
       "2             2.90    0.000341   0.016260  \n",
       "3             2.90    0.000046   0.013933  \n",
       "4             1.50    0.000058   0.047895  \n",
       "5             0.40    0.000028   0.036703  \n",
       "6             0.37    0.000032   0.142675  \n",
       "7             1.40    0.000034   0.147350  \n",
       "8             0.79    0.000053   0.149955  \n",
       "9             2.80    0.000134   0.220301  \n",
       "10            0.37    0.000132   0.051600  \n",
       "11            0.79    0.000114   0.025440  \n",
       "12            1.40    0.000423   0.120617  \n",
       "13            2.80    0.000370   0.021179  \n",
       "14            1.00    0.000041  -0.267333  \n",
       "15            1.00    0.000070  -0.043500  \n",
       "16            1.00    0.000024   0.103042  \n",
       "17            1.00    0.000035   0.004375  \n",
       "18            1.00    0.000019   0.042875  \n",
       "19            1.00    0.000020   0.009500  \n",
       "20            1.00    0.000016   0.039792  \n",
       "21            1.00    0.000018   0.008500  \n",
       "22            1.00    0.000016   0.039250  \n",
       "23            0.16    0.000009  -0.057917  \n",
       "24            0.16    0.000026  -0.002750  \n",
       "25            0.16    0.000006   0.034708  \n",
       "26            0.16    0.000007   0.003667  \n",
       "27            0.16    0.000004   0.030167  \n",
       "28            3.00    0.000089  -0.497542  \n",
       "29            3.00    0.000062   0.021375  \n",
       "30            3.00    0.000046   0.079042  \n",
       "31            3.00    0.000046   0.016875  \n",
       "32            3.00    0.000040   0.077583  \n",
       "33            8.00    0.000156  -0.768833  \n",
       "34            8.00    0.000110   0.038500  \n",
       "35            8.00    0.000095   0.079167  \n",
       "36            8.00    0.000089   0.022333  \n",
       "37            8.00    0.000084   0.085792  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43604aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svtdanny",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
